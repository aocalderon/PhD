acald013@dblab-rack12: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack15: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack14: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack11: no org.apache.spark.deploy.worker.Worker to stop
no org.apache.spark.deploy.master.Master to stop
starting org.apache.spark.deploy.master.Master, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.master.Master-1-dblab-rack11.cs.ucr.edu.out
acald013@dblab-rack14: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack14.cs.ucr.edu.out
Running iteration 1/5 for 7 cores...
2017-12-09 18:25:37,643 -> Starting session,1.63,0
2017-12-09 18:25:37,644 -> Setting variables,0.00,0
2017-12-09 18:25:42,097 -> Reading datasets,4.45,0
2017-12-09 18:25:42,117 -> Points partitions: 2
2017-12-09 18:25:42,130 -> Centers partitions: 2
2017-12-09 18:25:49,761 -> 01.Indexing points,7.58,78857,50.0,7
2017-12-09 18:25:57,985 -> 02.Indexing centers,8.22,502168,50.0,7
2017-12-09 18:25:57,997 -> 1024
2017-12-09 18:25:58,006 -> 1024
2017-12-09 18:26:20,211 -> 03.Joining datasets,22.20,502159,50.0,7
Done!!! Sat Dec  9 18:26:20 PST 2017
Running iteration 2/5 for 7 cores...
2017-12-09 18:26:22,969 -> Starting session,1.51,0
2017-12-09 18:26:22,970 -> Setting variables,0.00,0
2017-12-09 18:26:27,209 -> Reading datasets,4.24,0
2017-12-09 18:26:27,223 -> Points partitions: 2
2017-12-09 18:26:27,232 -> Centers partitions: 2
2017-12-09 18:26:35,187 -> 01.Indexing points,7.75,78857,50.0,7
2017-12-09 18:26:43,829 -> 02.Indexing centers,8.64,502168,50.0,7
2017-12-09 18:26:43,839 -> 1024
2017-12-09 18:26:43,845 -> 1024
2017-12-09 18:27:06,930 -> 03.Joining datasets,23.08,502159,50.0,7
Done!!! Sat Dec  9 18:27:07 PST 2017
Running iteration 3/5 for 7 cores...
2017-12-09 18:27:09,681 -> Starting session,1.59,0
2017-12-09 18:27:09,682 -> Setting variables,0.00,0
2017-12-09 18:27:13,994 -> Reading datasets,4.31,0
2017-12-09 18:27:14,009 -> Points partitions: 2
2017-12-09 18:27:14,019 -> Centers partitions: 2
2017-12-09 18:27:21,868 -> 01.Indexing points,7.81,78857,50.0,7
2017-12-09 18:27:30,250 -> 02.Indexing centers,8.38,502168,50.0,7
2017-12-09 18:27:30,258 -> 1024
2017-12-09 18:27:30,264 -> 1024
2017-12-09 18:27:52,439 -> 03.Joining datasets,22.17,502159,50.0,7
Done!!! Sat Dec  9 18:27:52 PST 2017
Running iteration 4/5 for 7 cores...
2017-12-09 18:27:55,482 -> Starting session,1.86,0
2017-12-09 18:27:55,483 -> Setting variables,0.00,0
2017-12-09 18:27:59,695 -> Reading datasets,4.21,0
2017-12-09 18:27:59,706 -> Points partitions: 2
2017-12-09 18:27:59,713 -> Centers partitions: 2
2017-12-09 18:28:07,066 -> 01.Indexing points,7.31,78857,50.0,7
2017-12-09 18:28:14,999 -> 02.Indexing centers,7.93,502168,50.0,7
2017-12-09 18:28:15,011 -> 1024
2017-12-09 18:28:15,019 -> 1024
2017-12-09 18:28:36,442 -> 03.Joining datasets,21.42,502159,50.0,7
Done!!! Sat Dec  9 18:28:36 PST 2017
Running iteration 5/5 for 7 cores...
2017-12-09 18:28:39,199 -> Starting session,1.54,0
2017-12-09 18:28:39,199 -> Setting variables,0.00,0
2017-12-09 18:28:43,533 -> Reading datasets,4.33,0
2017-12-09 18:28:43,549 -> Points partitions: 2
2017-12-09 18:28:43,558 -> Centers partitions: 2
2017-12-09 18:28:51,298 -> 01.Indexing points,7.70,78857,50.0,7
2017-12-09 18:28:59,699 -> 02.Indexing centers,8.40,502168,50.0,7
2017-12-09 18:28:59,711 -> 1024
2017-12-09 18:28:59,719 -> 1024
2017-12-09 18:29:22,306 -> 03.Joining datasets,22.59,502159,50.0,7
Done!!! Sat Dec  9 18:29:22 PST 2017
acald013@dblab-rack14: stopping org.apache.spark.deploy.worker.Worker
stopping org.apache.spark.deploy.master.Master
starting org.apache.spark.deploy.master.Master, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.master.Master-1-dblab-rack11.cs.ucr.edu.out
acald013@dblab-rack12: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack12.out
acald013@dblab-rack11: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack11.cs.ucr.edu.out
Running iteration 1/5 for 14 cores...
2017-12-09 18:29:30,724 -> Starting session,1.67,0
2017-12-09 18:29:30,724 -> Setting variables,0.00,0
2017-12-09 18:29:35,837 -> Reading datasets,5.11,0
2017-12-09 18:29:35,851 -> Points partitions: 2
2017-12-09 18:29:35,861 -> Centers partitions: 2
2017-12-09 18:29:43,598 -> 01.Indexing points,7.70,78857,50.0,14
2017-12-09 18:29:51,738 -> 02.Indexing centers,8.14,502168,50.0,14
2017-12-09 18:29:51,746 -> 1024
2017-12-09 18:29:51,751 -> 1024
2017-12-09 18:30:09,566 -> 03.Joining datasets,17.81,502159,50.0,14
Done!!! Sat Dec  9 18:30:10 PST 2017
Running iteration 2/5 for 14 cores...
2017-12-09 18:30:13,187 -> Starting session,1.62,0
2017-12-09 18:30:13,187 -> Setting variables,0.00,0
2017-12-09 18:30:18,193 -> Reading datasets,5.01,0
2017-12-09 18:30:18,210 -> Points partitions: 2
2017-12-09 18:30:18,220 -> Centers partitions: 2
2017-12-09 18:30:25,674 -> 01.Indexing points,7.41,78857,50.0,14
2017-12-09 18:30:34,465 -> 02.Indexing centers,8.79,502168,50.0,14
2017-12-09 18:30:34,472 -> 1024
2017-12-09 18:30:34,478 -> 1024
2017-12-09 18:30:52,012 -> 03.Joining datasets,17.53,502159,50.0,14
Done!!! Sat Dec  9 18:30:52 PST 2017
Running iteration 3/5 for 14 cores...
2017-12-09 18:30:54,813 -> Starting session,1.68,0
2017-12-09 18:30:54,814 -> Setting variables,0.00,0
2017-12-09 18:30:59,954 -> Reading datasets,5.14,0
2017-12-09 18:30:59,965 -> Points partitions: 2
2017-12-09 18:30:59,973 -> Centers partitions: 2
2017-12-09 18:31:07,648 -> 01.Indexing points,7.64,78857,50.0,14
2017-12-09 18:31:16,063 -> 02.Indexing centers,8.41,502168,50.0,14
2017-12-09 18:31:16,071 -> 1024
2017-12-09 18:31:16,078 -> 1024
2017-12-09 18:31:34,318 -> 03.Joining datasets,18.24,502159,50.0,14
Done!!! Sat Dec  9 18:31:34 PST 2017
Running iteration 4/5 for 14 cores...
2017-12-09 18:31:37,318 -> Starting session,1.79,0
2017-12-09 18:31:37,319 -> Setting variables,0.00,0
2017-12-09 18:31:42,531 -> Reading datasets,5.21,0
2017-12-09 18:31:42,541 -> Points partitions: 2
2017-12-09 18:31:42,548 -> Centers partitions: 2
2017-12-09 18:31:50,864 -> 01.Indexing points,8.27,78857,50.0,14
2017-12-09 18:31:59,233 -> 02.Indexing centers,8.37,502168,50.0,14
2017-12-09 18:31:59,241 -> 1024
2017-12-09 18:31:59,247 -> 1024
2017-12-09 18:32:17,568 -> 03.Joining datasets,18.32,502159,50.0,14
Done!!! Sat Dec  9 18:32:18 PST 2017
Running iteration 5/5 for 14 cores...
2017-12-09 18:32:20,430 -> Starting session,1.57,0
2017-12-09 18:32:20,431 -> Setting variables,0.00,0
2017-12-09 18:32:25,500 -> Reading datasets,5.07,0
2017-12-09 18:32:25,511 -> Points partitions: 2
2017-12-09 18:32:25,519 -> Centers partitions: 2
2017-12-09 18:32:33,135 -> 01.Indexing points,7.58,78857,50.0,14
2017-12-09 18:32:41,171 -> 02.Indexing centers,8.03,502168,50.0,14
2017-12-09 18:32:41,182 -> 1024
2017-12-09 18:32:41,190 -> 1024
2017-12-09 18:32:58,985 -> 03.Joining datasets,17.94,502159,50.0,14
Done!!! Sat Dec  9 18:32:59 PST 2017
acald013@dblab-rack12: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack11: stopping org.apache.spark.deploy.worker.Worker
stopping org.apache.spark.deploy.master.Master
starting org.apache.spark.deploy.master.Master, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.master.Master-1-dblab-rack11.cs.ucr.edu.out
acald013@dblab-rack12: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack12.out
acald013@dblab-rack14: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack14.cs.ucr.edu.out
acald013@dblab-rack11: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack11.cs.ucr.edu.out
Running iteration 1/5 for 21 cores...
2017-12-09 18:33:07,289 -> Starting session,1.79,0
2017-12-09 18:33:07,289 -> Setting variables,0.00,0
2017-12-09 18:33:13,521 -> Reading datasets,6.23,0
2017-12-09 18:33:13,542 -> Points partitions: 2
2017-12-09 18:33:13,555 -> Centers partitions: 2
2017-12-09 18:33:20,588 -> 01.Indexing points,6.97,78857,50.0,21
2017-12-09 18:33:28,639 -> 02.Indexing centers,8.05,502168,50.0,21
2017-12-09 18:33:28,650 -> 1024
2017-12-09 18:33:28,658 -> 1024
2017-12-09 18:33:42,283 -> 03.Joining datasets,13.62,502159,50.0,21
Done!!! Sat Dec  9 18:33:42 PST 2017
Running iteration 2/5 for 21 cores...
2017-12-09 18:33:45,241 -> Starting session,1.69,0
2017-12-09 18:33:45,242 -> Setting variables,0.00,0
2017-12-09 18:33:51,025 -> Reading datasets,5.78,0
2017-12-09 18:33:51,044 -> Points partitions: 2
2017-12-09 18:33:51,056 -> Centers partitions: 2
2017-12-09 18:33:58,219 -> 01.Indexing points,7.11,78857,50.0,21
2017-12-09 18:34:05,680 -> 02.Indexing centers,7.46,502168,50.0,21
2017-12-09 18:34:05,690 -> 1024
2017-12-09 18:34:05,698 -> 1024
2017-12-09 18:34:19,191 -> 03.Joining datasets,13.49,502159,50.0,21
Done!!! Sat Dec  9 18:34:19 PST 2017
Running iteration 3/5 for 21 cores...
2017-12-09 18:34:21,970 -> Starting session,1.62,0
2017-12-09 18:34:21,970 -> Setting variables,0.00,0
2017-12-09 18:34:27,816 -> Reading datasets,5.84,0
2017-12-09 18:34:27,836 -> Points partitions: 2
2017-12-09 18:34:27,848 -> Centers partitions: 2
2017-12-09 18:34:34,741 -> 01.Indexing points,6.84,78857,50.0,21
2017-12-09 18:34:42,702 -> 02.Indexing centers,7.96,502168,50.0,21
2017-12-09 18:34:42,710 -> 1024
2017-12-09 18:34:42,716 -> 1024
2017-12-09 18:34:57,119 -> 03.Joining datasets,14.40,502159,50.0,21
Done!!! Sat Dec  9 18:34:57 PST 2017
Running iteration 4/5 for 21 cores...
2017-12-09 18:34:59,978 -> Starting session,1.56,0
2017-12-09 18:34:59,978 -> Setting variables,0.00,0
2017-12-09 18:35:05,124 -> Reading datasets,5.15,0
2017-12-09 18:35:05,135 -> Points partitions: 2
2017-12-09 18:35:05,143 -> Centers partitions: 2
2017-12-09 18:35:12,818 -> 01.Indexing points,7.64,78857,50.0,21
2017-12-09 18:35:20,529 -> 02.Indexing centers,7.71,502168,50.0,21
2017-12-09 18:35:20,540 -> 1024
2017-12-09 18:35:20,549 -> 1024
2017-12-09 18:35:33,326 -> 03.Joining datasets,12.78,502159,50.0,21
Done!!! Sat Dec  9 18:35:33 PST 2017
Running iteration 5/5 for 21 cores...
2017-12-09 18:35:36,144 -> Starting session,1.60,0
2017-12-09 18:35:36,145 -> Setting variables,0.00,0
2017-12-09 18:35:41,128 -> Reading datasets,4.98,0
2017-12-09 18:35:41,141 -> Points partitions: 2
2017-12-09 18:35:41,152 -> Centers partitions: 2
2017-12-09 18:35:48,902 -> 01.Indexing points,7.71,78857,50.0,21
2017-12-09 18:35:56,616 -> 02.Indexing centers,7.71,502168,50.0,21
2017-12-09 18:35:56,624 -> 1024
2017-12-09 18:35:56,630 -> 1024
2017-12-09 18:36:10,395 -> 03.Joining datasets,13.77,502159,50.0,21
Done!!! Sat Dec  9 18:36:10 PST 2017
acald013@dblab-rack12: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack11: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack14: stopping org.apache.spark.deploy.worker.Worker
stopping org.apache.spark.deploy.master.Master
starting org.apache.spark.deploy.master.Master, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.master.Master-1-dblab-rack11.cs.ucr.edu.out
acald013@dblab-rack12: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack12.out
acald013@dblab-rack15: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack15.out
acald013@dblab-rack14: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack14.cs.ucr.edu.out
acald013@dblab-rack11: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack11.cs.ucr.edu.out
Running iteration 1/5 for 28 cores...
2017-12-09 18:36:18,898 -> Starting session,1.92,0
2017-12-09 18:36:18,899 -> Setting variables,0.00,0
2017-12-09 18:36:26,108 -> Reading datasets,7.21,0
2017-12-09 18:36:26,122 -> Points partitions: 2
2017-12-09 18:36:26,134 -> Centers partitions: 2
2017-12-09 18:36:34,354 -> 01.Indexing points,8.17,78857,50.0,28
2017-12-09 18:36:43,044 -> 02.Indexing centers,8.69,502168,50.0,28
2017-12-09 18:36:43,052 -> 1024
2017-12-09 18:36:43,064 -> 1024
2017-12-09 18:36:55,847 -> 03.Joining datasets,12.78,502159,50.0,28
Done!!! Sat Dec  9 18:36:56 PST 2017
Running iteration 2/5 for 28 cores...
2017-12-09 18:36:58,633 -> Starting session,1.51,0
2017-12-09 18:36:58,633 -> Setting variables,0.00,0
2017-12-09 18:37:05,803 -> Reading datasets,7.17,0
2017-12-09 18:37:05,821 -> Points partitions: 2
2017-12-09 18:37:05,833 -> Centers partitions: 2
2017-12-09 18:37:13,749 -> 01.Indexing points,7.87,78857,50.0,28
2017-12-09 18:37:23,769 -> 02.Indexing centers,10.02,502168,50.0,28
2017-12-09 18:37:23,777 -> 1024
2017-12-09 18:37:23,783 -> 1024
2017-12-09 18:37:37,318 -> 03.Joining datasets,13.53,502159,50.0,28
Done!!! Sat Dec  9 18:37:37 PST 2017
Running iteration 3/5 for 28 cores...
2017-12-09 18:37:40,167 -> Starting session,1.61,0
2017-12-09 18:37:40,167 -> Setting variables,0.00,0
2017-12-09 18:37:46,254 -> Reading datasets,6.09,0
2017-12-09 18:37:46,269 -> Points partitions: 2
2017-12-09 18:37:46,278 -> Centers partitions: 2
2017-12-09 18:37:55,789 -> 01.Indexing points,9.47,78857,50.0,28
2017-12-09 18:38:07,558 -> 02.Indexing centers,11.77,502168,50.0,28
2017-12-09 18:38:07,570 -> 1024
2017-12-09 18:38:07,580 -> 1024
2017-12-09 18:38:20,962 -> 03.Joining datasets,13.38,502159,50.0,28
Done!!! Sat Dec  9 18:38:21 PST 2017
Running iteration 4/5 for 28 cores...
2017-12-09 18:38:23,733 -> Starting session,1.54,0
2017-12-09 18:38:23,734 -> Setting variables,0.00,0
2017-12-09 18:38:31,104 -> Reading datasets,7.37,0
2017-12-09 18:38:31,122 -> Points partitions: 2
2017-12-09 18:38:31,133 -> Centers partitions: 2
2017-12-09 18:38:38,686 -> 01.Indexing points,8.05,78857,50.0,28
2017-12-09 18:38:50,078 -> 02.Indexing centers,11.39,502168,50.0,28
2017-12-09 18:38:50,091 -> 1024
2017-12-09 18:38:50,099 -> 1024
2017-12-09 18:39:02,269 -> 03.Joining datasets,12.17,502159,50.0,28
Done!!! Sat Dec  9 18:39:02 PST 2017
Running iteration 5/5 for 28 cores...
2017-12-09 18:39:04,996 -> Starting session,1.63,0
2017-12-09 18:39:04,996 -> Setting variables,0.00,0
2017-12-09 18:39:12,347 -> Reading datasets,7.35,0
2017-12-09 18:39:12,370 -> Points partitions: 2
2017-12-09 18:39:12,387 -> Centers partitions: 2
2017-12-09 18:39:20,192 -> 01.Indexing points,7.74,78857,50.0,28
2017-12-09 18:39:30,779 -> 02.Indexing centers,10.58,502168,50.0,28
2017-12-09 18:39:30,788 -> 1024
2017-12-09 18:39:30,795 -> 1024
2017-12-09 18:39:42,971 -> 03.Joining datasets,12.18,502159,50.0,28
Done!!! Sat Dec  9 18:39:44 PST 2017
acald013@dblab-rack12: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack15: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack11: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack14: stopping org.apache.spark.deploy.worker.Worker
stopping org.apache.spark.deploy.master.Master
Done!!!
acald013@dblab-rack12: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack15: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack14: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack11: no org.apache.spark.deploy.worker.Worker to stop
no org.apache.spark.deploy.master.Master to stop
starting org.apache.spark.deploy.master.Master, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.master.Master-1-dblab-rack11.cs.ucr.edu.out
acald013@dblab-rack14: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack14.cs.ucr.edu.out
Running iteration 1/5 for 7 cores...
2017-12-09 18:39:52,386 -> Starting session,1.77,0
2017-12-09 18:39:52,387 -> Setting variables,0.00,0
2017-12-09 18:39:56,792 -> Reading datasets,4.40,0
2017-12-09 18:39:56,805 -> Points partitions: 2
2017-12-09 18:39:56,816 -> Centers partitions: 2
2017-12-09 18:40:03,978 -> 01.Indexing points,7.12,59143,50.0,7
2017-12-09 18:40:11,222 -> 02.Indexing centers,7.24,376626,50.0,7
2017-12-09 18:40:11,233 -> 1024
2017-12-09 18:40:11,240 -> 1024
2017-12-09 18:40:30,659 -> 03.Joining datasets,19.49,376619,50.0,7
Done!!! Sat Dec  9 18:40:31 PST 2017
Running iteration 2/5 for 7 cores...
2017-12-09 18:40:33,392 -> Starting session,1.54,0
2017-12-09 18:40:33,392 -> Setting variables,0.00,0
2017-12-09 18:40:37,789 -> Reading datasets,4.40,0
2017-12-09 18:40:37,804 -> Points partitions: 2
2017-12-09 18:40:37,813 -> Centers partitions: 2
2017-12-09 18:40:45,002 -> 01.Indexing points,7.15,59143,50.0,7
2017-12-09 18:40:52,259 -> 02.Indexing centers,7.25,376626,50.0,7
2017-12-09 18:40:52,274 -> 1024
2017-12-09 18:40:52,287 -> 1024
2017-12-09 18:41:13,207 -> 03.Joining datasets,20.92,376619,50.0,7
Done!!! Sat Dec  9 18:41:13 PST 2017
Running iteration 3/5 for 7 cores...
2017-12-09 18:41:15,934 -> Starting session,1.52,0
2017-12-09 18:41:15,935 -> Setting variables,0.00,0
2017-12-09 18:41:20,148 -> Reading datasets,4.21,0
2017-12-09 18:41:20,162 -> Points partitions: 2
2017-12-09 18:41:20,171 -> Centers partitions: 2
2017-12-09 18:41:27,796 -> 01.Indexing points,7.58,59143,50.0,7
2017-12-09 18:41:35,171 -> 02.Indexing centers,7.37,376626,50.0,7
2017-12-09 18:41:35,186 -> 1024
2017-12-09 18:41:35,198 -> 1024
2017-12-09 18:41:56,491 -> 03.Joining datasets,21.29,376619,50.0,7
Done!!! Sat Dec  9 18:41:56 PST 2017
Running iteration 4/5 for 7 cores...
2017-12-09 18:41:59,085 -> Starting session,1.50,0
2017-12-09 18:41:59,086 -> Setting variables,0.00,0
2017-12-09 18:42:03,791 -> Reading datasets,4.70,0
2017-12-09 18:42:03,810 -> Points partitions: 2
2017-12-09 18:42:03,821 -> Centers partitions: 2
2017-12-09 18:42:11,474 -> 01.Indexing points,7.60,59143,50.0,7
2017-12-09 18:42:18,882 -> 02.Indexing centers,7.41,376626,50.0,7
2017-12-09 18:42:18,895 -> 1024
2017-12-09 18:42:18,905 -> 1024
2017-12-09 18:42:39,749 -> 03.Joining datasets,20.84,376619,50.0,7
Done!!! Sat Dec  9 18:42:40 PST 2017
Running iteration 5/5 for 7 cores...
2017-12-09 18:42:42,518 -> Starting session,1.54,0
2017-12-09 18:42:42,519 -> Setting variables,0.00,0
2017-12-09 18:42:46,921 -> Reading datasets,4.40,0
2017-12-09 18:42:46,931 -> Points partitions: 2
2017-12-09 18:42:46,939 -> Centers partitions: 2
2017-12-09 18:42:54,158 -> 01.Indexing points,7.18,59143,50.0,7
2017-12-09 18:43:01,450 -> 02.Indexing centers,7.29,376626,50.0,7
2017-12-09 18:43:01,462 -> 1024
2017-12-09 18:43:01,471 -> 1024
2017-12-09 18:43:22,012 -> 03.Joining datasets,20.54,376619,50.0,7
Done!!! Sat Dec  9 18:43:22 PST 2017
acald013@dblab-rack14: stopping org.apache.spark.deploy.worker.Worker
stopping org.apache.spark.deploy.master.Master
starting org.apache.spark.deploy.master.Master, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.master.Master-1-dblab-rack11.cs.ucr.edu.out
acald013@dblab-rack12: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack12.out
acald013@dblab-rack11: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack11.cs.ucr.edu.out
Running iteration 1/5 for 14 cores...
2017-12-09 18:43:30,409 -> Starting session,1.68,0
2017-12-09 18:43:30,410 -> Setting variables,0.00,0
2017-12-09 18:43:35,359 -> Reading datasets,4.95,0
2017-12-09 18:43:35,373 -> Points partitions: 2
2017-12-09 18:43:35,384 -> Centers partitions: 2
2017-12-09 18:43:42,750 -> 01.Indexing points,7.33,59143,50.0,14
2017-12-09 18:43:50,114 -> 02.Indexing centers,7.36,376626,50.0,14
2017-12-09 18:43:50,122 -> 1024
2017-12-09 18:43:50,127 -> 1024
2017-12-09 18:44:06,492 -> 03.Joining datasets,16.36,376619,50.0,14
Done!!! Sat Dec  9 18:44:07 PST 2017
Running iteration 2/5 for 14 cores...
2017-12-09 18:44:09,487 -> Starting session,1.78,0
2017-12-09 18:44:09,487 -> Setting variables,0.00,0
2017-12-09 18:44:14,378 -> Reading datasets,4.89,0
2017-12-09 18:44:14,392 -> Points partitions: 2
2017-12-09 18:44:14,403 -> Centers partitions: 2
2017-12-09 18:44:21,769 -> 01.Indexing points,7.32,59143,50.0,14
2017-12-09 18:44:29,200 -> 02.Indexing centers,7.43,376626,50.0,14
2017-12-09 18:44:29,213 -> 1024
2017-12-09 18:44:29,222 -> 1024
2017-12-09 18:44:46,197 -> 03.Joining datasets,16.98,376619,50.0,14
Done!!! Sat Dec  9 18:44:46 PST 2017
Running iteration 3/5 for 14 cores...
2017-12-09 18:44:48,884 -> Starting session,1.58,0
2017-12-09 18:44:48,884 -> Setting variables,0.00,0
2017-12-09 18:44:53,825 -> Reading datasets,4.94,0
2017-12-09 18:44:53,847 -> Points partitions: 2
2017-12-09 18:44:53,859 -> Centers partitions: 2
2017-12-09 18:45:00,878 -> 01.Indexing points,6.97,59143,50.0,14
2017-12-09 18:45:08,203 -> 02.Indexing centers,7.32,376626,50.0,14
2017-12-09 18:45:08,211 -> 1024
2017-12-09 18:45:08,216 -> 1024
2017-12-09 18:45:24,350 -> 03.Joining datasets,16.13,376619,50.0,14
Done!!! Sat Dec  9 18:45:24 PST 2017
Running iteration 4/5 for 14 cores...
2017-12-09 18:45:27,291 -> Starting session,1.72,0
2017-12-09 18:45:27,292 -> Setting variables,0.00,0
2017-12-09 18:45:32,266 -> Reading datasets,4.97,0
2017-12-09 18:45:32,279 -> Points partitions: 2
2017-12-09 18:45:32,287 -> Centers partitions: 2
2017-12-09 18:45:39,794 -> 01.Indexing points,7.42,59143,50.0,14
2017-12-09 18:45:46,764 -> 02.Indexing centers,6.97,376626,50.0,14
2017-12-09 18:45:46,774 -> 1024
2017-12-09 18:45:46,783 -> 1024
2017-12-09 18:46:03,713 -> 03.Joining datasets,16.93,376619,50.0,14
Done!!! Sat Dec  9 18:46:04 PST 2017
Running iteration 5/5 for 14 cores...
2017-12-09 18:46:06,553 -> Starting session,1.62,0
2017-12-09 18:46:06,554 -> Setting variables,0.00,0
2017-12-09 18:46:11,711 -> Reading datasets,5.16,0
2017-12-09 18:46:11,721 -> Points partitions: 2
2017-12-09 18:46:11,729 -> Centers partitions: 2
2017-12-09 18:46:19,065 -> 01.Indexing points,7.30,59143,50.0,14
2017-12-09 18:46:26,609 -> 02.Indexing centers,7.54,376626,50.0,14
2017-12-09 18:46:26,618 -> 1024
2017-12-09 18:46:26,624 -> 1024
2017-12-09 18:46:43,711 -> 03.Joining datasets,17.09,376619,50.0,14
Done!!! Sat Dec  9 18:46:44 PST 2017
acald013@dblab-rack12: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack11: stopping org.apache.spark.deploy.worker.Worker
stopping org.apache.spark.deploy.master.Master
starting org.apache.spark.deploy.master.Master, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.master.Master-1-dblab-rack11.cs.ucr.edu.out
acald013@dblab-rack12: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack12.out
acald013@dblab-rack14: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack14.cs.ucr.edu.out
acald013@dblab-rack11: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack11.cs.ucr.edu.out
Running iteration 1/5 for 21 cores...
2017-12-09 18:46:52,214 -> Starting session,1.75,0
2017-12-09 18:46:52,216 -> Setting variables,0.00,0
2017-12-09 18:46:57,240 -> Reading datasets,5.02,0
2017-12-09 18:46:57,251 -> Points partitions: 2
2017-12-09 18:46:57,259 -> Centers partitions: 2
2017-12-09 18:47:04,704 -> 01.Indexing points,7.41,59143,50.0,21
2017-12-09 18:47:11,718 -> 02.Indexing centers,7.01,376626,50.0,21
2017-12-09 18:47:11,733 -> 1024
2017-12-09 18:47:11,742 -> 1024
2017-12-09 18:47:24,714 -> 03.Joining datasets,12.97,376619,50.0,21
Done!!! Sat Dec  9 18:47:26 PST 2017
Running iteration 2/5 for 21 cores...
2017-12-09 18:47:28,371 -> Starting session,1.66,0
2017-12-09 18:47:28,372 -> Setting variables,0.00,0
2017-12-09 18:47:34,267 -> Reading datasets,5.89,0
2017-12-09 18:47:34,280 -> Points partitions: 2
2017-12-09 18:47:34,288 -> Centers partitions: 2
2017-12-09 18:47:40,898 -> 01.Indexing points,6.57,59143,50.0,21
2017-12-09 18:47:47,678 -> 02.Indexing centers,6.78,376626,50.0,21
2017-12-09 18:47:47,688 -> 1024
2017-12-09 18:47:47,696 -> 1024
2017-12-09 18:48:00,551 -> 03.Joining datasets,12.85,376619,50.0,21
Done!!! Sat Dec  9 18:48:01 PST 2017
Running iteration 3/5 for 21 cores...
2017-12-09 18:48:03,816 -> Starting session,1.53,0
2017-12-09 18:48:03,817 -> Setting variables,0.00,0
2017-12-09 18:48:09,797 -> Reading datasets,5.98,0
2017-12-09 18:48:09,809 -> Points partitions: 2
2017-12-09 18:48:09,817 -> Centers partitions: 2
2017-12-09 18:48:16,126 -> 01.Indexing points,6.27,59143,50.0,21
2017-12-09 18:48:23,299 -> 02.Indexing centers,7.17,376626,50.0,21
2017-12-09 18:48:23,311 -> 1024
2017-12-09 18:48:23,321 -> 1024
2017-12-09 18:48:36,169 -> 03.Joining datasets,12.85,376619,50.0,21
Done!!! Sat Dec  9 18:48:36 PST 2017
Running iteration 4/5 for 21 cores...
2017-12-09 18:48:39,085 -> Starting session,1.85,0
2017-12-09 18:48:39,086 -> Setting variables,0.00,0
2017-12-09 18:48:44,984 -> Reading datasets,5.90,0
2017-12-09 18:48:45,004 -> Points partitions: 2
2017-12-09 18:48:45,017 -> Centers partitions: 2
2017-12-09 18:48:51,395 -> 01.Indexing points,6.33,59143,50.0,21
2017-12-09 18:48:58,147 -> 02.Indexing centers,6.75,376626,50.0,21
2017-12-09 18:48:58,156 -> 1024
2017-12-09 18:48:58,162 -> 1024
2017-12-09 18:49:11,603 -> 03.Joining datasets,13.44,376619,50.0,21
Done!!! Sat Dec  9 18:49:12 PST 2017
Running iteration 5/5 for 21 cores...
2017-12-09 18:49:14,379 -> Starting session,1.59,0
2017-12-09 18:49:14,380 -> Setting variables,0.00,0
2017-12-09 18:49:20,241 -> Reading datasets,5.86,0
2017-12-09 18:49:20,263 -> Points partitions: 2
2017-12-09 18:49:20,279 -> Centers partitions: 2
2017-12-09 18:49:27,132 -> 01.Indexing points,6.80,59143,50.0,21
2017-12-09 18:49:33,866 -> 02.Indexing centers,6.73,376626,50.0,21
2017-12-09 18:49:33,876 -> 1024
2017-12-09 18:49:33,882 -> 1024
2017-12-09 18:49:46,757 -> 03.Joining datasets,12.87,376619,50.0,21
Done!!! Sat Dec  9 18:49:48 PST 2017
acald013@dblab-rack12: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack11: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack14: stopping org.apache.spark.deploy.worker.Worker
stopping org.apache.spark.deploy.master.Master
starting org.apache.spark.deploy.master.Master, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.master.Master-1-dblab-rack11.cs.ucr.edu.out
acald013@dblab-rack12: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack12.out
acald013@dblab-rack15: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack15.out
acald013@dblab-rack14: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack14.cs.ucr.edu.out
acald013@dblab-rack11: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack11.cs.ucr.edu.out
Running iteration 1/5 for 28 cores...
2017-12-09 18:49:56,166 -> Starting session,1.84,0
2017-12-09 18:49:56,167 -> Setting variables,0.00,0
2017-12-09 18:50:03,565 -> Reading datasets,7.40,0
2017-12-09 18:50:03,577 -> Points partitions: 2
2017-12-09 18:50:03,584 -> Centers partitions: 2
2017-12-09 18:50:11,401 -> 01.Indexing points,7.78,59143,50.0,28
2017-12-09 18:50:17,939 -> 02.Indexing centers,6.54,376626,50.0,28
2017-12-09 18:50:17,950 -> 1024
2017-12-09 18:50:17,959 -> 1024
2017-12-09 18:50:29,173 -> 03.Joining datasets,11.21,376619,50.0,28
Done!!! Sat Dec  9 18:50:29 PST 2017
Running iteration 2/5 for 28 cores...
2017-12-09 18:50:31,938 -> Starting session,1.54,0
2017-12-09 18:50:31,939 -> Setting variables,0.00,0
2017-12-09 18:50:39,272 -> Reading datasets,7.33,0
2017-12-09 18:50:39,292 -> Points partitions: 2
2017-12-09 18:50:39,306 -> Centers partitions: 2
2017-12-09 18:50:45,705 -> 01.Indexing points,6.34,59143,50.0,28
2017-12-09 18:50:52,524 -> 02.Indexing centers,6.82,376626,50.0,28
2017-12-09 18:50:52,538 -> 1024
2017-12-09 18:50:52,547 -> 1024
2017-12-09 18:51:04,531 -> 03.Joining datasets,11.98,376619,50.0,28
Done!!! Sat Dec  9 18:51:05 PST 2017
Running iteration 3/5 for 28 cores...
2017-12-09 18:51:07,363 -> Starting session,1.71,0
2017-12-09 18:51:07,363 -> Setting variables,0.00,0
2017-12-09 18:51:14,270 -> Reading datasets,6.91,0
2017-12-09 18:51:14,290 -> Points partitions: 2
2017-12-09 18:51:14,303 -> Centers partitions: 2
2017-12-09 18:51:21,470 -> 01.Indexing points,7.11,59143,50.0,28
2017-12-09 18:51:29,524 -> 02.Indexing centers,8.05,376626,50.0,28
2017-12-09 18:51:29,532 -> 1024
2017-12-09 18:51:29,539 -> 1024
2017-12-09 18:51:41,392 -> 03.Joining datasets,11.85,376619,50.0,28
Done!!! Sat Dec  9 18:51:41 PST 2017
Running iteration 4/5 for 28 cores...
2017-12-09 18:51:44,206 -> Starting session,1.59,0
2017-12-09 18:51:44,206 -> Setting variables,0.00,0
2017-12-09 18:51:51,411 -> Reading datasets,7.20,0
2017-12-09 18:51:51,430 -> Points partitions: 2
2017-12-09 18:51:51,446 -> Centers partitions: 2
2017-12-09 18:51:59,322 -> 01.Indexing points,7.82,59143,50.0,28
2017-12-09 18:52:06,973 -> 02.Indexing centers,7.65,376626,50.0,28
2017-12-09 18:52:06,981 -> 1024
2017-12-09 18:52:06,988 -> 1024
2017-12-09 18:52:18,582 -> 03.Joining datasets,11.59,376619,50.0,28
Done!!! Sat Dec  9 18:52:19 PST 2017
Running iteration 5/5 for 28 cores...
2017-12-09 18:52:21,270 -> Starting session,1.55,0
2017-12-09 18:52:21,270 -> Setting variables,0.00,0
2017-12-09 18:52:28,295 -> Reading datasets,7.02,0
2017-12-09 18:52:28,314 -> Points partitions: 2
2017-12-09 18:52:28,326 -> Centers partitions: 2
2017-12-09 18:52:36,194 -> 01.Indexing points,7.81,59143,50.0,28
2017-12-09 18:52:42,756 -> 02.Indexing centers,6.56,376626,50.0,28
2017-12-09 18:52:42,767 -> 1024
2017-12-09 18:52:42,774 -> 1024
2017-12-09 18:52:54,575 -> 03.Joining datasets,11.80,376619,50.0,28
Done!!! Sat Dec  9 18:52:55 PST 2017
acald013@dblab-rack12: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack15: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack14: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack11: stopping org.apache.spark.deploy.worker.Worker
stopping org.apache.spark.deploy.master.Master
Done!!!
acald013@dblab-rack12: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack15: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack11: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack14: no org.apache.spark.deploy.worker.Worker to stop
no org.apache.spark.deploy.master.Master to stop
starting org.apache.spark.deploy.master.Master, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.master.Master-1-dblab-rack11.cs.ucr.edu.out
acald013@dblab-rack14: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack14.cs.ucr.edu.out
Running iteration 1/5 for 7 cores...
2017-12-09 18:53:03,022 -> Starting session,1.47,0
2017-12-09 18:53:03,022 -> Setting variables,0.00,0
2017-12-09 18:53:07,245 -> Reading datasets,4.22,0
2017-12-09 18:53:07,259 -> Points partitions: 2
2017-12-09 18:53:07,270 -> Centers partitions: 2
2017-12-09 18:53:14,531 -> 01.Indexing points,7.22,39429,50.0,7
2017-12-09 18:53:20,837 -> 02.Indexing centers,6.31,251084,50.0,7
2017-12-09 18:53:20,852 -> 1024
2017-12-09 18:53:20,862 -> 1024
2017-12-09 18:53:39,272 -> 03.Joining datasets,18.49,251080,50.0,7
Done!!! Sat Dec  9 18:53:39 PST 2017
Running iteration 2/5 for 7 cores...
2017-12-09 18:53:42,122 -> Starting session,1.56,0
2017-12-09 18:53:42,123 -> Setting variables,0.00,0
2017-12-09 18:53:46,448 -> Reading datasets,4.33,0
2017-12-09 18:53:46,460 -> Points partitions: 2
2017-12-09 18:53:46,468 -> Centers partitions: 2
2017-12-09 18:53:53,643 -> 01.Indexing points,7.14,39429,50.0,7
2017-12-09 18:53:59,960 -> 02.Indexing centers,6.32,251084,50.0,7
2017-12-09 18:53:59,970 -> 1024
2017-12-09 18:53:59,978 -> 1024
2017-12-09 18:54:18,927 -> 03.Joining datasets,18.95,251080,50.0,7
Done!!! Sat Dec  9 18:54:19 PST 2017
Running iteration 3/5 for 7 cores...
2017-12-09 18:54:21,814 -> Starting session,1.70,0
2017-12-09 18:54:21,814 -> Setting variables,0.00,0
2017-12-09 18:54:25,922 -> Reading datasets,4.11,0
2017-12-09 18:54:25,933 -> Points partitions: 2
2017-12-09 18:54:25,940 -> Centers partitions: 2
2017-12-09 18:54:33,256 -> 01.Indexing points,7.28,39429,50.0,7
2017-12-09 18:54:39,552 -> 02.Indexing centers,6.29,251084,50.0,7
2017-12-09 18:54:39,565 -> 1024
2017-12-09 18:54:39,574 -> 1024
2017-12-09 18:54:57,742 -> 03.Joining datasets,18.17,251080,50.0,7
Done!!! Sat Dec  9 18:54:58 PST 2017
Running iteration 4/5 for 7 cores...
2017-12-09 18:55:00,567 -> Starting session,1.56,0
2017-12-09 18:55:00,567 -> Setting variables,0.00,0
2017-12-09 18:55:04,835 -> Reading datasets,4.27,0
2017-12-09 18:55:04,851 -> Points partitions: 2
2017-12-09 18:55:04,861 -> Centers partitions: 2
2017-12-09 18:55:12,358 -> 01.Indexing points,7.45,39429,50.0,7
2017-12-09 18:55:18,586 -> 02.Indexing centers,6.23,251084,50.0,7
2017-12-09 18:55:18,600 -> 1024
2017-12-09 18:55:18,608 -> 1024
2017-12-09 18:55:36,975 -> 03.Joining datasets,18.37,251080,50.0,7
Done!!! Sat Dec  9 18:55:37 PST 2017
Running iteration 5/5 for 7 cores...
2017-12-09 18:55:39,646 -> Starting session,1.50,0
2017-12-09 18:55:39,647 -> Setting variables,0.00,0
2017-12-09 18:55:43,865 -> Reading datasets,4.22,0
2017-12-09 18:55:43,878 -> Points partitions: 2
2017-12-09 18:55:43,886 -> Centers partitions: 2
2017-12-09 18:55:51,185 -> 01.Indexing points,7.26,39429,50.0,7
2017-12-09 18:55:57,615 -> 02.Indexing centers,6.43,251084,50.0,7
2017-12-09 18:55:57,628 -> 1024
2017-12-09 18:55:57,636 -> 1024
2017-12-09 18:56:16,668 -> 03.Joining datasets,19.03,251080,50.0,7
Done!!! Sat Dec  9 18:56:17 PST 2017
acald013@dblab-rack14: stopping org.apache.spark.deploy.worker.Worker
stopping org.apache.spark.deploy.master.Master
starting org.apache.spark.deploy.master.Master, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.master.Master-1-dblab-rack11.cs.ucr.edu.out
acald013@dblab-rack12: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack12.out
acald013@dblab-rack11: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack11.cs.ucr.edu.out
Running iteration 1/5 for 14 cores...
2017-12-09 18:56:25,129 -> Starting session,1.75,0
2017-12-09 18:56:25,130 -> Setting variables,0.00,0
2017-12-09 18:56:29,921 -> Reading datasets,4.79,0
2017-12-09 18:56:29,931 -> Points partitions: 2
2017-12-09 18:56:29,940 -> Centers partitions: 2
2017-12-09 18:56:36,904 -> 01.Indexing points,6.92,39429,50.0,14
2017-12-09 18:56:43,186 -> 02.Indexing centers,6.28,251084,50.0,14
2017-12-09 18:56:43,196 -> 1024
2017-12-09 18:56:43,202 -> 1024
2017-12-09 18:56:58,335 -> 03.Joining datasets,15.13,251080,50.0,14
Done!!! Sat Dec  9 18:56:59 PST 2017
Running iteration 2/5 for 14 cores...
2017-12-09 18:57:01,879 -> Starting session,1.49,0
2017-12-09 18:57:01,880 -> Setting variables,0.00,0
2017-12-09 18:57:06,721 -> Reading datasets,4.84,0
2017-12-09 18:57:06,738 -> Points partitions: 2
2017-12-09 18:57:06,749 -> Centers partitions: 2
2017-12-09 18:57:14,026 -> 01.Indexing points,7.23,39429,50.0,14
2017-12-09 18:57:20,936 -> 02.Indexing centers,6.91,251084,50.0,14
2017-12-09 18:57:20,945 -> 1024
2017-12-09 18:57:20,953 -> 1024
2017-12-09 18:57:35,683 -> 03.Joining datasets,14.73,251080,50.0,14
Done!!! Sat Dec  9 18:57:36 PST 2017
Running iteration 3/5 for 14 cores...
2017-12-09 18:57:38,505 -> Starting session,1.58,0
2017-12-09 18:57:38,506 -> Setting variables,0.00,0
2017-12-09 18:57:43,189 -> Reading datasets,4.68,0
2017-12-09 18:57:43,199 -> Points partitions: 2
2017-12-09 18:57:43,206 -> Centers partitions: 2
2017-12-09 18:57:50,273 -> 01.Indexing points,7.03,39429,50.0,14
2017-12-09 18:57:56,573 -> 02.Indexing centers,6.30,251084,50.0,14
2017-12-09 18:57:56,581 -> 1024
2017-12-09 18:57:56,587 -> 1024
2017-12-09 18:58:11,795 -> 03.Joining datasets,15.21,251080,50.0,14
Done!!! Sat Dec  9 18:58:12 PST 2017
Running iteration 4/5 for 14 cores...
2017-12-09 18:58:14,567 -> Starting session,1.55,0
2017-12-09 18:58:14,568 -> Setting variables,0.00,0
2017-12-09 18:58:19,465 -> Reading datasets,4.90,0
2017-12-09 18:58:19,475 -> Points partitions: 2
2017-12-09 18:58:19,483 -> Centers partitions: 2
2017-12-09 18:58:26,558 -> 01.Indexing points,7.04,39429,50.0,14
2017-12-09 18:58:32,708 -> 02.Indexing centers,6.15,251084,50.0,14
2017-12-09 18:58:32,720 -> 1024
2017-12-09 18:58:32,731 -> 1024
2017-12-09 18:58:47,800 -> 03.Joining datasets,15.07,251080,50.0,14
Done!!! Sat Dec  9 18:58:48 PST 2017
Running iteration 5/5 for 14 cores...
2017-12-09 18:58:50,578 -> Starting session,1.55,0
2017-12-09 18:58:50,579 -> Setting variables,0.00,0
2017-12-09 18:58:55,505 -> Reading datasets,4.93,0
2017-12-09 18:58:55,519 -> Points partitions: 2
2017-12-09 18:58:55,530 -> Centers partitions: 2
2017-12-09 18:59:02,653 -> 01.Indexing points,7.08,39429,50.0,14
2017-12-09 18:59:09,125 -> 02.Indexing centers,6.47,251084,50.0,14
2017-12-09 18:59:09,133 -> 1024
2017-12-09 18:59:09,139 -> 1024
2017-12-09 18:59:24,313 -> 03.Joining datasets,15.25,251080,50.0,14
Done!!! Sat Dec  9 18:59:25 PST 2017
acald013@dblab-rack12: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack11: stopping org.apache.spark.deploy.worker.Worker
stopping org.apache.spark.deploy.master.Master
starting org.apache.spark.deploy.master.Master, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.master.Master-1-dblab-rack11.cs.ucr.edu.out
acald013@dblab-rack12: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack12.out
acald013@dblab-rack14: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack14.cs.ucr.edu.out
acald013@dblab-rack11: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack11.cs.ucr.edu.out
Running iteration 1/5 for 21 cores...
2017-12-09 18:59:33,688 -> Starting session,1.76,0
2017-12-09 18:59:33,689 -> Setting variables,0.00,0
2017-12-09 18:59:38,718 -> Reading datasets,5.03,0
2017-12-09 18:59:38,729 -> Points partitions: 2
2017-12-09 18:59:38,737 -> Centers partitions: 2
2017-12-09 18:59:46,198 -> 01.Indexing points,7.42,39429,50.0,21
2017-12-09 18:59:52,197 -> 02.Indexing centers,6.00,251084,50.0,21
2017-12-09 18:59:52,209 -> 1024
2017-12-09 18:59:52,219 -> 1024
2017-12-09 19:00:03,662 -> 03.Joining datasets,11.44,251080,50.0,21
Done!!! Sat Dec  9 19:00:04 PST 2017
Running iteration 2/5 for 21 cores...
2017-12-09 19:00:06,396 -> Starting session,1.60,0
2017-12-09 19:00:06,397 -> Setting variables,0.00,0
2017-12-09 19:00:12,027 -> Reading datasets,5.63,0
2017-12-09 19:00:12,044 -> Points partitions: 2
2017-12-09 19:00:12,055 -> Centers partitions: 2
2017-12-09 19:00:18,615 -> 01.Indexing points,6.51,39429,50.0,21
2017-12-09 19:00:24,569 -> 02.Indexing centers,5.95,251084,50.0,21
2017-12-09 19:00:24,579 -> 1024
2017-12-09 19:00:24,586 -> 1024
2017-12-09 19:00:36,367 -> 03.Joining datasets,11.78,251080,50.0,21
Done!!! Sat Dec  9 19:00:36 PST 2017
Running iteration 3/5 for 21 cores...
2017-12-09 19:00:39,266 -> Starting session,1.68,0
2017-12-09 19:00:39,266 -> Setting variables,0.00,0
2017-12-09 19:00:45,093 -> Reading datasets,5.83,0
2017-12-09 19:00:45,108 -> Points partitions: 2
2017-12-09 19:00:45,118 -> Centers partitions: 2
2017-12-09 19:00:51,851 -> 01.Indexing points,6.57,39429,50.0,21
2017-12-09 19:00:57,768 -> 02.Indexing centers,5.91,251084,50.0,21
2017-12-09 19:00:57,781 -> 1024
2017-12-09 19:00:57,791 -> 1024
2017-12-09 19:01:09,181 -> 03.Joining datasets,11.39,251080,50.0,21
Done!!! Sat Dec  9 19:01:10 PST 2017
Running iteration 4/5 for 21 cores...
2017-12-09 19:01:12,743 -> Starting session,1.65,0
2017-12-09 19:01:12,744 -> Setting variables,0.00,0
2017-12-09 19:01:17,458 -> Reading datasets,4.71,0
2017-12-09 19:01:17,471 -> Points partitions: 2
2017-12-09 19:01:17,478 -> Centers partitions: 2
2017-12-09 19:01:24,677 -> 01.Indexing points,7.16,39429,50.0,21
2017-12-09 19:01:30,203 -> 02.Indexing centers,5.52,251084,50.0,21
2017-12-09 19:01:30,212 -> 1024
2017-12-09 19:01:30,219 -> 1024
2017-12-09 19:01:41,662 -> 03.Joining datasets,11.44,251080,50.0,21
Done!!! Sat Dec  9 19:01:42 PST 2017
Running iteration 5/5 for 21 cores...
2017-12-09 19:01:44,430 -> Starting session,1.59,0
2017-12-09 19:01:44,430 -> Setting variables,0.00,0
2017-12-09 19:01:50,149 -> Reading datasets,5.72,0
2017-12-09 19:01:50,167 -> Points partitions: 2
2017-12-09 19:01:50,179 -> Centers partitions: 2
2017-12-09 19:01:56,561 -> 01.Indexing points,6.33,39429,50.0,21
2017-12-09 19:02:02,173 -> 02.Indexing centers,5.61,251084,50.0,21
2017-12-09 19:02:02,181 -> 1024
2017-12-09 19:02:02,187 -> 1024
2017-12-09 19:02:13,386 -> 03.Joining datasets,11.32,251080,50.0,21
Done!!! Sat Dec  9 19:02:13 PST 2017
acald013@dblab-rack12: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack11: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack14: stopping org.apache.spark.deploy.worker.Worker
stopping org.apache.spark.deploy.master.Master
starting org.apache.spark.deploy.master.Master, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.master.Master-1-dblab-rack11.cs.ucr.edu.out
acald013@dblab-rack12: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack12.out
acald013@dblab-rack15: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack15.out
acald013@dblab-rack14: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack14.cs.ucr.edu.out
acald013@dblab-rack11: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack11.cs.ucr.edu.out
Running iteration 1/5 for 28 cores...
2017-12-09 19:02:21,874 -> Starting session,1.71,0
2017-12-09 19:02:21,874 -> Setting variables,0.00,0
2017-12-09 19:02:28,884 -> Reading datasets,7.01,0
2017-12-09 19:02:28,901 -> Points partitions: 2
2017-12-09 19:02:28,911 -> Centers partitions: 2
2017-12-09 19:02:35,122 -> 01.Indexing points,6.17,39429,50.0,28
2017-12-09 19:02:41,225 -> 02.Indexing centers,6.10,251084,50.0,28
2017-12-09 19:02:41,233 -> 1024
2017-12-09 19:02:41,240 -> 1024
2017-12-09 19:02:51,481 -> 03.Joining datasets,10.24,251080,50.0,28
Done!!! Sat Dec  9 19:02:52 PST 2017
Running iteration 2/5 for 28 cores...
2017-12-09 19:02:54,403 -> Starting session,1.65,0
2017-12-09 19:02:54,403 -> Setting variables,0.00,0
2017-12-09 19:02:59,296 -> Reading datasets,4.89,0
2017-12-09 19:02:59,307 -> Points partitions: 2
2017-12-09 19:02:59,314 -> Centers partitions: 2
2017-12-09 19:03:08,394 -> 01.Indexing points,9.04,39429,50.0,28
2017-12-09 19:03:14,272 -> 02.Indexing centers,5.88,251084,50.0,28
2017-12-09 19:03:14,289 -> 1024
2017-12-09 19:03:14,299 -> 1024
2017-12-09 19:03:25,224 -> 03.Joining datasets,10.93,251080,50.0,28
Done!!! Sat Dec  9 19:03:25 PST 2017
Running iteration 3/5 for 28 cores...
2017-12-09 19:03:28,109 -> Starting session,1.58,0
2017-12-09 19:03:28,109 -> Setting variables,0.00,0
2017-12-09 19:03:34,045 -> Reading datasets,5.94,0
2017-12-09 19:03:34,067 -> Points partitions: 2
2017-12-09 19:03:34,080 -> Centers partitions: 2
2017-12-09 19:03:42,612 -> 01.Indexing points,8.47,39429,50.0,28
2017-12-09 19:03:48,567 -> 02.Indexing centers,5.95,251084,50.0,28
2017-12-09 19:03:48,578 -> 1024
2017-12-09 19:03:48,586 -> 1024
2017-12-09 19:03:59,347 -> 03.Joining datasets,10.76,251080,50.0,28
Done!!! Sat Dec  9 19:04:00 PST 2017
Running iteration 4/5 for 28 cores...
2017-12-09 19:04:03,015 -> Starting session,1.63,0
2017-12-09 19:04:03,016 -> Setting variables,0.00,0
2017-12-09 19:04:10,354 -> Reading datasets,7.34,0
2017-12-09 19:04:10,378 -> Points partitions: 2
2017-12-09 19:04:10,395 -> Centers partitions: 2
2017-12-09 19:04:17,572 -> 01.Indexing points,7.12,39429,50.0,28
2017-12-09 19:04:25,246 -> 02.Indexing centers,7.67,251084,50.0,28
2017-12-09 19:04:25,257 -> 1024
2017-12-09 19:04:25,266 -> 1024
2017-12-09 19:04:35,216 -> 03.Joining datasets,9.95,251080,50.0,28
Done!!! Sat Dec  9 19:04:35 PST 2017
Running iteration 5/5 for 28 cores...
2017-12-09 19:04:38,001 -> Starting session,1.56,0
2017-12-09 19:04:38,002 -> Setting variables,0.00,0
2017-12-09 19:04:44,987 -> Reading datasets,6.99,0
2017-12-09 19:04:45,004 -> Points partitions: 2
2017-12-09 19:04:45,015 -> Centers partitions: 2
2017-12-09 19:04:52,279 -> 01.Indexing points,7.21,39429,50.0,28
2017-12-09 19:04:58,571 -> 02.Indexing centers,6.29,251084,50.0,28
2017-12-09 19:04:58,580 -> 1024
2017-12-09 19:04:58,589 -> 1024
2017-12-09 19:05:09,322 -> 03.Joining datasets,10.73,251080,50.0,28
Done!!! Sat Dec  9 19:05:10 PST 2017
acald013@dblab-rack12: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack15: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack11: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack14: stopping org.apache.spark.deploy.worker.Worker
stopping org.apache.spark.deploy.master.Master
Done!!!
acald013@dblab-rack12: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack15: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack14: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack11: no org.apache.spark.deploy.worker.Worker to stop
no org.apache.spark.deploy.master.Master to stop
starting org.apache.spark.deploy.master.Master, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.master.Master-1-dblab-rack11.cs.ucr.edu.out
acald013@dblab-rack14: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack14.cs.ucr.edu.out
Running iteration 1/5 for 7 cores...
2017-12-09 19:05:18,556 -> Starting session,1.43,0
2017-12-09 19:05:18,556 -> Setting variables,0.00,0
2017-12-09 19:05:22,868 -> Reading datasets,4.31,0
2017-12-09 19:05:22,884 -> Points partitions: 2
2017-12-09 19:05:22,896 -> Centers partitions: 2
2017-12-09 19:05:29,606 -> 01.Indexing points,6.67,19715,50.0,7
2017-12-09 19:05:35,229 -> 02.Indexing centers,5.62,125542,50.0,7
2017-12-09 19:05:35,242 -> 992
2017-12-09 19:05:35,251 -> 1024
2017-12-09 19:05:50,717 -> 03.Joining datasets,15.47,125540,50.0,7
Done!!! Sat Dec  9 19:05:51 PST 2017
Running iteration 2/5 for 7 cores...
2017-12-09 19:05:53,475 -> Starting session,1.57,0
2017-12-09 19:05:53,475 -> Setting variables,0.00,0
2017-12-09 19:05:57,592 -> Reading datasets,4.12,0
2017-12-09 19:05:57,604 -> Points partitions: 2
2017-12-09 19:05:57,615 -> Centers partitions: 2
2017-12-09 19:06:04,506 -> 01.Indexing points,6.85,19715,50.0,7
2017-12-09 19:06:10,008 -> 02.Indexing centers,5.50,125542,50.0,7
2017-12-09 19:06:10,020 -> 992
2017-12-09 19:06:10,028 -> 1024
2017-12-09 19:06:25,483 -> 03.Joining datasets,15.45,125540,50.0,7
Done!!! Sat Dec  9 19:06:25 PST 2017
Running iteration 3/5 for 7 cores...
2017-12-09 19:06:28,133 -> Starting session,1.56,0
2017-12-09 19:06:28,134 -> Setting variables,0.00,0
2017-12-09 19:06:32,451 -> Reading datasets,4.32,0
2017-12-09 19:06:32,467 -> Points partitions: 2
2017-12-09 19:06:32,476 -> Centers partitions: 2
2017-12-09 19:06:39,080 -> 01.Indexing points,6.57,19715,50.0,7
2017-12-09 19:06:44,342 -> 02.Indexing centers,5.26,125542,50.0,7
2017-12-09 19:06:44,351 -> 992
2017-12-09 19:06:44,358 -> 1024
2017-12-09 19:06:59,827 -> 03.Joining datasets,15.47,125540,50.0,7
Done!!! Sat Dec  9 19:07:00 PST 2017
Running iteration 4/5 for 7 cores...
2017-12-09 19:07:02,575 -> Starting session,1.58,0
2017-12-09 19:07:02,576 -> Setting variables,0.00,0
2017-12-09 19:07:06,714 -> Reading datasets,4.14,0
2017-12-09 19:07:06,731 -> Points partitions: 2
2017-12-09 19:07:06,744 -> Centers partitions: 2
2017-12-09 19:07:13,472 -> 01.Indexing points,6.68,19715,50.0,7
2017-12-09 19:07:18,950 -> 02.Indexing centers,5.48,125542,50.0,7
2017-12-09 19:07:18,963 -> 992
2017-12-09 19:07:18,972 -> 1024
2017-12-09 19:07:34,506 -> 03.Joining datasets,15.53,125540,50.0,7
Done!!! Sat Dec  9 19:07:34 PST 2017
Running iteration 5/5 for 7 cores...
2017-12-09 19:07:37,408 -> Starting session,1.72,0
2017-12-09 19:07:37,408 -> Setting variables,0.00,0
2017-12-09 19:07:41,637 -> Reading datasets,4.23,0
2017-12-09 19:07:41,651 -> Points partitions: 2
2017-12-09 19:07:41,661 -> Centers partitions: 2
2017-12-09 19:07:48,297 -> 01.Indexing points,6.59,19715,50.0,7
2017-12-09 19:07:53,626 -> 02.Indexing centers,5.33,125542,50.0,7
2017-12-09 19:07:53,640 -> 992
2017-12-09 19:07:53,651 -> 1024
2017-12-09 19:08:08,956 -> 03.Joining datasets,15.30,125540,50.0,7
Done!!! Sat Dec  9 19:08:09 PST 2017
acald013@dblab-rack14: stopping org.apache.spark.deploy.worker.Worker
stopping org.apache.spark.deploy.master.Master
starting org.apache.spark.deploy.master.Master, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.master.Master-1-dblab-rack11.cs.ucr.edu.out
acald013@dblab-rack12: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack12.out
acald013@dblab-rack11: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack11.cs.ucr.edu.out
Running iteration 1/5 for 14 cores...
2017-12-09 19:08:17,434 -> Starting session,1.72,0
2017-12-09 19:08:17,435 -> Setting variables,0.00,0
2017-12-09 19:08:22,097 -> Reading datasets,4.66,0
2017-12-09 19:08:22,111 -> Points partitions: 2
2017-12-09 19:08:22,122 -> Centers partitions: 2
2017-12-09 19:08:29,261 -> 01.Indexing points,7.09,19715,50.0,14
2017-12-09 19:08:34,724 -> 02.Indexing centers,5.46,125542,50.0,14
2017-12-09 19:08:34,732 -> 992
2017-12-09 19:08:34,738 -> 1024
2017-12-09 19:08:47,871 -> 03.Joining datasets,13.27,125540,50.0,14
Done!!! Sat Dec  9 19:08:48 PST 2017
Running iteration 2/5 for 14 cores...
2017-12-09 19:08:50,693 -> Starting session,1.59,0
2017-12-09 19:08:50,693 -> Setting variables,0.00,0
2017-12-09 19:08:55,509 -> Reading datasets,4.82,0
2017-12-09 19:08:55,523 -> Points partitions: 2
2017-12-09 19:08:55,533 -> Centers partitions: 2
2017-12-09 19:09:02,306 -> 01.Indexing points,6.74,19715,50.0,14
2017-12-09 19:09:07,324 -> 02.Indexing centers,5.02,125542,50.0,14
2017-12-09 19:09:07,334 -> 992
2017-12-09 19:09:07,342 -> 1024
2017-12-09 19:09:20,393 -> 03.Joining datasets,13.05,125540,50.0,14
Done!!! Sat Dec  9 19:09:20 PST 2017
Running iteration 3/5 for 14 cores...
2017-12-09 19:09:23,164 -> Starting session,1.55,0
2017-12-09 19:09:23,165 -> Setting variables,0.00,0
2017-12-09 19:09:28,076 -> Reading datasets,4.91,0
2017-12-09 19:09:28,086 -> Points partitions: 2
2017-12-09 19:09:28,094 -> Centers partitions: 2
2017-12-09 19:09:34,813 -> 01.Indexing points,6.68,19715,50.0,14
2017-12-09 19:09:40,172 -> 02.Indexing centers,5.36,125542,50.0,14
2017-12-09 19:09:40,180 -> 992
2017-12-09 19:09:40,185 -> 1024
2017-12-09 19:09:52,546 -> 03.Joining datasets,12.36,125540,50.0,14
Done!!! Sat Dec  9 19:09:53 PST 2017
Running iteration 4/5 for 14 cores...
2017-12-09 19:09:55,406 -> Starting session,1.62,0
2017-12-09 19:09:55,406 -> Setting variables,0.00,0
2017-12-09 19:09:59,979 -> Reading datasets,4.57,0
2017-12-09 19:09:59,992 -> Points partitions: 2
2017-12-09 19:10:00,004 -> Centers partitions: 2
2017-12-09 19:10:07,202 -> 01.Indexing points,7.15,19715,50.0,14
2017-12-09 19:10:12,541 -> 02.Indexing centers,5.34,125542,50.0,14
2017-12-09 19:10:12,549 -> 992
2017-12-09 19:10:12,555 -> 1024
2017-12-09 19:10:24,686 -> 03.Joining datasets,12.13,125540,50.0,14
Done!!! Sat Dec  9 19:10:25 PST 2017
Running iteration 5/5 for 14 cores...
2017-12-09 19:10:27,484 -> Starting session,1.57,0
2017-12-09 19:10:27,485 -> Setting variables,0.00,0
2017-12-09 19:10:32,208 -> Reading datasets,4.72,0
2017-12-09 19:10:32,218 -> Points partitions: 2
2017-12-09 19:10:32,227 -> Centers partitions: 2
2017-12-09 19:10:39,255 -> 01.Indexing points,6.99,19715,50.0,14
2017-12-09 19:10:44,388 -> 02.Indexing centers,5.13,125542,50.0,14
2017-12-09 19:10:44,396 -> 992
2017-12-09 19:10:44,401 -> 1024
2017-12-09 19:10:56,733 -> 03.Joining datasets,12.33,125540,50.0,14
Done!!! Sat Dec  9 19:10:57 PST 2017
acald013@dblab-rack12: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack11: stopping org.apache.spark.deploy.worker.Worker
stopping org.apache.spark.deploy.master.Master
starting org.apache.spark.deploy.master.Master, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.master.Master-1-dblab-rack11.cs.ucr.edu.out
acald013@dblab-rack12: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack12.out
acald013@dblab-rack14: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack14.cs.ucr.edu.out
acald013@dblab-rack11: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack11.cs.ucr.edu.out
Running iteration 1/5 for 21 cores...
2017-12-09 19:11:05,031 -> Starting session,1.55,0
2017-12-09 19:11:05,032 -> Setting variables,0.00,0
2017-12-09 19:11:10,184 -> Reading datasets,5.15,0
2017-12-09 19:11:10,201 -> Points partitions: 2
2017-12-09 19:11:10,213 -> Centers partitions: 2
2017-12-09 19:11:18,401 -> 01.Indexing points,8.14,19715,50.0,21
2017-12-09 19:11:23,090 -> 02.Indexing centers,4.69,125542,50.0,21
2017-12-09 19:11:23,101 -> 992
2017-12-09 19:11:23,111 -> 1024
2017-12-09 19:11:33,940 -> 03.Joining datasets,10.83,125540,50.0,21
Done!!! Sat Dec  9 19:11:34 PST 2017
Running iteration 2/5 for 21 cores...
2017-12-09 19:11:36,699 -> Starting session,1.50,0
2017-12-09 19:11:36,699 -> Setting variables,0.00,0
2017-12-09 19:11:41,457 -> Reading datasets,4.76,0
2017-12-09 19:11:41,470 -> Points partitions: 2
2017-12-09 19:11:41,480 -> Centers partitions: 2
2017-12-09 19:11:49,599 -> 01.Indexing points,8.07,19715,50.0,21
2017-12-09 19:11:55,406 -> 02.Indexing centers,4.93,125542,50.0,21
2017-12-09 19:11:55,417 -> 992
2017-12-09 19:11:55,427 -> 1024
2017-12-09 19:12:09,334 -> 03.Joining datasets,13.91,125540,50.0,21
Done!!! Sat Dec  9 19:12:09 PST 2017
Running iteration 3/5 for 21 cores...
2017-12-09 19:12:12,152 -> Starting session,1.62,0
2017-12-09 19:12:12,153 -> Setting variables,0.00,0
2017-12-09 19:12:17,993 -> Reading datasets,5.84,0
2017-12-09 19:12:18,013 -> Points partitions: 2
2017-12-09 19:12:18,023 -> Centers partitions: 2
2017-12-09 19:12:25,283 -> 01.Indexing points,7.22,19715,50.0,21
2017-12-09 19:12:30,804 -> 02.Indexing centers,5.52,125542,50.0,21
2017-12-09 19:12:30,813 -> 992
2017-12-09 19:12:30,819 -> 1024
2017-12-09 19:12:41,996 -> 03.Joining datasets,11.18,125540,50.0,21
Done!!! Sat Dec  9 19:12:42 PST 2017
Running iteration 4/5 for 21 cores...
2017-12-09 19:12:45,006 -> Starting session,1.85,0
2017-12-09 19:12:45,006 -> Setting variables,0.00,0
2017-12-09 19:12:51,068 -> Reading datasets,6.06,0
2017-12-09 19:12:51,087 -> Points partitions: 2
2017-12-09 19:12:51,098 -> Centers partitions: 2
2017-12-09 19:12:57,972 -> 01.Indexing points,6.82,19715,50.0,21
2017-12-09 19:13:02,941 -> 02.Indexing centers,4.97,125542,50.0,21
2017-12-09 19:13:02,952 -> 992
2017-12-09 19:13:02,960 -> 1024
2017-12-09 19:13:15,126 -> 03.Joining datasets,12.17,125540,50.0,21
Done!!! Sat Dec  9 19:13:15 PST 2017
Running iteration 5/5 for 21 cores...
2017-12-09 19:13:18,016 -> Starting session,1.66,0
2017-12-09 19:13:18,017 -> Setting variables,0.00,0
2017-12-09 19:13:23,620 -> Reading datasets,5.60,0
2017-12-09 19:13:23,640 -> Points partitions: 2
2017-12-09 19:13:23,653 -> Centers partitions: 2
2017-12-09 19:13:29,161 -> 01.Indexing points,5.45,19715,50.0,21
2017-12-09 19:13:33,784 -> 02.Indexing centers,4.62,125542,50.0,21
2017-12-09 19:13:33,796 -> 992
2017-12-09 19:13:33,803 -> 1024
2017-12-09 19:13:43,504 -> 03.Joining datasets,9.70,125540,50.0,21
Done!!! Sat Dec  9 19:13:44 PST 2017
acald013@dblab-rack12: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack14: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack11: stopping org.apache.spark.deploy.worker.Worker
stopping org.apache.spark.deploy.master.Master
starting org.apache.spark.deploy.master.Master, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.master.Master-1-dblab-rack11.cs.ucr.edu.out
acald013@dblab-rack12: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack12.out
acald013@dblab-rack15: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack15.out
acald013@dblab-rack14: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack14.cs.ucr.edu.out
acald013@dblab-rack11: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack11.cs.ucr.edu.out
Running iteration 1/5 for 28 cores...
2017-12-09 19:13:52,050 -> Starting session,1.85,0
2017-12-09 19:13:52,052 -> Setting variables,0.00,0
2017-12-09 19:13:58,782 -> Reading datasets,6.73,0
2017-12-09 19:13:58,793 -> Points partitions: 2
2017-12-09 19:13:58,802 -> Centers partitions: 2
2017-12-09 19:14:05,201 -> 01.Indexing points,6.36,19715,50.0,28
2017-12-09 19:14:10,776 -> 02.Indexing centers,5.57,125542,50.0,28
2017-12-09 19:14:10,789 -> 992
2017-12-09 19:14:10,798 -> 1024
2017-12-09 19:14:23,036 -> 03.Joining datasets,12.24,125540,50.0,28
Done!!! Sat Dec  9 19:14:23 PST 2017
Running iteration 2/5 for 28 cores...
2017-12-09 19:14:25,901 -> Starting session,1.64,0
2017-12-09 19:14:25,901 -> Setting variables,0.00,0
2017-12-09 19:14:32,774 -> Reading datasets,6.87,0
2017-12-09 19:14:32,785 -> Points partitions: 2
2017-12-09 19:14:32,794 -> Centers partitions: 2
2017-12-09 19:14:41,059 -> 01.Indexing points,8.23,19715,50.0,28
2017-12-09 19:14:46,202 -> 02.Indexing centers,5.14,125542,50.0,28
2017-12-09 19:14:46,214 -> 992
2017-12-09 19:14:46,223 -> 1024
2017-12-09 19:14:56,325 -> 03.Joining datasets,10.10,125540,50.0,28
Done!!! Sat Dec  9 19:14:56 PST 2017
Running iteration 3/5 for 28 cores...
2017-12-09 19:14:59,166 -> Starting session,1.55,0
2017-12-09 19:14:59,167 -> Setting variables,0.00,0
2017-12-09 19:15:05,351 -> Reading datasets,6.18,0
2017-12-09 19:15:05,370 -> Points partitions: 2
2017-12-09 19:15:05,380 -> Centers partitions: 2
2017-12-09 19:15:12,367 -> 01.Indexing points,6.94,19715,50.0,28
2017-12-09 19:15:17,773 -> 02.Indexing centers,5.40,125542,50.0,28
2017-12-09 19:15:17,781 -> 992
2017-12-09 19:15:17,787 -> 1024
2017-12-09 19:15:29,001 -> 03.Joining datasets,11.21,125540,50.0,28
Done!!! Sat Dec  9 19:15:29 PST 2017
Running iteration 4/5 for 28 cores...
2017-12-09 19:15:31,787 -> Starting session,1.53,0
2017-12-09 19:15:31,788 -> Setting variables,0.00,0
2017-12-09 19:15:36,645 -> Reading datasets,4.86,0
2017-12-09 19:15:36,656 -> Points partitions: 2
2017-12-09 19:15:36,663 -> Centers partitions: 2
2017-12-09 19:15:46,537 -> 01.Indexing points,9.84,19715,50.0,28
2017-12-09 19:15:52,717 -> 02.Indexing centers,6.18,125542,50.0,28
2017-12-09 19:15:52,729 -> 992
2017-12-09 19:15:52,738 -> 1024
2017-12-09 19:16:04,557 -> 03.Joining datasets,11.82,125540,50.0,28
Done!!! Sat Dec  9 19:16:05 PST 2017
Running iteration 5/5 for 28 cores...
2017-12-09 19:16:07,264 -> Starting session,1.57,0
2017-12-09 19:16:07,265 -> Setting variables,0.00,0
2017-12-09 19:16:13,384 -> Reading datasets,6.12,0
2017-12-09 19:16:13,410 -> Points partitions: 2
2017-12-09 19:16:13,425 -> Centers partitions: 2
2017-12-09 19:16:22,682 -> 01.Indexing points,9.21,19715,50.0,28
2017-12-09 19:16:28,193 -> 02.Indexing centers,5.51,125542,50.0,28
2017-12-09 19:16:28,203 -> 992
2017-12-09 19:16:28,210 -> 1024
2017-12-09 19:16:40,232 -> 03.Joining datasets,12.02,125540,50.0,28
Done!!! Sat Dec  9 19:16:40 PST 2017
acald013@dblab-rack12: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack15: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack11: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack14: stopping org.apache.spark.deploy.worker.Worker
stopping org.apache.spark.deploy.master.Master
Done!!!
acald013@dblab-rack12: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack15: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack14: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack11: no org.apache.spark.deploy.worker.Worker to stop
no org.apache.spark.deploy.master.Master to stop
starting org.apache.spark.deploy.master.Master, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.master.Master-1-dblab-rack11.cs.ucr.edu.out
acald013@dblab-rack14: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack14.cs.ucr.edu.out
Running iteration 1/5 for 7 cores...
2017-12-09 19:16:48,467 -> Starting session,1.43,0
2017-12-09 19:16:48,467 -> Setting variables,0.00,0
2017-12-09 19:16:52,965 -> Reading datasets,4.50,0
2017-12-09 19:16:52,979 -> Points partitions: 2
2017-12-09 19:16:52,991 -> Centers partitions: 2
2017-12-09 19:17:00,447 -> 01.Indexing points,7.41,78857,40.0,7
2017-12-09 19:17:07,877 -> 02.Indexing centers,7.43,395352,40.0,7
2017-12-09 19:17:07,889 -> 1024
2017-12-09 19:17:07,897 -> 1024
2017-12-09 19:17:28,476 -> 03.Joining datasets,20.58,395346,40.0,7
Done!!! Sat Dec  9 19:17:28 PST 2017
Running iteration 2/5 for 7 cores...
2017-12-09 19:17:31,116 -> Starting session,1.51,0
2017-12-09 19:17:31,117 -> Setting variables,0.00,0
2017-12-09 19:17:35,386 -> Reading datasets,4.27,0
2017-12-09 19:17:35,401 -> Points partitions: 2
2017-12-09 19:17:35,411 -> Centers partitions: 2
2017-12-09 19:17:42,836 -> 01.Indexing points,7.39,78857,40.0,7
2017-12-09 19:17:50,002 -> 02.Indexing centers,7.21,395352,40.0,7
2017-12-09 19:17:50,012 -> 1024
2017-12-09 19:17:50,020 -> 1024
2017-12-09 19:18:10,664 -> 03.Joining datasets,20.64,395346,40.0,7
Done!!! Sat Dec  9 19:18:11 PST 2017
Running iteration 3/5 for 7 cores...
2017-12-09 19:18:13,384 -> Starting session,1.54,0
2017-12-09 19:18:13,384 -> Setting variables,0.00,0
2017-12-09 19:18:17,800 -> Reading datasets,4.41,0
2017-12-09 19:18:17,813 -> Points partitions: 2
2017-12-09 19:18:17,822 -> Centers partitions: 2
2017-12-09 19:18:25,200 -> 01.Indexing points,7.34,78857,40.0,7
2017-12-09 19:18:32,244 -> 02.Indexing centers,7.04,395352,40.0,7
2017-12-09 19:18:32,253 -> 1024
2017-12-09 19:18:32,259 -> 1024
2017-12-09 19:18:52,840 -> 03.Joining datasets,20.58,395346,40.0,7
Done!!! Sat Dec  9 19:18:53 PST 2017
Running iteration 4/5 for 7 cores...
2017-12-09 19:18:55,705 -> Starting session,1.63,0
2017-12-09 19:18:55,705 -> Setting variables,0.00,0
2017-12-09 19:19:00,173 -> Reading datasets,4.47,0
2017-12-09 19:19:00,189 -> Points partitions: 2
2017-12-09 19:19:00,201 -> Centers partitions: 2
2017-12-09 19:19:08,075 -> 01.Indexing points,7.83,78857,40.0,7
2017-12-09 19:19:15,405 -> 02.Indexing centers,7.33,395352,40.0,7
2017-12-09 19:19:15,414 -> 1024
2017-12-09 19:19:15,421 -> 1024
2017-12-09 19:19:37,262 -> 03.Joining datasets,21.84,395346,40.0,7
Done!!! Sat Dec  9 19:19:37 PST 2017
Running iteration 5/5 for 7 cores...
2017-12-09 19:19:39,986 -> Starting session,1.52,0
2017-12-09 19:19:39,987 -> Setting variables,0.00,0
2017-12-09 19:19:44,477 -> Reading datasets,4.49,0
2017-12-09 19:19:44,492 -> Points partitions: 2
2017-12-09 19:19:44,501 -> Centers partitions: 2
2017-12-09 19:19:52,284 -> 01.Indexing points,7.74,78857,40.0,7
2017-12-09 19:19:59,782 -> 02.Indexing centers,7.50,395352,40.0,7
2017-12-09 19:19:59,795 -> 1024
2017-12-09 19:19:59,804 -> 1024
2017-12-09 19:20:20,545 -> 03.Joining datasets,20.74,395346,40.0,7
Done!!! Sat Dec  9 19:20:21 PST 2017
acald013@dblab-rack14: stopping org.apache.spark.deploy.worker.Worker
stopping org.apache.spark.deploy.master.Master
starting org.apache.spark.deploy.master.Master, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.master.Master-1-dblab-rack11.cs.ucr.edu.out
acald013@dblab-rack12: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack12.out
acald013@dblab-rack11: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack11.cs.ucr.edu.out
Running iteration 1/5 for 14 cores...
2017-12-09 19:20:28,842 -> Starting session,1.65,0
2017-12-09 19:20:28,843 -> Setting variables,0.00,0
2017-12-09 19:20:33,766 -> Reading datasets,4.92,0
2017-12-09 19:20:33,778 -> Points partitions: 2
2017-12-09 19:20:33,788 -> Centers partitions: 2
2017-12-09 19:20:41,427 -> 01.Indexing points,7.60,78857,40.0,14
2017-12-09 19:20:48,858 -> 02.Indexing centers,7.43,395352,40.0,14
2017-12-09 19:20:48,869 -> 1024
2017-12-09 19:20:48,876 -> 1024
2017-12-09 19:21:05,630 -> 03.Joining datasets,16.75,395346,40.0,14
Done!!! Sat Dec  9 19:21:06 PST 2017
Running iteration 2/5 for 14 cores...
2017-12-09 19:21:08,501 -> Starting session,1.62,0
2017-12-09 19:21:08,502 -> Setting variables,0.00,0
2017-12-09 19:21:13,732 -> Reading datasets,5.23,0
2017-12-09 19:21:13,744 -> Points partitions: 2
2017-12-09 19:21:13,752 -> Centers partitions: 2
2017-12-09 19:21:21,509 -> 01.Indexing points,7.72,78857,40.0,14
2017-12-09 19:21:28,996 -> 02.Indexing centers,7.49,395352,40.0,14
2017-12-09 19:21:29,008 -> 1024
2017-12-09 19:21:29,017 -> 1024
2017-12-09 19:21:46,701 -> 03.Joining datasets,17.68,395346,40.0,14
Done!!! Sat Dec  9 19:21:47 PST 2017
Running iteration 3/5 for 14 cores...
2017-12-09 19:21:49,635 -> Starting session,1.74,0
2017-12-09 19:21:49,635 -> Setting variables,0.00,0
2017-12-09 19:21:54,692 -> Reading datasets,5.06,0
2017-12-09 19:21:54,704 -> Points partitions: 2
2017-12-09 19:21:54,713 -> Centers partitions: 2
2017-12-09 19:22:02,423 -> 01.Indexing points,7.67,78857,40.0,14
2017-12-09 19:22:09,933 -> 02.Indexing centers,7.51,395352,40.0,14
2017-12-09 19:22:09,947 -> 1024
2017-12-09 19:22:09,960 -> 1024
2017-12-09 19:22:27,085 -> 03.Joining datasets,17.12,395346,40.0,14
Done!!! Sat Dec  9 19:22:27 PST 2017
Running iteration 4/5 for 14 cores...
2017-12-09 19:22:29,940 -> Starting session,1.65,0
2017-12-09 19:22:29,940 -> Setting variables,0.00,0
2017-12-09 19:22:34,915 -> Reading datasets,4.97,0
2017-12-09 19:22:34,929 -> Points partitions: 2
2017-12-09 19:22:34,939 -> Centers partitions: 2
2017-12-09 19:22:42,483 -> 01.Indexing points,7.50,78857,40.0,14
2017-12-09 19:22:49,705 -> 02.Indexing centers,7.22,395352,40.0,14
2017-12-09 19:22:49,713 -> 1024
2017-12-09 19:22:49,719 -> 1024
2017-12-09 19:23:05,855 -> 03.Joining datasets,16.14,395346,40.0,14
Done!!! Sat Dec  9 19:23:06 PST 2017
Running iteration 5/5 for 14 cores...
2017-12-09 19:23:08,683 -> Starting session,1.64,0
2017-12-09 19:23:08,684 -> Setting variables,0.00,0
2017-12-09 19:23:13,552 -> Reading datasets,4.87,0
2017-12-09 19:23:13,566 -> Points partitions: 2
2017-12-09 19:23:13,575 -> Centers partitions: 2
2017-12-09 19:23:21,403 -> 01.Indexing points,7.79,78857,40.0,14
2017-12-09 19:23:29,021 -> 02.Indexing centers,7.62,395352,40.0,14
2017-12-09 19:23:29,029 -> 1024
2017-12-09 19:23:29,037 -> 1024
2017-12-09 19:23:46,227 -> 03.Joining datasets,17.19,395346,40.0,14
Done!!! Sat Dec  9 19:23:46 PST 2017
acald013@dblab-rack12: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack11: stopping org.apache.spark.deploy.worker.Worker
stopping org.apache.spark.deploy.master.Master
starting org.apache.spark.deploy.master.Master, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.master.Master-1-dblab-rack11.cs.ucr.edu.out
acald013@dblab-rack12: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack12.out
acald013@dblab-rack14: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack14.cs.ucr.edu.out
acald013@dblab-rack11: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack11.cs.ucr.edu.out
Running iteration 1/5 for 21 cores...
2017-12-09 19:23:54,665 -> Starting session,1.87,0
2017-12-09 19:23:54,666 -> Setting variables,0.00,0
2017-12-09 19:23:59,742 -> Reading datasets,5.08,0
2017-12-09 19:23:59,753 -> Points partitions: 2
2017-12-09 19:23:59,761 -> Centers partitions: 2
2017-12-09 19:24:07,570 -> 01.Indexing points,7.66,78857,40.0,21
2017-12-09 19:24:14,690 -> 02.Indexing centers,7.12,395352,40.0,21
2017-12-09 19:24:14,698 -> 1024
2017-12-09 19:24:14,704 -> 1024
2017-12-09 19:24:27,962 -> 03.Joining datasets,13.32,395346,40.0,21
Done!!! Sat Dec  9 19:24:28 PST 2017
Running iteration 2/5 for 21 cores...
2017-12-09 19:24:30,631 -> Starting session,1.55,0
2017-12-09 19:24:30,632 -> Setting variables,0.00,0
2017-12-09 19:24:36,496 -> Reading datasets,5.86,0
2017-12-09 19:24:36,510 -> Points partitions: 2
2017-12-09 19:24:36,520 -> Centers partitions: 2
2017-12-09 19:24:43,325 -> 01.Indexing points,6.76,78857,40.0,21
2017-12-09 19:24:49,989 -> 02.Indexing centers,6.66,395352,40.0,21
2017-12-09 19:24:50,001 -> 1024
2017-12-09 19:24:50,010 -> 1024
2017-12-09 19:25:02,739 -> 03.Joining datasets,12.73,395346,40.0,21
Done!!! Sat Dec  9 19:25:03 PST 2017
Running iteration 3/5 for 21 cores...
2017-12-09 19:25:05,681 -> Starting session,1.73,0
2017-12-09 19:25:05,681 -> Setting variables,0.00,0
2017-12-09 19:25:11,630 -> Reading datasets,5.95,0
2017-12-09 19:25:11,655 -> Points partitions: 2
2017-12-09 19:25:11,672 -> Centers partitions: 2
2017-12-09 19:25:18,438 -> 01.Indexing points,6.71,78857,40.0,21
2017-12-09 19:25:24,823 -> 02.Indexing centers,6.38,395352,40.0,21
2017-12-09 19:25:24,830 -> 1024
2017-12-09 19:25:24,836 -> 1024
2017-12-09 19:25:37,542 -> 03.Joining datasets,12.71,395346,40.0,21
Done!!! Sat Dec  9 19:25:38 PST 2017
Running iteration 4/5 for 21 cores...
2017-12-09 19:25:40,390 -> Starting session,1.61,0
2017-12-09 19:25:40,391 -> Setting variables,0.00,0
2017-12-09 19:25:46,334 -> Reading datasets,6.02,0
2017-12-09 19:25:46,351 -> Points partitions: 2
2017-12-09 19:25:46,362 -> Centers partitions: 2
2017-12-09 19:25:53,348 -> 01.Indexing points,6.94,78857,40.0,21
2017-12-09 19:25:59,854 -> 02.Indexing centers,6.50,395352,40.0,21
2017-12-09 19:25:59,862 -> 1024
2017-12-09 19:25:59,868 -> 1024
2017-12-09 19:26:12,825 -> 03.Joining datasets,12.96,395346,40.0,21
Done!!! Sat Dec  9 19:26:13 PST 2017
Running iteration 5/5 for 21 cores...
2017-12-09 19:26:15,741 -> Starting session,1.67,0
2017-12-09 19:26:15,742 -> Setting variables,0.00,0
2017-12-09 19:26:21,639 -> Reading datasets,5.90,0
2017-12-09 19:26:21,660 -> Points partitions: 2
2017-12-09 19:26:21,673 -> Centers partitions: 2
2017-12-09 19:26:29,294 -> 01.Indexing points,7.54,78857,40.0,21
2017-12-09 19:26:36,222 -> 02.Indexing centers,6.93,395352,40.0,21
2017-12-09 19:26:36,234 -> 1024
2017-12-09 19:26:36,243 -> 1024
2017-12-09 19:26:49,806 -> 03.Joining datasets,13.56,395346,40.0,21
Done!!! Sat Dec  9 19:26:51 PST 2017
acald013@dblab-rack12: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack14: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack11: stopping org.apache.spark.deploy.worker.Worker
stopping org.apache.spark.deploy.master.Master
starting org.apache.spark.deploy.master.Master, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.master.Master-1-dblab-rack11.cs.ucr.edu.out
acald013@dblab-rack12: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack12.out
acald013@dblab-rack15: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack15.out
acald013@dblab-rack14: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack14.cs.ucr.edu.out
acald013@dblab-rack11: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack11.cs.ucr.edu.out
Running iteration 1/5 for 28 cores...
2017-12-09 19:26:59,117 -> Starting session,1.69,0
2017-12-09 19:26:59,117 -> Setting variables,0.00,0
2017-12-09 19:27:06,238 -> Reading datasets,7.12,0
2017-12-09 19:27:06,266 -> Points partitions: 2
2017-12-09 19:27:06,282 -> Centers partitions: 2
2017-12-09 19:27:14,100 -> 01.Indexing points,7.77,78857,40.0,28
2017-12-09 19:27:20,293 -> 02.Indexing centers,6.19,395352,40.0,28
2017-12-09 19:27:20,304 -> 1024
2017-12-09 19:27:20,313 -> 1024
2017-12-09 19:27:32,877 -> 03.Joining datasets,12.56,395346,40.0,28
Done!!! Sat Dec  9 19:27:33 PST 2017
Running iteration 2/5 for 28 cores...
2017-12-09 19:27:35,802 -> Starting session,1.68,0
2017-12-09 19:27:35,802 -> Setting variables,0.00,0
2017-12-09 19:27:40,832 -> Reading datasets,5.03,0
2017-12-09 19:27:40,843 -> Points partitions: 2
2017-12-09 19:27:40,850 -> Centers partitions: 2
2017-12-09 19:27:51,282 -> 01.Indexing points,10.39,78857,40.0,28
2017-12-09 19:28:00,942 -> 02.Indexing centers,9.66,395352,40.0,28
2017-12-09 19:28:00,949 -> 1024
2017-12-09 19:28:00,955 -> 1024
2017-12-09 19:28:12,665 -> 03.Joining datasets,11.71,395346,40.0,28
Done!!! Sat Dec  9 19:28:13 PST 2017
Running iteration 3/5 for 28 cores...
2017-12-09 19:28:15,435 -> Starting session,1.55,0
2017-12-09 19:28:15,438 -> Setting variables,0.00,0
2017-12-09 19:28:20,569 -> Reading datasets,5.13,0
2017-12-09 19:28:20,586 -> Points partitions: 2
2017-12-09 19:28:20,598 -> Centers partitions: 2
2017-12-09 19:28:30,860 -> 01.Indexing points,10.22,78857,40.0,28
2017-12-09 19:28:39,408 -> 02.Indexing centers,8.55,395352,40.0,28
2017-12-09 19:28:39,419 -> 1024
2017-12-09 19:28:39,426 -> 1024
2017-12-09 19:28:50,799 -> 03.Joining datasets,11.37,395346,40.0,28
Done!!! Sat Dec  9 19:28:51 PST 2017
Running iteration 4/5 for 28 cores...
2017-12-09 19:28:53,565 -> Starting session,1.53,0
2017-12-09 19:28:53,565 -> Setting variables,0.00,0
2017-12-09 19:29:00,790 -> Reading datasets,7.22,0
2017-12-09 19:29:00,812 -> Points partitions: 2
2017-12-09 19:29:00,825 -> Centers partitions: 2
2017-12-09 19:29:08,508 -> 01.Indexing points,7.63,78857,40.0,28
2017-12-09 19:29:15,510 -> 02.Indexing centers,7.00,395352,40.0,28
2017-12-09 19:29:15,520 -> 1024
2017-12-09 19:29:15,527 -> 1024
2017-12-09 19:29:26,944 -> 03.Joining datasets,11.42,395346,40.0,28
Done!!! Sat Dec  9 19:29:27 PST 2017
Running iteration 5/5 for 28 cores...
2017-12-09 19:29:29,653 -> Starting session,1.58,0
2017-12-09 19:29:29,654 -> Setting variables,0.00,0
2017-12-09 19:29:36,940 -> Reading datasets,7.29,0
2017-12-09 19:29:36,954 -> Points partitions: 2
2017-12-09 19:29:36,965 -> Centers partitions: 2
2017-12-09 19:29:45,254 -> 01.Indexing points,8.24,78857,40.0,28
2017-12-09 19:29:54,505 -> 02.Indexing centers,9.25,395352,40.0,28
2017-12-09 19:29:54,514 -> 1024
2017-12-09 19:29:54,520 -> 1024
2017-12-09 19:30:06,278 -> 03.Joining datasets,11.76,395346,40.0,28
Done!!! Sat Dec  9 19:30:06 PST 2017
acald013@dblab-rack12: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack15: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack11: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack14: stopping org.apache.spark.deploy.worker.Worker
stopping org.apache.spark.deploy.master.Master
Done!!!
acald013@dblab-rack12: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack15: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack14: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack11: no org.apache.spark.deploy.worker.Worker to stop
no org.apache.spark.deploy.master.Master to stop
starting org.apache.spark.deploy.master.Master, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.master.Master-1-dblab-rack11.cs.ucr.edu.out
acald013@dblab-rack14: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack14.cs.ucr.edu.out
Running iteration 1/5 for 7 cores...
2017-12-09 19:30:14,789 -> Starting session,1.56,0
2017-12-09 19:30:14,790 -> Setting variables,0.00,0
2017-12-09 19:30:18,992 -> Reading datasets,4.20,0
2017-12-09 19:30:19,010 -> Points partitions: 2
2017-12-09 19:30:19,021 -> Centers partitions: 2
2017-12-09 19:30:26,131 -> 01.Indexing points,7.07,59143,40.0,7
2017-12-09 19:30:32,615 -> 02.Indexing centers,6.48,296514,40.0,7
2017-12-09 19:30:32,627 -> 1024
2017-12-09 19:30:32,635 -> 1024
2017-12-09 19:30:51,776 -> 03.Joining datasets,19.14,296510,40.0,7
Done!!! Sat Dec  9 19:30:52 PST 2017
Running iteration 2/5 for 7 cores...
2017-12-09 19:30:54,500 -> Starting session,1.53,0
2017-12-09 19:30:54,501 -> Setting variables,0.00,0
2017-12-09 19:30:58,797 -> Reading datasets,4.30,0
2017-12-09 19:30:58,808 -> Points partitions: 2
2017-12-09 19:30:58,815 -> Centers partitions: 2
2017-12-09 19:31:06,153 -> 01.Indexing points,7.27,59143,40.0,7
2017-12-09 19:31:12,665 -> 02.Indexing centers,6.51,296514,40.0,7
2017-12-09 19:31:12,675 -> 1024
2017-12-09 19:31:12,682 -> 1024
2017-12-09 19:31:31,862 -> 03.Joining datasets,19.18,296510,40.0,7
Done!!! Sat Dec  9 19:31:32 PST 2017
Running iteration 3/5 for 7 cores...
2017-12-09 19:31:34,576 -> Starting session,1.57,0
2017-12-09 19:31:34,576 -> Setting variables,0.00,0
2017-12-09 19:31:38,884 -> Reading datasets,4.31,0
2017-12-09 19:31:38,895 -> Points partitions: 2
2017-12-09 19:31:38,902 -> Centers partitions: 2
2017-12-09 19:31:46,291 -> 01.Indexing points,7.35,59143,40.0,7
2017-12-09 19:31:52,629 -> 02.Indexing centers,6.34,296514,40.0,7
2017-12-09 19:31:52,642 -> 1024
2017-12-09 19:31:52,651 -> 1024
2017-12-09 19:32:12,417 -> 03.Joining datasets,19.77,296510,40.0,7
Done!!! Sat Dec  9 19:32:12 PST 2017
Running iteration 4/5 for 7 cores...
2017-12-09 19:32:15,038 -> Starting session,1.51,0
2017-12-09 19:32:15,039 -> Setting variables,0.00,0
2017-12-09 19:32:19,352 -> Reading datasets,4.31,0
2017-12-09 19:32:19,364 -> Points partitions: 2
2017-12-09 19:32:19,371 -> Centers partitions: 2
2017-12-09 19:32:26,505 -> 01.Indexing points,7.10,59143,40.0,7
2017-12-09 19:32:33,146 -> 02.Indexing centers,6.64,296514,40.0,7
2017-12-09 19:32:33,158 -> 1024
2017-12-09 19:32:33,167 -> 1024
2017-12-09 19:32:52,364 -> 03.Joining datasets,19.31,296510,40.0,7
Done!!! Sat Dec  9 19:32:52 PST 2017
Running iteration 5/5 for 7 cores...
2017-12-09 19:32:55,118 -> Starting session,1.56,0
2017-12-09 19:32:55,118 -> Setting variables,0.00,0
2017-12-09 19:32:59,397 -> Reading datasets,4.28,0
2017-12-09 19:32:59,414 -> Points partitions: 2
2017-12-09 19:32:59,426 -> Centers partitions: 2
2017-12-09 19:33:06,634 -> 01.Indexing points,7.17,59143,40.0,7
2017-12-09 19:33:13,185 -> 02.Indexing centers,6.55,296514,40.0,7
2017-12-09 19:33:13,196 -> 1024
2017-12-09 19:33:13,203 -> 1024
2017-12-09 19:33:32,307 -> 03.Joining datasets,19.10,296510,40.0,7
Done!!! Sat Dec  9 19:33:32 PST 2017
acald013@dblab-rack14: stopping org.apache.spark.deploy.worker.Worker
stopping org.apache.spark.deploy.master.Master
starting org.apache.spark.deploy.master.Master, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.master.Master-1-dblab-rack11.cs.ucr.edu.out
acald013@dblab-rack12: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack12.out
acald013@dblab-rack11: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack11.cs.ucr.edu.out
Running iteration 1/5 for 14 cores...
2017-12-09 19:33:40,688 -> Starting session,1.64,0
2017-12-09 19:33:40,689 -> Setting variables,0.00,0
2017-12-09 19:33:45,614 -> Reading datasets,4.92,0
2017-12-09 19:33:45,625 -> Points partitions: 2
2017-12-09 19:33:45,633 -> Centers partitions: 2
2017-12-09 19:33:52,707 -> 01.Indexing points,7.03,59143,40.0,14
2017-12-09 19:33:59,212 -> 02.Indexing centers,6.50,296514,40.0,14
2017-12-09 19:33:59,223 -> 1024
2017-12-09 19:33:59,233 -> 1024
2017-12-09 19:34:15,751 -> 03.Joining datasets,16.52,296510,40.0,14
Done!!! Sat Dec  9 19:34:16 PST 2017
Running iteration 2/5 for 14 cores...
2017-12-09 19:34:18,569 -> Starting session,1.60,0
2017-12-09 19:34:18,569 -> Setting variables,0.00,0
2017-12-09 19:34:23,595 -> Reading datasets,5.03,0
2017-12-09 19:34:23,607 -> Points partitions: 2
2017-12-09 19:34:23,615 -> Centers partitions: 2
2017-12-09 19:34:31,042 -> 01.Indexing points,7.39,59143,40.0,14
2017-12-09 19:34:37,742 -> 02.Indexing centers,6.70,296514,40.0,14
2017-12-09 19:34:37,750 -> 1024
2017-12-09 19:34:37,757 -> 1024
2017-12-09 19:34:54,225 -> 03.Joining datasets,16.47,296510,40.0,14
Done!!! Sat Dec  9 19:34:54 PST 2017
Running iteration 3/5 for 14 cores...
2017-12-09 19:34:56,998 -> Starting session,1.66,0
2017-12-09 19:34:56,998 -> Setting variables,0.00,0
2017-12-09 19:35:02,042 -> Reading datasets,5.04,0
2017-12-09 19:35:02,053 -> Points partitions: 2
2017-12-09 19:35:02,060 -> Centers partitions: 2
2017-12-09 19:35:09,559 -> 01.Indexing points,7.46,59143,40.0,14
2017-12-09 19:35:15,927 -> 02.Indexing centers,6.37,296514,40.0,14
2017-12-09 19:35:15,935 -> 1024
2017-12-09 19:35:15,942 -> 1024
2017-12-09 19:35:31,608 -> 03.Joining datasets,15.67,296510,40.0,14
Done!!! Sat Dec  9 19:35:32 PST 2017
Running iteration 4/5 for 14 cores...
2017-12-09 19:35:35,168 -> Starting session,1.55,0
2017-12-09 19:35:35,168 -> Setting variables,0.00,0
2017-12-09 19:35:40,045 -> Reading datasets,4.88,0
2017-12-09 19:35:40,055 -> Points partitions: 2
2017-12-09 19:35:40,062 -> Centers partitions: 2
2017-12-09 19:35:47,219 -> 01.Indexing points,7.12,59143,40.0,14
2017-12-09 19:35:53,529 -> 02.Indexing centers,6.31,296514,40.0,14
2017-12-09 19:35:53,540 -> 1024
2017-12-09 19:35:53,547 -> 1024
2017-12-09 19:36:08,889 -> 03.Joining datasets,15.88,296510,40.0,14
Done!!! Sat Dec  9 19:36:09 PST 2017
Running iteration 5/5 for 14 cores...
2017-12-09 19:36:11,805 -> Starting session,1.64,0
2017-12-09 19:36:11,806 -> Setting variables,0.00,0
2017-12-09 19:36:16,607 -> Reading datasets,4.80,0
2017-12-09 19:36:16,619 -> Points partitions: 2
2017-12-09 19:36:16,626 -> Centers partitions: 2
2017-12-09 19:36:23,586 -> 01.Indexing points,6.92,59143,40.0,14
2017-12-09 19:36:29,719 -> 02.Indexing centers,6.13,296514,40.0,14
2017-12-09 19:36:29,727 -> 1024
2017-12-09 19:36:29,733 -> 1024
2017-12-09 19:36:45,199 -> 03.Joining datasets,15.47,296510,40.0,14
Done!!! Sat Dec  9 19:36:46 PST 2017
acald013@dblab-rack12: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack11: stopping org.apache.spark.deploy.worker.Worker
stopping org.apache.spark.deploy.master.Master
starting org.apache.spark.deploy.master.Master, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.master.Master-1-dblab-rack11.cs.ucr.edu.out
acald013@dblab-rack12: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack12.out
acald013@dblab-rack14: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack14.cs.ucr.edu.out
acald013@dblab-rack11: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack11.cs.ucr.edu.out
Running iteration 1/5 for 21 cores...
2017-12-09 19:36:54,695 -> Starting session,1.92,0
2017-12-09 19:36:54,695 -> Setting variables,0.00,0
2017-12-09 19:37:00,581 -> Reading datasets,5.89,0
2017-12-09 19:37:00,594 -> Points partitions: 2
2017-12-09 19:37:00,603 -> Centers partitions: 2
2017-12-09 19:37:07,282 -> 01.Indexing points,6.64,59143,40.0,21
2017-12-09 19:37:13,197 -> 02.Indexing centers,5.91,296514,40.0,21
2017-12-09 19:37:13,208 -> 1024
2017-12-09 19:37:13,218 -> 1024
2017-12-09 19:37:26,281 -> 03.Joining datasets,13.06,296510,40.0,21
Done!!! Sat Dec  9 19:37:27 PST 2017
Running iteration 2/5 for 21 cores...
2017-12-09 19:37:29,980 -> Starting session,1.64,0
2017-12-09 19:37:29,980 -> Setting variables,0.00,0
2017-12-09 19:37:35,977 -> Reading datasets,6.00,0
2017-12-09 19:37:36,000 -> Points partitions: 2
2017-12-09 19:37:36,017 -> Centers partitions: 2
2017-12-09 19:37:42,932 -> 01.Indexing points,6.86,59143,40.0,21
2017-12-09 19:37:48,704 -> 02.Indexing centers,5.77,296514,40.0,21
2017-12-09 19:37:48,711 -> 1024
2017-12-09 19:37:48,717 -> 1024
2017-12-09 19:38:00,883 -> 03.Joining datasets,12.17,296510,40.0,21
Done!!! Sat Dec  9 19:38:01 PST 2017
Running iteration 3/5 for 21 cores...
2017-12-09 19:38:03,729 -> Starting session,1.62,0
2017-12-09 19:38:03,730 -> Setting variables,0.00,0
2017-12-09 19:38:09,608 -> Reading datasets,5.88,0
2017-12-09 19:38:09,619 -> Points partitions: 2
2017-12-09 19:38:09,626 -> Centers partitions: 2
2017-12-09 19:38:16,684 -> 01.Indexing points,7.02,59143,40.0,21
2017-12-09 19:38:22,648 -> 02.Indexing centers,5.96,296514,40.0,21
2017-12-09 19:38:22,655 -> 1024
2017-12-09 19:38:22,661 -> 1024
2017-12-09 19:38:34,640 -> 03.Joining datasets,11.98,296510,40.0,21
Done!!! Sat Dec  9 19:38:35 PST 2017
Running iteration 4/5 for 21 cores...
2017-12-09 19:38:37,482 -> Starting session,1.63,0
2017-12-09 19:38:37,483 -> Setting variables,0.00,0
2017-12-09 19:38:43,384 -> Reading datasets,5.90,0
2017-12-09 19:38:43,399 -> Points partitions: 2
2017-12-09 19:38:43,412 -> Centers partitions: 2
2017-12-09 19:38:49,717 -> 01.Indexing points,6.26,59143,40.0,21
2017-12-09 19:38:55,398 -> 02.Indexing centers,5.68,296514,40.0,21
2017-12-09 19:38:55,408 -> 1024
2017-12-09 19:38:55,419 -> 1024
2017-12-09 19:39:07,730 -> 03.Joining datasets,12.31,296510,40.0,21
Done!!! Sat Dec  9 19:39:09 PST 2017
Running iteration 5/5 for 21 cores...
2017-12-09 19:39:11,244 -> Starting session,1.59,0
2017-12-09 19:39:11,245 -> Setting variables,0.00,0
2017-12-09 19:39:16,161 -> Reading datasets,4.92,0
2017-12-09 19:39:16,174 -> Points partitions: 2
2017-12-09 19:39:16,185 -> Centers partitions: 2
2017-12-09 19:39:24,249 -> 01.Indexing points,8.03,59143,40.0,21
2017-12-09 19:39:30,021 -> 02.Indexing centers,5.77,296514,40.0,21
2017-12-09 19:39:30,028 -> 1024
2017-12-09 19:39:30,034 -> 1024
2017-12-09 19:39:42,068 -> 03.Joining datasets,12.03,296510,40.0,21
Done!!! Sat Dec  9 19:39:43 PST 2017
acald013@dblab-rack12: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack11: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack14: stopping org.apache.spark.deploy.worker.Worker
stopping org.apache.spark.deploy.master.Master
starting org.apache.spark.deploy.master.Master, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.master.Master-1-dblab-rack11.cs.ucr.edu.out
acald013@dblab-rack12: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack12.out
acald013@dblab-rack15: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack15.out
acald013@dblab-rack14: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack14.cs.ucr.edu.out
acald013@dblab-rack11: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack11.cs.ucr.edu.out
Running iteration 1/5 for 28 cores...
2017-12-09 19:39:51,310 -> Starting session,1.67,0
2017-12-09 19:39:51,310 -> Setting variables,0.00,0
2017-12-09 19:39:58,411 -> Reading datasets,7.10,0
2017-12-09 19:39:58,429 -> Points partitions: 2
2017-12-09 19:39:58,440 -> Centers partitions: 2
2017-12-09 19:40:06,042 -> 01.Indexing points,7.55,59143,40.0,28
2017-12-09 19:40:14,126 -> 02.Indexing centers,8.08,296514,40.0,28
2017-12-09 19:40:14,134 -> 1024
2017-12-09 19:40:14,140 -> 1024
2017-12-09 19:40:24,760 -> 03.Joining datasets,10.62,296510,40.0,28
Done!!! Sat Dec  9 19:40:25 PST 2017
Running iteration 2/5 for 28 cores...
2017-12-09 19:40:27,435 -> Starting session,1.55,0
2017-12-09 19:40:27,435 -> Setting variables,0.00,0
2017-12-09 19:40:33,213 -> Reading datasets,5.78,0
2017-12-09 19:40:33,227 -> Points partitions: 2
2017-12-09 19:40:33,239 -> Centers partitions: 2
2017-12-09 19:40:42,789 -> 01.Indexing points,9.51,59143,40.0,28
2017-12-09 19:40:49,508 -> 02.Indexing centers,6.72,296514,40.0,28
2017-12-09 19:40:49,518 -> 1024
2017-12-09 19:40:49,526 -> 1024
2017-12-09 19:41:00,514 -> 03.Joining datasets,10.99,296510,40.0,28
Done!!! Sat Dec  9 19:41:01 PST 2017
Running iteration 3/5 for 28 cores...
2017-12-09 19:41:03,172 -> Starting session,1.56,0
2017-12-09 19:41:03,173 -> Setting variables,0.00,0
2017-12-09 19:41:10,348 -> Reading datasets,7.18,0
2017-12-09 19:41:10,369 -> Points partitions: 2
2017-12-09 19:41:10,381 -> Centers partitions: 2
2017-12-09 19:41:18,343 -> 01.Indexing points,7.91,59143,40.0,28
2017-12-09 19:41:25,840 -> 02.Indexing centers,7.50,296514,40.0,28
2017-12-09 19:41:25,853 -> 1024
2017-12-09 19:41:25,861 -> 1024
2017-12-09 19:41:36,680 -> 03.Joining datasets,10.82,296510,40.0,28
Done!!! Sat Dec  9 19:41:37 PST 2017
Running iteration 4/5 for 28 cores...
2017-12-09 19:41:40,249 -> Starting session,1.53,0
2017-12-09 19:41:40,249 -> Setting variables,0.00,0
2017-12-09 19:41:47,371 -> Reading datasets,7.12,0
2017-12-09 19:41:47,383 -> Points partitions: 2
2017-12-09 19:41:47,393 -> Centers partitions: 2
2017-12-09 19:41:55,143 -> 01.Indexing points,7.70,59143,40.0,28
2017-12-09 19:42:03,115 -> 02.Indexing centers,7.97,296514,40.0,28
2017-12-09 19:42:03,125 -> 1024
2017-12-09 19:42:03,133 -> 1024
2017-12-09 19:42:14,450 -> 03.Joining datasets,11.32,296510,40.0,28
Done!!! Sat Dec  9 19:42:15 PST 2017
Running iteration 5/5 for 28 cores...
2017-12-09 19:42:18,167 -> Starting session,1.62,0
2017-12-09 19:42:18,168 -> Setting variables,0.00,0
2017-12-09 19:42:25,290 -> Reading datasets,7.12,0
2017-12-09 19:42:25,308 -> Points partitions: 2
2017-12-09 19:42:25,319 -> Centers partitions: 2
2017-12-09 19:42:32,524 -> 01.Indexing points,7.15,59143,40.0,28
2017-12-09 19:42:38,675 -> 02.Indexing centers,6.15,296514,40.0,28
2017-12-09 19:42:38,686 -> 1024
2017-12-09 19:42:38,694 -> 1024
2017-12-09 19:42:50,672 -> 03.Joining datasets,11.98,296510,40.0,28
Done!!! Sat Dec  9 19:42:51 PST 2017
acald013@dblab-rack12: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack15: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack11: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack14: stopping org.apache.spark.deploy.worker.Worker
stopping org.apache.spark.deploy.master.Master
Done!!!
acald013@dblab-rack12: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack15: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack14: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack11: no org.apache.spark.deploy.worker.Worker to stop
no org.apache.spark.deploy.master.Master to stop
starting org.apache.spark.deploy.master.Master, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.master.Master-1-dblab-rack11.cs.ucr.edu.out
acald013@dblab-rack14: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack14.cs.ucr.edu.out
Running iteration 1/5 for 7 cores...
2017-12-09 19:42:59,831 -> Starting session,1.51,0
2017-12-09 19:42:59,831 -> Setting variables,0.00,0
2017-12-09 19:43:04,109 -> Reading datasets,4.28,0
2017-12-09 19:43:04,125 -> Points partitions: 2
2017-12-09 19:43:04,135 -> Centers partitions: 2
2017-12-09 19:43:11,531 -> 01.Indexing points,7.36,39429,40.0,7
2017-12-09 19:43:17,282 -> 02.Indexing centers,5.75,197676,40.0,7
2017-12-09 19:43:17,296 -> 1024
2017-12-09 19:43:17,306 -> 1024
2017-12-09 19:43:35,120 -> 03.Joining datasets,17.81,197673,40.0,7
Done!!! Sat Dec  9 19:43:35 PST 2017
Running iteration 2/5 for 7 cores...
2017-12-09 19:43:37,888 -> Starting session,1.57,0
2017-12-09 19:43:37,888 -> Setting variables,0.00,0
2017-12-09 19:43:42,260 -> Reading datasets,4.37,0
2017-12-09 19:43:42,276 -> Points partitions: 2
2017-12-09 19:43:42,286 -> Centers partitions: 2
2017-12-09 19:43:49,909 -> 01.Indexing points,7.58,39429,40.0,7
2017-12-09 19:43:55,565 -> 02.Indexing centers,5.66,197676,40.0,7
2017-12-09 19:43:55,576 -> 1024
2017-12-09 19:43:55,584 -> 1024
2017-12-09 19:44:12,920 -> 03.Joining datasets,17.34,197673,40.0,7
Done!!! Sat Dec  9 19:44:13 PST 2017
Running iteration 3/5 for 7 cores...
2017-12-09 19:44:15,686 -> Starting session,1.56,0
2017-12-09 19:44:15,686 -> Setting variables,0.00,0
2017-12-09 19:44:20,013 -> Reading datasets,4.33,0
2017-12-09 19:44:20,029 -> Points partitions: 2
2017-12-09 19:44:20,038 -> Centers partitions: 2
2017-12-09 19:44:27,248 -> 01.Indexing points,7.17,39429,40.0,7
2017-12-09 19:44:33,402 -> 02.Indexing centers,6.15,197676,40.0,7
2017-12-09 19:44:33,416 -> 1024
2017-12-09 19:44:33,426 -> 1024
2017-12-09 19:44:52,172 -> 03.Joining datasets,17.86,197673,40.0,7
Done!!! Sat Dec  9 19:44:52 PST 2017
Running iteration 4/5 for 7 cores...
2017-12-09 19:44:54,965 -> Starting session,1.57,0
2017-12-09 19:44:54,966 -> Setting variables,0.00,0
2017-12-09 19:44:59,327 -> Reading datasets,4.36,0
2017-12-09 19:44:59,338 -> Points partitions: 2
2017-12-09 19:44:59,346 -> Centers partitions: 2
2017-12-09 19:45:06,305 -> 01.Indexing points,6.92,39429,40.0,7
2017-12-09 19:45:12,117 -> 02.Indexing centers,5.81,197676,40.0,7
2017-12-09 19:45:12,132 -> 1024
2017-12-09 19:45:12,143 -> 1024
2017-12-09 19:45:29,545 -> 03.Joining datasets,17.44,197673,40.0,7
Done!!! Sat Dec  9 19:45:30 PST 2017
Running iteration 5/5 for 7 cores...
2017-12-09 19:45:32,297 -> Starting session,1.55,0
2017-12-09 19:45:32,298 -> Setting variables,0.00,0
2017-12-09 19:45:36,547 -> Reading datasets,4.25,0
2017-12-09 19:45:36,558 -> Points partitions: 2
2017-12-09 19:45:36,565 -> Centers partitions: 2
2017-12-09 19:45:43,693 -> 01.Indexing points,7.09,39429,40.0,7
2017-12-09 19:45:49,417 -> 02.Indexing centers,5.72,197676,40.0,7
2017-12-09 19:45:49,430 -> 1024
2017-12-09 19:45:49,439 -> 1024
2017-12-09 19:46:06,465 -> 03.Joining datasets,17.03,197673,40.0,7
Done!!! Sat Dec  9 19:46:06 PST 2017
acald013@dblab-rack14: stopping org.apache.spark.deploy.worker.Worker
stopping org.apache.spark.deploy.master.Master
starting org.apache.spark.deploy.master.Master, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.master.Master-1-dblab-rack11.cs.ucr.edu.out
acald013@dblab-rack12: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack12.out
acald013@dblab-rack11: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack11.cs.ucr.edu.out
Running iteration 1/5 for 14 cores...
2017-12-09 19:46:14,901 -> Starting session,1.67,0
2017-12-09 19:46:14,903 -> Setting variables,0.00,0
2017-12-09 19:46:19,763 -> Reading datasets,4.86,0
2017-12-09 19:46:19,774 -> Points partitions: 2
2017-12-09 19:46:19,782 -> Centers partitions: 2
2017-12-09 19:46:26,710 -> 01.Indexing points,6.89,39429,40.0,14
2017-12-09 19:46:32,490 -> 02.Indexing centers,5.78,197676,40.0,14
2017-12-09 19:46:32,499 -> 1024
2017-12-09 19:46:32,507 -> 1024
2017-12-09 19:46:47,061 -> 03.Joining datasets,14.55,197673,40.0,14
Done!!! Sat Dec  9 19:46:47 PST 2017
Running iteration 2/5 for 14 cores...
2017-12-09 19:46:49,881 -> Starting session,1.60,0
2017-12-09 19:46:49,882 -> Setting variables,0.00,0
2017-12-09 19:46:54,723 -> Reading datasets,4.84,0
2017-12-09 19:46:54,736 -> Points partitions: 2
2017-12-09 19:46:54,747 -> Centers partitions: 2
2017-12-09 19:47:01,706 -> 01.Indexing points,6.92,39429,40.0,14
2017-12-09 19:47:07,755 -> 02.Indexing centers,6.05,197676,40.0,14
2017-12-09 19:47:07,768 -> 1024
2017-12-09 19:47:07,779 -> 1024
2017-12-09 19:47:21,629 -> 03.Joining datasets,13.85,197673,40.0,14
Done!!! Sat Dec  9 19:47:22 PST 2017
Running iteration 3/5 for 14 cores...
2017-12-09 19:47:24,555 -> Starting session,1.68,0
2017-12-09 19:47:24,556 -> Setting variables,0.00,0
2017-12-09 19:47:29,344 -> Reading datasets,4.79,0
2017-12-09 19:47:29,358 -> Points partitions: 2
2017-12-09 19:47:29,369 -> Centers partitions: 2
2017-12-09 19:47:36,505 -> 01.Indexing points,7.08,39429,40.0,14
2017-12-09 19:47:42,274 -> 02.Indexing centers,5.77,197676,40.0,14
2017-12-09 19:47:42,282 -> 1024
2017-12-09 19:47:42,289 -> 1024
2017-12-09 19:47:56,885 -> 03.Joining datasets,14.60,197673,40.0,14
Done!!! Sat Dec  9 19:47:57 PST 2017
Running iteration 4/5 for 14 cores...
2017-12-09 19:47:59,893 -> Starting session,1.63,0
2017-12-09 19:47:59,893 -> Setting variables,0.00,0
2017-12-09 19:48:04,863 -> Reading datasets,4.97,0
2017-12-09 19:48:04,873 -> Points partitions: 2
2017-12-09 19:48:04,880 -> Centers partitions: 2
2017-12-09 19:48:11,954 -> 01.Indexing points,7.03,39429,40.0,14
2017-12-09 19:48:17,935 -> 02.Indexing centers,5.98,197676,40.0,14
2017-12-09 19:48:17,943 -> 1024
2017-12-09 19:48:17,949 -> 1024
2017-12-09 19:48:33,211 -> 03.Joining datasets,15.26,197673,40.0,14
Done!!! Sat Dec  9 19:48:33 PST 2017
Running iteration 5/5 for 14 cores...
2017-12-09 19:48:36,087 -> Starting session,1.67,0
2017-12-09 19:48:36,087 -> Setting variables,0.00,0
2017-12-09 19:48:40,664 -> Reading datasets,4.58,0
2017-12-09 19:48:40,675 -> Points partitions: 2
2017-12-09 19:48:40,683 -> Centers partitions: 2
2017-12-09 19:48:47,611 -> 01.Indexing points,6.89,39429,40.0,14
2017-12-09 19:48:53,274 -> 02.Indexing centers,5.66,197676,40.0,14
2017-12-09 19:48:53,284 -> 1024
2017-12-09 19:48:53,290 -> 1024
2017-12-09 19:49:07,638 -> 03.Joining datasets,14.35,197673,40.0,14
Done!!! Sat Dec  9 19:49:08 PST 2017
acald013@dblab-rack12: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack11: stopping org.apache.spark.deploy.worker.Worker
stopping org.apache.spark.deploy.master.Master
starting org.apache.spark.deploy.master.Master, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.master.Master-1-dblab-rack11.cs.ucr.edu.out
acald013@dblab-rack12: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack12.out
acald013@dblab-rack14: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack14.cs.ucr.edu.out
acald013@dblab-rack11: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack11.cs.ucr.edu.out
Running iteration 1/5 for 21 cores...
2017-12-09 19:49:16,815 -> Starting session,1.78,0
2017-12-09 19:49:16,817 -> Setting variables,0.00,0
2017-12-09 19:49:22,570 -> Reading datasets,5.75,0
2017-12-09 19:49:22,588 -> Points partitions: 2
2017-12-09 19:49:22,603 -> Centers partitions: 2
2017-12-09 19:49:29,279 -> 01.Indexing points,6.63,39429,40.0,21
2017-12-09 19:49:34,390 -> 02.Indexing centers,5.11,197676,40.0,21
2017-12-09 19:49:34,399 -> 1024
2017-12-09 19:49:34,406 -> 1024
2017-12-09 19:49:45,721 -> 03.Joining datasets,11.31,197673,40.0,21
Done!!! Sat Dec  9 19:49:46 PST 2017
Running iteration 2/5 for 21 cores...
2017-12-09 19:49:48,579 -> Starting session,1.62,0
2017-12-09 19:49:48,580 -> Setting variables,0.00,0
2017-12-09 19:49:54,393 -> Reading datasets,5.81,0
2017-12-09 19:49:54,408 -> Points partitions: 2
2017-12-09 19:49:54,417 -> Centers partitions: 2
2017-12-09 19:50:00,581 -> 01.Indexing points,6.12,39429,40.0,21
2017-12-09 19:50:05,966 -> 02.Indexing centers,5.38,197676,40.0,21
2017-12-09 19:50:05,974 -> 1024
2017-12-09 19:50:05,980 -> 1024
2017-12-09 19:50:17,047 -> 03.Joining datasets,11.07,197673,40.0,21
Done!!! Sat Dec  9 19:50:17 PST 2017
Running iteration 3/5 for 21 cores...
2017-12-09 19:50:19,912 -> Starting session,1.62,0
2017-12-09 19:50:19,912 -> Setting variables,0.00,0
2017-12-09 19:50:25,633 -> Reading datasets,5.72,0
2017-12-09 19:50:25,655 -> Points partitions: 2
2017-12-09 19:50:25,672 -> Centers partitions: 2
2017-12-09 19:50:31,848 -> 01.Indexing points,6.12,39429,40.0,21
2017-12-09 19:50:36,826 -> 02.Indexing centers,4.98,197676,40.0,21
2017-12-09 19:50:36,835 -> 1024
2017-12-09 19:50:36,842 -> 1024
2017-12-09 19:50:49,235 -> 03.Joining datasets,12.39,197673,40.0,21
Done!!! Sat Dec  9 19:50:49 PST 2017
Running iteration 4/5 for 21 cores...
2017-12-09 19:50:52,047 -> Starting session,1.58,0
2017-12-09 19:50:52,047 -> Setting variables,0.00,0
2017-12-09 19:50:57,812 -> Reading datasets,5.77,0
2017-12-09 19:50:57,827 -> Points partitions: 2
2017-12-09 19:50:57,836 -> Centers partitions: 2
2017-12-09 19:51:04,399 -> 01.Indexing points,6.52,39429,40.0,21
2017-12-09 19:51:09,571 -> 02.Indexing centers,5.17,197676,40.0,21
2017-12-09 19:51:09,582 -> 1024
2017-12-09 19:51:09,590 -> 1024
2017-12-09 19:51:20,695 -> 03.Joining datasets,11.10,197673,40.0,21
Done!!! Sat Dec  9 19:51:21 PST 2017
Running iteration 5/5 for 21 cores...
2017-12-09 19:51:23,611 -> Starting session,1.81,0
2017-12-09 19:51:23,612 -> Setting variables,0.00,0
2017-12-09 19:51:29,406 -> Reading datasets,5.79,0
2017-12-09 19:51:29,422 -> Points partitions: 2
2017-12-09 19:51:29,432 -> Centers partitions: 2
2017-12-09 19:51:35,193 -> 01.Indexing points,5.80,39429,40.0,21
2017-12-09 19:51:40,378 -> 02.Indexing centers,5.18,197676,40.0,21
2017-12-09 19:51:40,386 -> 1024
2017-12-09 19:51:40,392 -> 1024
2017-12-09 19:51:51,164 -> 03.Joining datasets,10.77,197673,40.0,21
Done!!! Sat Dec  9 19:51:51 PST 2017
acald013@dblab-rack12: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack14: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack11: stopping org.apache.spark.deploy.worker.Worker
stopping org.apache.spark.deploy.master.Master
starting org.apache.spark.deploy.master.Master, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.master.Master-1-dblab-rack11.cs.ucr.edu.out
acald013@dblab-rack12: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack12.out
acald013@dblab-rack15: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack15.out
acald013@dblab-rack14: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack14.cs.ucr.edu.out
acald013@dblab-rack11: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack11.cs.ucr.edu.out
Running iteration 1/5 for 28 cores...
2017-12-09 19:51:59,825 -> Starting session,1.81,0
2017-12-09 19:51:59,825 -> Setting variables,0.00,0
2017-12-09 19:52:06,934 -> Reading datasets,7.11,0
2017-12-09 19:52:06,945 -> Points partitions: 2
2017-12-09 19:52:06,952 -> Centers partitions: 2
2017-12-09 19:52:14,636 -> 01.Indexing points,7.65,39429,40.0,28
2017-12-09 19:52:19,564 -> 02.Indexing centers,4.93,197676,40.0,28
2017-12-09 19:52:19,573 -> 1024
2017-12-09 19:52:19,579 -> 1024
2017-12-09 19:52:29,855 -> 03.Joining datasets,10.28,197673,40.0,28
Done!!! Sat Dec  9 19:52:30 PST 2017
Running iteration 2/5 for 28 cores...
2017-12-09 19:52:32,647 -> Starting session,1.67,0
2017-12-09 19:52:32,648 -> Setting variables,0.00,0
2017-12-09 19:52:39,414 -> Reading datasets,6.77,0
2017-12-09 19:52:39,433 -> Points partitions: 2
2017-12-09 19:52:39,446 -> Centers partitions: 2
2017-12-09 19:52:47,075 -> 01.Indexing points,7.57,39429,40.0,28
2017-12-09 19:52:52,763 -> 02.Indexing centers,5.69,197676,40.0,28
2017-12-09 19:52:52,773 -> 1024
2017-12-09 19:52:52,783 -> 1024
2017-12-09 19:53:03,439 -> 03.Joining datasets,10.66,197673,40.0,28
Done!!! Sat Dec  9 19:53:03 PST 2017
Running iteration 3/5 for 28 cores...
2017-12-09 19:53:06,143 -> Starting session,1.59,0
2017-12-09 19:53:06,144 -> Setting variables,0.00,0
2017-12-09 19:53:13,237 -> Reading datasets,7.09,0
2017-12-09 19:53:13,256 -> Points partitions: 2
2017-12-09 19:53:13,267 -> Centers partitions: 2
2017-12-09 19:53:20,554 -> 01.Indexing points,7.22,39429,40.0,28
2017-12-09 19:53:26,169 -> 02.Indexing centers,5.61,197676,40.0,28
2017-12-09 19:53:26,176 -> 1024
2017-12-09 19:53:26,182 -> 1024
2017-12-09 19:53:35,966 -> 03.Joining datasets,9.78,197673,40.0,28
Done!!! Sat Dec  9 19:53:37 PST 2017
Running iteration 4/5 for 28 cores...
2017-12-09 19:53:39,540 -> Starting session,1.68,0
2017-12-09 19:53:39,540 -> Setting variables,0.00,0
2017-12-09 19:53:45,366 -> Reading datasets,5.83,0
2017-12-09 19:53:45,377 -> Points partitions: 2
2017-12-09 19:53:45,385 -> Centers partitions: 2
2017-12-09 19:53:53,739 -> 01.Indexing points,8.32,39429,40.0,28
2017-12-09 19:53:58,586 -> 02.Indexing centers,4.85,197676,40.0,28
2017-12-09 19:53:58,595 -> 1024
2017-12-09 19:53:58,601 -> 1024
2017-12-09 19:54:08,491 -> 03.Joining datasets,9.89,197673,40.0,28
Done!!! Sat Dec  9 19:54:08 PST 2017
Running iteration 5/5 for 28 cores...
2017-12-09 19:54:11,209 -> Starting session,1.50,0
2017-12-09 19:54:11,209 -> Setting variables,0.00,0
2017-12-09 19:54:18,074 -> Reading datasets,6.86,0
2017-12-09 19:54:18,093 -> Points partitions: 2
2017-12-09 19:54:18,104 -> Centers partitions: 2
2017-12-09 19:54:25,208 -> 01.Indexing points,7.06,39429,40.0,28
2017-12-09 19:54:31,528 -> 02.Indexing centers,6.32,197676,40.0,28
2017-12-09 19:54:31,537 -> 1024
2017-12-09 19:54:31,544 -> 1024
2017-12-09 19:54:41,266 -> 03.Joining datasets,9.72,197673,40.0,28
Done!!! Sat Dec  9 19:54:41 PST 2017
acald013@dblab-rack12: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack15: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack11: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack14: stopping org.apache.spark.deploy.worker.Worker
stopping org.apache.spark.deploy.master.Master
Done!!!
acald013@dblab-rack12: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack15: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack11: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack14: no org.apache.spark.deploy.worker.Worker to stop
no org.apache.spark.deploy.master.Master to stop
starting org.apache.spark.deploy.master.Master, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.master.Master-1-dblab-rack11.cs.ucr.edu.out
acald013@dblab-rack14: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack14.cs.ucr.edu.out
Running iteration 1/5 for 7 cores...
2017-12-09 19:54:49,615 -> Starting session,1.44,0
2017-12-09 19:54:49,616 -> Setting variables,0.00,0
2017-12-09 19:54:53,978 -> Reading datasets,4.36,0
2017-12-09 19:54:53,989 -> Points partitions: 2
2017-12-09 19:54:53,996 -> Centers partitions: 2
2017-12-09 19:55:00,623 -> 01.Indexing points,6.59,19715,40.0,7
2017-12-09 19:55:05,819 -> 02.Indexing centers,5.19,98838,40.0,7
2017-12-09 19:55:05,832 -> 992
2017-12-09 19:55:05,841 -> 1024
2017-12-09 19:55:20,533 -> 03.Joining datasets,14.77,98837,40.0,7
Done!!! Sat Dec  9 19:55:21 PST 2017
Running iteration 2/5 for 7 cores...
2017-12-09 19:55:23,313 -> Starting session,1.57,0
2017-12-09 19:55:23,370 -> Setting variables,0.00,0
2017-12-09 19:55:27,532 -> Reading datasets,4.16,0
2017-12-09 19:55:27,546 -> Points partitions: 2
2017-12-09 19:55:27,555 -> Centers partitions: 2
2017-12-09 19:55:34,293 -> 01.Indexing points,6.70,19715,40.0,7
2017-12-09 19:55:39,652 -> 02.Indexing centers,5.36,98838,40.0,7
2017-12-09 19:55:39,664 -> 992
2017-12-09 19:55:39,672 -> 1024
2017-12-09 19:55:54,381 -> 03.Joining datasets,14.71,98837,40.0,7
Done!!! Sat Dec  9 19:55:54 PST 2017
Running iteration 3/5 for 7 cores...
2017-12-09 19:55:57,133 -> Starting session,1.58,0
2017-12-09 19:55:57,133 -> Setting variables,0.00,0
2017-12-09 19:56:01,216 -> Reading datasets,4.08,0
2017-12-09 19:56:01,227 -> Points partitions: 2
2017-12-09 19:56:01,235 -> Centers partitions: 2
2017-12-09 19:56:07,921 -> 01.Indexing points,6.65,19715,40.0,7
2017-12-09 19:56:13,357 -> 02.Indexing centers,5.43,98838,40.0,7
2017-12-09 19:56:13,370 -> 992
2017-12-09 19:56:13,379 -> 1024
2017-12-09 19:56:28,526 -> 03.Joining datasets,15.15,98837,40.0,7
Done!!! Sat Dec  9 19:56:28 PST 2017
Running iteration 4/5 for 7 cores...
2017-12-09 19:56:31,205 -> Starting session,1.52,0
2017-12-09 19:56:31,205 -> Setting variables,0.00,0
2017-12-09 19:56:35,306 -> Reading datasets,4.10,0
2017-12-09 19:56:35,320 -> Points partitions: 2
2017-12-09 19:56:35,330 -> Centers partitions: 2
2017-12-09 19:56:41,773 -> 01.Indexing points,6.40,19715,40.0,7
2017-12-09 19:56:46,627 -> 02.Indexing centers,4.85,98838,40.0,7
2017-12-09 19:56:46,635 -> 992
2017-12-09 19:56:46,642 -> 1024
2017-12-09 19:57:01,351 -> 03.Joining datasets,14.71,98837,40.0,7
Done!!! Sat Dec  9 19:57:01 PST 2017
Running iteration 5/5 for 7 cores...
2017-12-09 19:57:04,096 -> Starting session,1.64,0
2017-12-09 19:57:04,097 -> Setting variables,0.00,0
2017-12-09 19:57:08,254 -> Reading datasets,4.16,0
2017-12-09 19:57:08,265 -> Points partitions: 2
2017-12-09 19:57:08,272 -> Centers partitions: 2
2017-12-09 19:57:14,878 -> 01.Indexing points,6.57,19715,40.0,7
2017-12-09 19:57:19,756 -> 02.Indexing centers,4.88,98838,40.0,7
2017-12-09 19:57:19,766 -> 992
2017-12-09 19:57:19,775 -> 1024
2017-12-09 19:57:34,407 -> 03.Joining datasets,14.63,98837,40.0,7
Done!!! Sat Dec  9 19:57:34 PST 2017
acald013@dblab-rack14: stopping org.apache.spark.deploy.worker.Worker
stopping org.apache.spark.deploy.master.Master
starting org.apache.spark.deploy.master.Master, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.master.Master-1-dblab-rack11.cs.ucr.edu.out
acald013@dblab-rack12: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack12.out
acald013@dblab-rack11: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack11.cs.ucr.edu.out
Running iteration 1/5 for 14 cores...
2017-12-09 19:57:42,864 -> Starting session,1.72,0
2017-12-09 19:57:42,864 -> Setting variables,0.00,0
2017-12-09 19:57:47,627 -> Reading datasets,4.76,0
2017-12-09 19:57:47,638 -> Points partitions: 2
2017-12-09 19:57:47,645 -> Centers partitions: 2
2017-12-09 19:57:54,545 -> 01.Indexing points,6.86,19715,40.0,14
2017-12-09 19:57:59,663 -> 02.Indexing centers,5.12,98838,40.0,14
2017-12-09 19:57:59,672 -> 992
2017-12-09 19:57:59,679 -> 1024
2017-12-09 19:58:12,594 -> 03.Joining datasets,12.91,98837,40.0,14
Done!!! Sat Dec  9 19:58:13 PST 2017
Running iteration 2/5 for 14 cores...
2017-12-09 19:58:15,436 -> Starting session,1.60,0
2017-12-09 19:58:15,436 -> Setting variables,0.00,0
2017-12-09 19:58:20,349 -> Reading datasets,4.91,0
2017-12-09 19:58:20,362 -> Points partitions: 2
2017-12-09 19:58:20,370 -> Centers partitions: 2
2017-12-09 19:58:27,184 -> 01.Indexing points,6.77,19715,40.0,14
2017-12-09 19:58:32,202 -> 02.Indexing centers,5.02,98838,40.0,14
2017-12-09 19:58:32,212 -> 992
2017-12-09 19:58:32,219 -> 1024
2017-12-09 19:58:43,637 -> 03.Joining datasets,11.42,98837,40.0,14
Done!!! Sat Dec  9 19:58:44 PST 2017
Running iteration 3/5 for 14 cores...
2017-12-09 19:58:46,462 -> Starting session,1.62,0
2017-12-09 19:58:46,462 -> Setting variables,0.00,0
2017-12-09 19:58:51,444 -> Reading datasets,4.98,0
2017-12-09 19:58:51,454 -> Points partitions: 2
2017-12-09 19:58:51,462 -> Centers partitions: 2
2017-12-09 19:58:58,674 -> 01.Indexing points,7.17,19715,40.0,14
2017-12-09 19:59:03,478 -> 02.Indexing centers,4.80,98838,40.0,14
2017-12-09 19:59:03,485 -> 992
2017-12-09 19:59:03,491 -> 1024
2017-12-09 19:59:15,261 -> 03.Joining datasets,11.77,98837,40.0,14
Done!!! Sat Dec  9 19:59:15 PST 2017
Running iteration 4/5 for 14 cores...
2017-12-09 19:59:18,063 -> Starting session,1.54,0
2017-12-09 19:59:18,063 -> Setting variables,0.00,0
2017-12-09 19:59:22,883 -> Reading datasets,4.82,0
2017-12-09 19:59:22,894 -> Points partitions: 2
2017-12-09 19:59:22,902 -> Centers partitions: 2
2017-12-09 19:59:29,773 -> 01.Indexing points,6.83,19715,40.0,14
2017-12-09 19:59:34,458 -> 02.Indexing centers,4.68,98838,40.0,14
2017-12-09 19:59:34,467 -> 992
2017-12-09 19:59:34,473 -> 1024
2017-12-09 19:59:46,853 -> 03.Joining datasets,12.38,98837,40.0,14
Done!!! Sat Dec  9 19:59:47 PST 2017
Running iteration 5/5 for 14 cores...
2017-12-09 19:59:49,574 -> Starting session,1.55,0
2017-12-09 19:59:49,575 -> Setting variables,0.00,0
2017-12-09 19:59:54,490 -> Reading datasets,4.91,0
2017-12-09 19:59:54,501 -> Points partitions: 2
2017-12-09 19:59:54,509 -> Centers partitions: 2
2017-12-09 20:00:01,621 -> 01.Indexing points,7.07,19715,40.0,14
2017-12-09 20:00:06,376 -> 02.Indexing centers,4.75,98838,40.0,14
2017-12-09 20:00:06,387 -> 992
2017-12-09 20:00:06,396 -> 1024
2017-12-09 20:00:18,461 -> 03.Joining datasets,12.06,98837,40.0,14
Done!!! Sat Dec  9 20:00:18 PST 2017
acald013@dblab-rack12: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack11: stopping org.apache.spark.deploy.worker.Worker
stopping org.apache.spark.deploy.master.Master
starting org.apache.spark.deploy.master.Master, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.master.Master-1-dblab-rack11.cs.ucr.edu.out
acald013@dblab-rack12: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack12.out
acald013@dblab-rack14: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack14.cs.ucr.edu.out
acald013@dblab-rack11: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack11.cs.ucr.edu.out
Running iteration 1/5 for 21 cores...
2017-12-09 20:00:26,674 -> Starting session,1.62,0
2017-12-09 20:00:26,675 -> Setting variables,0.00,0
2017-12-09 20:00:31,519 -> Reading datasets,4.84,0
2017-12-09 20:00:31,530 -> Points partitions: 2
2017-12-09 20:00:31,537 -> Centers partitions: 2
2017-12-09 20:00:39,602 -> 01.Indexing points,8.03,19715,40.0,21
2017-12-09 20:00:43,971 -> 02.Indexing centers,4.37,98838,40.0,21
2017-12-09 20:00:43,983 -> 992
2017-12-09 20:00:43,991 -> 1024
2017-12-09 20:00:54,700 -> 03.Joining datasets,10.71,98837,40.0,21
Done!!! Sat Dec  9 20:00:55 PST 2017
Running iteration 2/5 for 21 cores...
2017-12-09 20:00:58,383 -> Starting session,1.79,0
2017-12-09 20:00:58,383 -> Setting variables,0.00,0
2017-12-09 20:01:03,120 -> Reading datasets,4.74,0
2017-12-09 20:01:03,130 -> Points partitions: 2
2017-12-09 20:01:03,138 -> Centers partitions: 2
2017-12-09 20:01:09,068 -> 01.Indexing points,5.89,19715,40.0,21
2017-12-09 20:01:13,745 -> 02.Indexing centers,4.68,98838,40.0,21
2017-12-09 20:01:13,752 -> 992
2017-12-09 20:01:13,758 -> 1024
2017-12-09 20:01:26,670 -> 03.Joining datasets,12.91,98837,40.0,21
Done!!! Sat Dec  9 20:01:27 PST 2017
Running iteration 3/5 for 21 cores...
2017-12-09 20:01:29,642 -> Starting session,1.74,0
2017-12-09 20:01:29,643 -> Setting variables,0.00,0
2017-12-09 20:01:35,244 -> Reading datasets,5.60,0
2017-12-09 20:01:35,263 -> Points partitions: 2
2017-12-09 20:01:35,275 -> Centers partitions: 2
2017-12-09 20:01:42,781 -> 01.Indexing points,7.45,19715,40.0,21
2017-12-09 20:01:47,157 -> 02.Indexing centers,4.37,98838,40.0,21
2017-12-09 20:01:47,169 -> 992
2017-12-09 20:01:47,178 -> 1024
2017-12-09 20:01:57,191 -> 03.Joining datasets,10.01,98837,40.0,21
Done!!! Sat Dec  9 20:01:57 PST 2017
Running iteration 4/5 for 21 cores...
2017-12-09 20:01:59,949 -> Starting session,1.50,0
2017-12-09 20:01:59,949 -> Setting variables,0.00,0
2017-12-09 20:02:05,505 -> Reading datasets,5.56,0
2017-12-09 20:02:05,529 -> Points partitions: 2
2017-12-09 20:02:05,547 -> Centers partitions: 2
2017-12-09 20:02:13,048 -> 01.Indexing points,7.44,19715,40.0,21
2017-12-09 20:02:17,396 -> 02.Indexing centers,4.35,98838,40.0,21
2017-12-09 20:02:17,408 -> 992
2017-12-09 20:02:17,417 -> 1024
2017-12-09 20:02:30,199 -> 03.Joining datasets,12.96,98837,40.0,21
Done!!! Sat Dec  9 20:02:30 PST 2017
Running iteration 5/5 for 21 cores...
2017-12-09 20:02:32,992 -> Starting session,1.61,0
2017-12-09 20:02:32,993 -> Setting variables,0.00,0
2017-12-09 20:02:38,555 -> Reading datasets,5.56,0
2017-12-09 20:02:38,571 -> Points partitions: 2
2017-12-09 20:02:38,581 -> Centers partitions: 2
2017-12-09 20:02:46,175 -> 01.Indexing points,7.54,19715,40.0,21
2017-12-09 20:02:50,742 -> 02.Indexing centers,4.57,98838,40.0,21
2017-12-09 20:02:50,754 -> 992
2017-12-09 20:02:50,763 -> 1024
2017-12-09 20:03:01,347 -> 03.Joining datasets,10.58,98837,40.0,21
Done!!! Sat Dec  9 20:03:01 PST 2017
acald013@dblab-rack12: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack11: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack14: stopping org.apache.spark.deploy.worker.Worker
stopping org.apache.spark.deploy.master.Master
starting org.apache.spark.deploy.master.Master, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.master.Master-1-dblab-rack11.cs.ucr.edu.out
acald013@dblab-rack12: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack12.out
acald013@dblab-rack15: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack15.out
acald013@dblab-rack14: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack14.cs.ucr.edu.out
acald013@dblab-rack11: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack11.cs.ucr.edu.out
Running iteration 1/5 for 28 cores...
2017-12-09 20:03:09,661 -> Starting session,1.70,0
2017-12-09 20:03:09,661 -> Setting variables,0.00,0
2017-12-09 20:03:16,675 -> Reading datasets,7.01,0
2017-12-09 20:03:16,692 -> Points partitions: 2
2017-12-09 20:03:16,705 -> Centers partitions: 2
2017-12-09 20:03:24,977 -> 01.Indexing points,8.23,19715,40.0,28
2017-12-09 20:03:29,481 -> 02.Indexing centers,4.50,98838,40.0,28
2017-12-09 20:03:29,488 -> 992
2017-12-09 20:03:29,494 -> 1024
2017-12-09 20:03:39,861 -> 03.Joining datasets,10.37,98837,40.0,28
Done!!! Sat Dec  9 20:03:40 PST 2017
Running iteration 2/5 for 28 cores...
2017-12-09 20:03:42,728 -> Starting session,1.65,0
2017-12-09 20:03:42,728 -> Setting variables,0.00,0
2017-12-09 20:03:49,533 -> Reading datasets,6.80,0
2017-12-09 20:03:49,545 -> Points partitions: 2
2017-12-09 20:03:49,554 -> Centers partitions: 2
2017-12-09 20:03:57,797 -> 01.Indexing points,8.20,19715,40.0,28
2017-12-09 20:04:03,163 -> 02.Indexing centers,5.36,98838,40.0,28
2017-12-09 20:04:03,179 -> 992
2017-12-09 20:04:03,190 -> 1024
2017-12-09 20:04:14,234 -> 03.Joining datasets,11.04,98837,40.0,28
Done!!! Sat Dec  9 20:04:14 PST 2017
Running iteration 3/5 for 28 cores...
2017-12-09 20:04:17,022 -> Starting session,1.55,0
2017-12-09 20:04:17,023 -> Setting variables,0.00,0
2017-12-09 20:04:24,090 -> Reading datasets,7.07,0
2017-12-09 20:04:24,102 -> Points partitions: 2
2017-12-09 20:04:24,109 -> Centers partitions: 2
2017-12-09 20:04:32,131 -> 01.Indexing points,7.98,19715,40.0,28
2017-12-09 20:04:37,926 -> 02.Indexing centers,5.79,98838,40.0,28
2017-12-09 20:04:37,938 -> 992
2017-12-09 20:04:37,947 -> 1024
2017-12-09 20:04:47,955 -> 03.Joining datasets,10.01,98837,40.0,28
Done!!! Sat Dec  9 20:04:48 PST 2017
Running iteration 4/5 for 28 cores...
2017-12-09 20:04:50,743 -> Starting session,1.61,0
2017-12-09 20:04:50,744 -> Setting variables,0.00,0
2017-12-09 20:04:57,779 -> Reading datasets,7.03,0
2017-12-09 20:04:57,796 -> Points partitions: 2
2017-12-09 20:04:57,806 -> Centers partitions: 2
2017-12-09 20:05:03,990 -> 01.Indexing points,6.13,19715,40.0,28
2017-12-09 20:05:09,465 -> 02.Indexing centers,5.47,98838,40.0,28
2017-12-09 20:05:09,474 -> 992
2017-12-09 20:05:09,480 -> 1024
2017-12-09 20:05:20,722 -> 03.Joining datasets,11.24,98837,40.0,28
Done!!! Sat Dec  9 20:05:21 PST 2017
Running iteration 5/5 for 28 cores...
2017-12-09 20:05:23,483 -> Starting session,1.58,0
2017-12-09 20:05:23,483 -> Setting variables,0.00,0
2017-12-09 20:05:30,204 -> Reading datasets,6.72,0
2017-12-09 20:05:30,221 -> Points partitions: 2
2017-12-09 20:05:30,232 -> Centers partitions: 2
2017-12-09 20:05:39,052 -> 01.Indexing points,8.77,19715,40.0,28
2017-12-09 20:05:44,462 -> 02.Indexing centers,5.41,98838,40.0,28
2017-12-09 20:05:44,470 -> 992
2017-12-09 20:05:44,476 -> 1024
2017-12-09 20:05:53,545 -> 03.Joining datasets,9.07,98837,40.0,28
Done!!! Sat Dec  9 20:05:54 PST 2017
acald013@dblab-rack12: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack15: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack14: stopping org.apache.spark.deploy.worker.Worker
acald013@dblab-rack11: stopping org.apache.spark.deploy.worker.Worker
stopping org.apache.spark.deploy.master.Master
Done!!!
acald013@dblab-rack12: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack15: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack14: no org.apache.spark.deploy.worker.Worker to stop
acald013@dblab-rack11: no org.apache.spark.deploy.worker.Worker to stop
no org.apache.spark.deploy.master.Master to stop
starting org.apache.spark.deploy.master.Master, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.master.Master-1-dblab-rack11.cs.ucr.edu.out
acald013@dblab-rack14: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack14.cs.ucr.edu.out
Running iteration 1/5 for 7 cores...
2017-12-09 20:06:02,006 -> Starting session,1.48,0
2017-12-09 20:06:02,007 -> Setting variables,0.00,0
2017-12-09 20:06:06,273 -> Reading datasets,4.27,0
2017-12-09 20:06:06,286 -> Points partitions: 2
2017-12-09 20:06:06,294 -> Centers partitions: 2
2017-12-09 20:06:13,744 -> 01.Indexing points,7.41,78857,30.0,7
2017-12-09 20:06:20,308 -> 02.Indexing centers,6.56,289496,30.0,7
2017-12-09 20:06:20,322 -> 1024
2017-12-09 20:06:20,331 -> 1024
2017-12-09 20:06:39,650 -> 03.Joining datasets,19.32,289486,30.0,7
Done!!! Sat Dec  9 20:06:40 PST 2017
Running iteration 2/5 for 7 cores...
2017-12-09 20:06:42,459 -> Starting session,1.61,0
2017-12-09 20:06:42,459 -> Setting variables,0.00,0
2017-12-09 20:06:46,702 -> Reading datasets,4.24,0
2017-12-09 20:06:46,715 -> Points partitions: 2
2017-12-09 20:06:46,724 -> Centers partitions: 2
2017-12-09 20:06:54,701 -> 01.Indexing points,7.89,78857,30.0,7
2017-12-09 20:07:01,246 -> 02.Indexing centers,6.54,289496,30.0,7
2017-12-09 20:07:01,257 -> 1024
2017-12-09 20:07:01,268 -> 1024
2017-12-09 20:07:20,734 -> 03.Joining datasets,19.47,289486,30.0,7
Done!!! Sat Dec  9 20:07:21 PST 2017
Running iteration 3/5 for 7 cores...
2017-12-09 20:07:23,477 -> Starting session,1.60,0
2017-12-09 20:07:23,478 -> Setting variables,0.00,0
2017-12-09 20:07:27,795 -> Reading datasets,4.32,0
2017-12-09 20:07:27,808 -> Points partitions: 2
2017-12-09 20:07:27,816 -> Centers partitions: 2
2017-12-09 20:07:35,435 -> 01.Indexing points,7.58,78857,30.0,7
2017-12-09 20:07:41,907 -> 02.Indexing centers,6.47,289496,30.0,7
2017-12-09 20:07:41,920 -> 1024
2017-12-09 20:07:41,928 -> 1024
2017-12-09 20:08:01,453 -> 03.Joining datasets,19.52,289486,30.0,7
Done!!! Sat Dec  9 20:08:01 PST 2017
Running iteration 4/5 for 7 cores...
2017-12-09 20:08:04,251 -> Starting session,1.74,0
2017-12-09 20:08:04,251 -> Setting variables,0.00,0
2017-12-09 20:08:08,529 -> Reading datasets,4.28,0
2017-12-09 20:08:08,542 -> Points partitions: 2
2017-12-09 20:08:08,554 -> Centers partitions: 2
2017-12-09 20:08:16,468 -> 01.Indexing points,7.87,78857,30.0,7
2017-12-09 20:08:22,730 -> 02.Indexing centers,6.26,289496,30.0,7
2017-12-09 20:08:22,742 -> 1024
2017-12-09 20:08:22,750 -> 1024
