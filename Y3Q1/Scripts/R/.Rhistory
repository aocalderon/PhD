facet_wrap(~Epsilon) +
scale_colour_discrete() +
scale_shape_discrete() +
scale_linetype_discrete()
plot(g)
g = ggplot(data=candidates, aes(x=factor(Cores), y=Count, group = Disks, colour = Disks, shape = Disks)) +
geom_line(aes(linetype = Disks)) +
geom_point(size = 2) +
labs(title = title, y = "Count") +
scale_x_discrete("Cores") +
theme(axis.text.x = element_text(size = 8, angle = 90), axis.text.y = element_text(size = 8)) +
facet_wrap(~Epsilon) +
scale_color_manual(values=c("#F8766D")) +
scale_shape_manual(values=c(16)) +
scale_linetype_discrete()
plot(g)
maximals = data[data$Disks == "Maximals",]
g = ggplot(data=maximals, aes(x=factor(Cores), y=Count, group = Disks, colour = Disks, shape = Disks)) +
geom_line(aes(linetype = Disks)) +
geom_point(size = 2) +
labs(title = title, y = "Count") +
scale_x_discrete("Cores") +
theme(axis.text.x = element_text(size = 8, angle = 90), axis.text.y = element_text(size = 8)) +
facet_wrap(~Epsilon) +
scale_color_manual(values=c("#00BFC4")) +
scale_shape_manual(values=c(16)) +
scale_linetype_discrete()
plot(g)
source('~/Documents/PhD/Code/Y3Q1/Scripts/R/plotScaleup.R')
source('~/Documents/PhD/Code/Y3Q1/Scripts/R/plotScaleup.R')
source('~/Documents/PhD/Code/Y3Q1/Scripts/R/plotScaleup.R')
View(candidates1)
View(candidates2)
source('~/Documents/PhD/Code/Y3Q1/Scripts/R/sampleBerlin.R')
install.packages("rgdal")
library("rgdal", lib.loc="~/R/x86_64-pc-linux-gnu-library/3.4")
source('~/Documents/PhD/Code/Y3Q1/Scripts/R/sampleBerlin.R')
library(data.table)
library(sp)
library(rgdal)
LAYERS = 10
FIRST_LAYER = 1
WGS84 = "+init=epsg:4326"
DHDN = "+init=epsg:3068"
DATASET = "/opt/Datasets/Berlin/berlin.csv"
OUTPUT = "Berlin"
data = read.csv(DATASET, header = F)
berlin = as.data.table(data[,c(3,4,1,2)])
names(berlin) = c('x','y','t','id')
berlin = berlin[berlin$t >= FIRST_LAYER, ]
berlin = berlin[berlin$t < FIRST_LAYER + LAYERS, c('x', 'y', 't', 'id')]
View(berlin)
berlin = berlin[ , list(id = min(id)), by = c('x', 'y', 't')]
berlin[ , `:=`( count = .N , idx = 1:.N ) , by = t ]
avg = mean(berlin$count)
print(avg)
if(avg < 1000){A=paste0(avg)}else if(avg < 1000000){A=paste0(as.integer(avg/1000),'K')}else if(avg < 1000000000){A=paste0(as.integer(avg/1000000),'M')}
berlin = berlin[sample(1:nrow(berlin), 1000) ,]
head(berlin)
berlin = berlin[order(t),]
head(berlin)
View(berlin)
berlin = as.data.table(data[,c(3,4,1,2)])
names(berlin) = c('x','y','t','id')
berlin = berlin[berlin$t >= FIRST_LAYER, c('x', 'y', 't', 'id')]
berlin = berlin[berlin$t < FIRST_LAYER + LAYERS,]
berlin = berlin[sample(1:nrow(berlin), 1000),]
View(berlin)
berlin = berlin[order(t),]
berlin = as.data.table(data[,c(3,4,1,2)])
names(berlin) = c('x','y','t','id')
berlin = berlin[berlin$t >= FIRST_LAYER, c('x', 'y', 't', 'id')]
berlin = berlin[berlin$t < FIRST_LAYER + LAYERS,]
LAYERS = 15
FIRST_LAYER = 1
WGS84 = "+init=epsg:4326"
DHDN = "+init=epsg:3068"
DATASET = "/opt/Datasets/Berlin/berlin.csv"
OUTPUT = "Berlin"
SAMPLE_SIZE = 10000
berlin = as.data.table(data[,c(3,4,1,2)])
names(berlin) = c('x','y','t','id')
berlin = berlin[berlin$t >= FIRST_LAYER, c('x', 'y', 't', 'id')]
berlin = berlin[berlin$t < FIRST_LAYER + LAYERS,]
berlin = berlin[sample(1:nrow(berlin), SAMPLE_SIZE),]
berlin = berlin[order(t),]
head(berlin)
berlin = berlin[ , list(id = min(id)), by = c('x', 'y', 't')]
berlin[ , `:=`( count = .N , idx = 1:.N ) , by = t ]
avg = mean(berlin$count)
print(avg)
coordinates(berlin) = ~x+y
proj4string(berlin) <- CRS(WGS84)
berlin = spTransform(berlin, CRS(DHDN))
if(avg < 1000){A=paste0(avg)}else if(avg < 1000000){A=paste0(as.integer(avg/1000),'K')}else if(avg < 1000000000){A=paste0(as.integer(avg/1000000),'M')}
N = nrow(berlin)
if(N < 1000){N=paste0(N,'')} else if(N < 1000000){N=paste0(as.integer(N/1000),'K')} else if(N < 1000000000){N=paste0(as.integer(N/1000000),'M')} else {N=paste0(as.integer(N/1000000000),'G')}
filename = paste0(OUTPUT,'_N',N,'_A',A,'_T',LAYERS,'.csv')
write.table(cbind(coordinates(berlin), berlin@data)
, file = filename
, row.names = F
, col.names = F
, sep = ','
, quote = F)
source('~/Documents/PhD/Code/Y3Q1/Scripts/R/sampleBerlin.R')
berlin
nrow(berlin)
source('~/Documents/PhD/Code/Y3Q1/Scripts/R/sampleBerlin.R')
source('~/Documents/PhD/Code/Y3Q1/Scripts/R/sampleBerlin.R')
source('~/Documents/PhD/Code/Y3Q1/Scripts/R/sampleBerlin.R')
source('~/Documents/PhD/Code/Y3Q1/Scripts/R/sampleBerlin.R')
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
PATH = "Y3Q1/Scripts/Scaleup/"
filename ="Berlin_N20K-80K_E50.0-100.0"
files = system(paste0("ls ",PHD_HOME,PATH,filename,"_C*.csv"), intern = T)
data = data.frame()
PATH = "Y3Q1/Scripts/Scaleup/"
filename ="Berlin_N20K-80K_E50.0-100.0"
files = system(paste0("ls ",PHD_HOME,PATH,filename,"_C*.csv"), intern = T)
data = data.frame()
foreach(f = files) %do% {
data = rbind(data, read.csv(f, header = F))
}
data = data[, c(2, 3, 6, 9)]
names(data) = c("Epsilon", "Dataset", "Time", "Cores")
PHD_HOME = Sys.getenv(c("PHD_HOME"))
files = system(paste0("ls ",PHD_HOME,PATH,filename,"_C*.csv"), intern = T)
data = data.frame()
foreach(f = files) %do% {
data = rbind(data, read.csv(f, header = F))
}
data = data[, c(2, 3, 6, 9)]
names(data) = c("Epsilon", "Dataset", "Time", "Cores")
View(data)
source('~/Documents/PhD/Code/Y3Q1/Scripts/R/plotScaleup2.R')
source('~/Documents/PhD/Code/Y3Q1/Scripts/R/plotScaleup2.R')
source('~/Documents/PhD/Code/Y3Q1/Scripts/R/plotScaleup2.R')
source('~/Documents/PhD/Code/Y3Q1/Scripts/R/plotScaleup2.R')
if (!require("pacman")) install.packages("pacman")
pacman::p_load(ggplot2, data.table, foreach, sqldf, tidyr)
PATH = "Y3Q1/Scripts/Scaleup/"
filename ="Berlin_N20K-80K_E50.0-100.0"
PHD_HOME = Sys.getenv(c("PHD_HOME"))
files = system(paste0("ls ",PHD_HOME,PATH,filename,"_C*.csv"), intern = T)
data = data.frame()
foreach(f = files) %do% {
data = rbind(data, read.csv(f, header = F))
}
data = data[, c(2, 3, 6, 9)]
if (!require("pacman")) install.packages("pacman")
pacman::p_load(ggplot2, data.table, foreach, sqldf, tidyr)
PATH = "Y3Q1/Scripts/Scaleup/"
filename ="Berlin_N20K-80K_E10.0-50.0"
PHD_HOME = Sys.getenv(c("PHD_HOME"))
files = system(paste0("ls ",PHD_HOME,PATH,filename,"_C*.csv"), intern = T)
data = data.frame()
foreach(f = files) %do% {
data = rbind(data, read.csv(f, header = F))
}
data = data[, c(2, 3, 6, 9)]
if (!require("pacman")) install.packages("pacman")
pacman::p_load(ggplot2, data.table, foreach, sqldf, tidyr)
PATH = "Y3Q1/Scripts/Scaleup/"
filename ="Berlin_N20K-80K_E10.0-50.0"
PHD_HOME = Sys.getenv(c("PHD_HOME"))
files = system(paste0("ls ",PHD_HOME,PATH,filename,"_C*.csv"), intern = T)
data = data.frame()
foreach(f = files) %do% {
data = rbind(data, read.csv(f, header = F))
}
data = data[, c(2, 3, 6, 9)]
names(data) = c("Epsilon", "Dataset", "Time", "Cores")
data20 = sqldf("SELECT Epsilon, Dataset, Cores, Time FROM data WHERE Dataset LIKE '20K' AND Cores = 7")
data40 = sqldf("SELECT Epsilon, Dataset, Cores, Time FROM data WHERE Dataset LIKE '40K' AND Cores = 14")
data60 = sqldf("SELECT Epsilon, Dataset, Cores, Time FROM data WHERE Dataset LIKE '60K' AND Cores = 21")
data80 = sqldf("SELECT Epsilon, Dataset, Cores, Time FROM data WHERE Dataset LIKE '80K' AND Cores = 28")
data = rbind(data20, data40, data60, data80)
data = sqldf("SELECT Epsilon, Dataset, Cores, AVG(Time) AS Time FROM data GROUP BY 1, 2, 3")
data$Dataset = factor(data$Dataset, levels = paste0(seq(20, 80, 20), "K"))
data$Cores = factor(data$Cores)
if (!require("pacman")) install.packages("pacman")
pacman::p_load(stringr, plotly)
volcano
dim(volcano)
str(volcano)
PHD_HOME = Sys.getenv(c("PHD_HOME"))
PATH = "Y3Q1/Scripts/Misc/"
EXTENSION = ".txt"
LOGNAME = "OO_D40K-80K_En2-26_P512-3072_E50_M12"
filename = paste0(PHD_HOME,PATH,LOGNAME,EXTENSION)
log = read.table(filename)
data = as.data.frame(str_split_fixed(as.character(log$V7),",",14), stringsAsFactors = F)
names(data) = c('tag','Dataset','NCandidates','Partitions1','Partitions2','Entries','Epsilon','Mu','time','avg','sd','var','min','max')
data$NCandidates = as.numeric(data$NCandidates)
data$Partitions1 = as.numeric(data$Partitions1)
data$Partitions2 = as.numeric(data$Partitions2)
data$Entries = as.numeric(data$Entries)
data$Epsilon = as.numeric(data$Epsilon)
data$Mu = as.numeric(data$Mu)
data$time = as.numeric(data$time)
data$avg = as.numeric(data$avg)
data$sd = as.numeric(data$sd)
data$var = as.numeric(data$var)
data$min = as.numeric(data$min)
data$max = as.numeric(data$max)
data
data3D = data[,c('Dataset','Partitions1','Entries','time')]
View(data3D)
B40K = data3D[data3D$Dataset === 'B40K']
B40K = data3D[data3D$Dataset == 'B40K']
B40K = data3D[data3D$Dataset === 'B40K',]
B40K = data3D[data3D$Dataset == 'B40K',]
View(B40K)
B80K = data3D[data3D$Dataset == 'B80K', c('Partitions1','Entries','time')]
B80K
as.matrix(B80K)
table(B80K)
pacman::p_load(stringr, plotly, dplyr)
library(dplyr)
pacman::p_load(stringr, plotly, dplyr, reshape2)
dcast(B80K, Partitions1 ~ Entries, value.var = time)
B80K = data.table(data3D[data3D$Dataset == 'B80K', c('Partitions1','Entries','time')])
?dcast
cast(B80K, Partitions1 ~ Entries, value.var = time)
pacman::p_load(stringr, plotly, dplyr, reshape2)
?cast
airquality
names(airquality) <- tolower(names(airquality))
airquality
id.data.frame
is.data.frame(airquality)
aqm <- melt(airquality, id=c("month", "day"), na.rm=TRUE)
is.data.frame(aqm)
aqm
View(airquality)
acast(aqm, day ~ month ~ variable)
acast(data3D, Partitions1 ~ Entries ~ time)
acast(data3D, Dataset ~ Partitions1 ~ Entries)
acast(data3D, Partitions1 ~ Entries ~ Dataset)
dataSurface = acast(data3D, Partitions1 ~ Entries ~ Dataset)
dataSurface[[1]]
dataSurface[1]
dataSurface[,,B80K]
dataSurface[B80K]
dataSurface[,,2]
dataSurface[,,1]
dataSurface[,,0]
dataSurface[,,1]
dataSurface[,,2]
dataSurface[,,3]
dataSurface[,,4]
p <- plot_ly(showscale = FALSE) %>%
add_surface(z = ~dataSurface[,,3]) %>%
add_surface(z = ~dataSurface[,,2], opacity = 0.98) %>%
add_surface(z = ~dataSurface[,,1], opacity = 0.98)
Sys.setenv("plotly_username"="aocalderon1978")
Sys.setenv("plotly_api_key"="dx4LIeqcXzokLrO2SUHF")
chart_link = api_create(p, filename="Optimizer", fileopt = "overwrite")
chart_link
source('~/Documents/PhD/Code/Y3Q1/Scripts/R/analyzeOptimizer.R')
chart_link
source('~/Documents/PhD/Code/Y3Q1/Scripts/R/analyzeOptimizer.R')
dataSurface
dataSurface[,,1]
names(dataSurface[,,1])
colnames(dataSurface[,,1])
rownames(dataSurface[,,1])
rownames(dataSurface[,,0])
colnames(dataSurface[,,0])
dataSurface[,,0]
source('~/Documents/PhD/Code/Y3Q1/Scripts/R/analyzeOptimizer.R')
chart_link
source('~/Documents/PhD/Code/Y3Q1/Scripts/R/analyzeOptimizer.R')
chart_link
rownames(dataSurface[,,0])
rownames(dataSurface[,,0])[0]
rownames(dataSurface[,,0])[1]
as.numeric(rownames(dataSurface[,,0])[1])
as.numeric(rownames(dataSurface[,,0])[6])
source('~/Documents/PhD/Code/Y3Q1/Scripts/R/analyzeOptimizer.R')
source('~/Documents/PhD/Code/Y3Q1/Scripts/R/analyzeOptimizer.R')
PHD_HOME = Sys.getenv(c("PHD_HOME"))
PATH = "Y3Q1/Scripts/Misc/"
EXTENSION = ".txt"
LOGNAME = "OO_D40K-80K_En2-26_P512-3072_E50_M12"
filename = paste0(PHD_HOME,PATH,LOGNAME,EXTENSION)
log = read.table(filename)
data = as.data.frame(str_split_fixed(as.character(log$V7),",",14), stringsAsFactors = F)
names(data) = c('tag','Dataset','NCandidates','Partitions1','Partitions2','Entries','Epsilon','Mu','time','avg','sd','var','min','max')
View(data)
data$NCandidates = as.numeric(data$NCandidates)
data$Partitions1 = as.numeric(data$Partitions1)
data$Partitions2 = as.numeric(data$Partitions2)
data$Entries = as.numeric(data$Entries)
data$Epsilon = as.numeric(data$Epsilon)
data$Mu = as.numeric(data$Mu)
data$time = as.numeric(data$time)
data$avg = as.numeric(data$avg)
data$sd = as.numeric(data$sd)
data$var = as.numeric(data$var)
data$min = as.numeric(data$min)
data$max = as.numeric(data$max)
metric = 'time'
metricData = data[,c('Dataset','Partitions1','Entries',metric)]
dataSurface = acast(metricData, Partitions1 ~ Entries ~ Dataset)
axx <- list(nticks = 4, title = 'Partitions')
axy <- list(nticks = 4, title = 'Maximun entries per node')
axz <- list(nticks = 4, title = metric)
p <- plot_ly(showscale = F) %>%
add_surface(z = ~dataSurface[,,3], opacity = 0.98) %>%
add_surface(z = ~dataSurface[,,2], opacity = 0.98) %>%
add_surface(z = ~dataSurface[,,1])  %>%
layout(scene = list(xaxis = axx, yaxis = axy, zaxis = axz))
chart_link = api_create(p, filename=metric, fileopt = "overwrite")
chart_link
source('~/Documents/PhD/Code/Y3Q1/Scripts/R/analyzeOptimizer.R')
chart_link
source('~/Documents/PhD/Code/Y3Q1/Scripts/R/analyzeOptimizer.R')
chart_link
source('~/Documents/PhD/Code/Y3Q1/Scripts/R/analyzeOptimizer.R')
chart_link
rownames(dataSurface[,,1])
source('~/Documents/PhD/Code/Y3Q1/Scripts/R/analyzeOptimizer.R')
chart_link
source('~/Documents/PhD/Code/Y3Q1/Scripts/R/analyzeOptimizer.R')
chart_link
source('~/Documents/PhD/Code/Y3Q1/Scripts/R/analyzeOptimizer.R')
chart_link
seq(0,6)
seq(0,5)
0:6
0:4
source('~/Documents/PhD/Code/Y3Q1/Scripts/R/analyzeOptimizer.R')
chart_link
source('~/Documents/PhD/Code/Y3Q1/Scripts/R/analyzeOptimizer.R')
timeLink
maxLink
source('~/Documents/PhD/Code/Y3Q1/Scripts/R/analyzeOptimizer.R')
source('~/Documents/PhD/Code/Y3Q1/Scripts/R/analyzeOptimizer.R')
timeLink
maxLink
if (!require("pacman")) install.packages("pacman")
pacman::p_load(ggplot2, data.table, foreach, sqldf, tidyr)
PATH = "Y3Q1/Scripts/Scaleup/Scaleup_2017-10-18-14-53/"
filename ="Berlin_N20K-80K_E10.0-50.0"
PHD_HOME = Sys.getenv(c("PHD_HOME"))
files = system(paste0("ls ",PHD_HOME,PATH,filename,"_C*.csv"), intern = T)
data = data.frame()
foreach(f = files) %do% {
data = rbind(data, read.csv(f, header = F))
}
data = data[, c(2, 3, 6, 9)]
names(data) = c("Epsilon", "Dataset", "Time", "Cores")
if (!require("pacman")) install.packages("pacman")
pacman::p_load(ggplot2, data.table, foreach, sqldf, tidyr)
PATH = "Y3Q1/Scripts/Scaleup/"
filename ="Berlin_N10K-50K_E10.0-50.0_M12_P1024_"
PHD_HOME = Sys.getenv(c("PHD_HOME"))
files = system(paste0("ls ",PHD_HOME,PATH,filename,"*.csv"), intern = T)
data = data.frame()
foreach(f = files) %do% {
data = rbind(data, read.csv(f, header = F))
}
View(data)
files = system(paste0("ls ",PHD_HOME,PATH,filename,"*.csv"), intern = T)
data = data.frame()
foreach(f = files) %do% {
data = rbind(data, read.table(f, header = F, sep = "->"))
}
data = data.frame()
foreach(f = files) %do% {
data = rbind(data, read.table(f, header = F, sep = ">"))
}
pacman::p_load(ggplot2, data.table, foreach, sqldf, tidyr, stringr)
data = str_split_fixed(data[,2], ",")
data = str_split_fixed(data[,2], ",", 13)
data = as.data.frame(str_split_fixed(data[,2], ",", 13))
files = system(paste0("ls ",PHD_HOME,PATH,filename,"*.csv"), intern = T)
data = data.frame()
foreach(f = files) %do% {
data = rbind(data, read.table(f, header = F, sep = ">"))
}
data = as.data.frame(str_split_fixed(data[,2], ",", 13))
data = as.data.frame(str_split_fixed(data[,2], ",", 12))
files = system(paste0("ls ",PHD_HOME,PATH,filename,"*.csv"), intern = T)
data = data.frame()
foreach(f = files) %do% {
data = rbind(data, read.table(f, header = F, sep = ">"))
}
data = as.data.frame(str_split_fixed(data[,2], ",", 12))
data$V13 = 0
data[data$V1 == "B20K",13]
data[data$V1 == "B20K",]
files = system(paste0("ls ",PHD_HOME,PATH,filename,"*.csv"), intern = T)
data = data.frame()
foreach(f = files) %do% {
data = rbind(data, read.table(f, header = F, sep = ">"))
}
data = as.data.frame(str_split_fixed(data[,2], ",", 12), stringsAsFactors = F)
data$V13 = 0
data[data$V1 == "B20K",]
data$V1
str_trim(data$V1)
data$V1 = str_trim(data$V1)
data[data$V1 == "B20K",]
data[data$V1 == "B20K",13]
data[data$V1 == "B20K",13] = 7
files = system(paste0("ls ",PHD_HOME,PATH,filename,"*.csv"), intern = T)
data = data.frame()
foreach(f = files) %do% {
data = rbind(data, read.table(f, header = F, sep = ">"))
}
data = as.data.frame(str_split_fixed(data[,2], ",", 12), stringsAsFactors = F)
data$V13 = 0
data$V1 = str_trim(data$V1)
data[data$V1 == "B20K",13] = 7
data[data$V1 == "B40K",13] = 14
data[data$V1 == "B60K",13] = 21
data[data$V1 == "B80K",13] = 28
data = data[, c(8, 1, 12, 13)]
names(data) = c("Epsilon", "Dataset", "Time", "Cores")
data20 = sqldf("SELECT Epsilon, Dataset, Cores, Time FROM data WHERE Dataset LIKE '20K'")
data40 = sqldf("SELECT Epsilon, Dataset, Cores, Time FROM data WHERE Dataset LIKE '40K'")
data60 = sqldf("SELECT Epsilon, Dataset, Cores, Time FROM data WHERE Dataset LIKE '60K'")
data80 = sqldf("SELECT Epsilon, Dataset, Cores, Time FROM data WHERE Dataset LIKE '80K'")
files = system(paste0("ls ",PHD_HOME,PATH,filename,"*.csv"), intern = T)
data = data.frame()
foreach(f = files) %do% {
data = rbind(data, read.table(f, header = F, sep = ">"))
}
data = as.data.frame(str_split_fixed(data[,2], ",", 12), stringsAsFactors = F)
data$V13 = 0
data$V1 = str_sub(2, str_trim(data$V1))
files = system(paste0("ls ",PHD_HOME,PATH,filename,"*.csv"), intern = T)
data = data.frame()
foreach(f = files) %do% {
data = rbind(data, read.table(f, header = F, sep = ">"))
}
data = as.data.frame(str_split_fixed(data[,2], ",", 12), stringsAsFactors = F)
data$V13 = 0
str_sub(str_trim(data$V1), 2)
str_sub(str_trim(data$V1), 1)
str_sub(str_trim(data$V1), 2)
files = system(paste0("ls ",PHD_HOME,PATH,filename,"*.csv"), intern = T)
data = data.frame()
foreach(f = files) %do% {
data = rbind(data, read.table(f, header = F, sep = ">"))
}
data = as.data.frame(str_split_fixed(data[,2], ",", 12), stringsAsFactors = F)
data$V13 = 0
data$V1 = str_sub(str_trim(data$V1), 2)
data[data$V1 == "B20K",13] = 7
data[data$V1 == "20K",13] = 7
data[data$V1 == "40K",13] = 14
data[data$V1 == "60K",13] = 21
data[data$V1 == "80K",13] = 28
data = data[, c(8, 1, 12, 13)]
names(data) = c("Epsilon", "Dataset", "Time", "Cores")
data20 = sqldf("SELECT Epsilon, Dataset, Cores, Time FROM data WHERE Dataset LIKE '20K'")
data40 = sqldf("SELECT Epsilon, Dataset, Cores, Time FROM data WHERE Dataset LIKE '40K'")
data60 = sqldf("SELECT Epsilon, Dataset, Cores, Time FROM data WHERE Dataset LIKE '60K'")
data80 = sqldf("SELECT Epsilon, Dataset, Cores, Time FROM data WHERE Dataset LIKE '80K'")
data = sqldf("SELECT Epsilon, Dataset, Cores, AVG(Time) AS Time FROM data GROUP BY 1, 2, 3")
data$Dataset = factor(data$Dataset, levels = paste0(seq(20, 80, 20), "K"))
data$Cores = factor(data$Cores)
temp_title = paste("(radius of disk in mts) in Berlin dataset (Partitions = 1024).")
title = substitute(paste("Scaleup by ", epsilon) ~ temp_title, list(temp_title = temp_title))
g = ggplot(data=data, aes(x=factor(Epsilon), y=Time, fill=Dataset)) +
geom_bar(stat="identity", position=position_dodge(width = 0.75),width = 0.75) +
labs(title=title, y="Time(s)", x=expression(paste(epsilon,"(mts)")))
plot(g)
sqldf.sql("SELECT * FROM data")
sqldf("SELECT * FROM data")
sqldf("SELECT Dataset, Epsilon, Cores, max(Time) FROM data GROUP BY 1, 2, 3")
PATH = "Y3Q1/Scripts/Scaleup/"
filename ="Berlin_N10K-50K_E10.0-50.0_M12_P1024_"
PHD_HOME = Sys.getenv(c("PHD_HOME"))
files = system(paste0("ls ",PHD_HOME,PATH,filename,"*.csv"), intern = T)
data = data.frame()
foreach(f = files) %do% {
data = rbind(data, read.table(f, header = F, sep = ">"))
}
data = as.data.frame(str_split_fixed(data[,2], ",", 12), stringsAsFactors = F)
data$V13 = 0
data$V1 = str_sub(str_trim(data$V1), 2)
data[data$V1 == "20K",13] = 7
data[data$V1 == "40K",13] = 14
data[data$V1 == "60K",13] = 21
data[data$V1 == "80K",13] = 28
data = data[, c(8, 1, 12, 13)]
names(data) = c("Epsilon", "Dataset", "Time", "Cores")
data$Time = as.numeric(data$Time)
data$Epsilon = as.numeric(data$Epsilon)
sqldf("SELECT Dataset, Epsilon, Cores, max(Time) FROM data GROUP BY 1, 2, 3")
maxs = sqldf("SELECT Dataset, Epsilon, Cores, max(Time) FROM data GROUP BY 1, 2, 3")
data
maxs
pacman::p_load(ggplot2, data.table, foreach, sqldf, tidyr, stringr, dplyr)
anti_join(data, maxs)
anti_join(data, maxs, by = c("Epsilon", "Dataset"))
anti_join(maxs, data, by = c("Epsilon", "Dataset"))
anti_join(maxs, data, by = "Time")
maxs
maxs = sqldf("SELECT Dataset, Epsilon, Cores, max(Time) AS Time FROM data GROUP BY 1, 2, 3")
anti_join(maxs, data, by = "Time")
data
maxs
anti_join(data, maxs, by = "Time")
anti_join(data, maxs, by = c("Time"))
anti_join(data, maxs, by = c("Dataset","Time"))
anti_join(data, maxs, by = c("Dataset", "Epsilon", "Time"))
