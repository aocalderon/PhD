\documentclass{article}
\usepackage{graphicx}
\usepackage{minted}
\usepackage{xcolor}
\usepackage{hyperref}
\hypersetup{
colorlinks=false,
hidelinks
}


\title{Milestone 1}
\author{Andres Calderon \\ acald013@ucr.edu}

\begin{document}
\maketitle

\section{Introduction}
This report describes the initial steps in order to accomplish the final project in the course. The main goal of the project is to perform a reliability analysis of a machine learning algorithm (kNN).  During this first milestone it is intedend to provide a flexible implementation of the kNN algorithm, a mechanism to inject random errors in the calculation of the distance metric and a brief analisys of the impact of an unreliable distance calculation.

\section{A flexible implementation of kNN}
There are many open source implementations of the kNN algorithm under different programming languages.  This report uses the R Project for Statistical Computing\footnote{https://www.r-project.org/} platform using especifically the knnflex\footnote{\url{http://ftp.uni-bayreuth.de/math/statlib/R/CRAN/src/contrib/Descriptions/knnflex.html}} package. The knnflex package allows a more flexible implementation of the distance metric as well the oportunity to code custom functions for aggregations and tie handlers.  In addition, it uses the caret package to compute the confusion matrix and associated statistics for the model fit.

\subsection{A quick classification example}
The code in figure \ref{fig:code} illustrates the use of knnflex to classify a small random set of features.  In lines 5 to 10 it sets the number of instances and a random seed, create two attributes with random numbers (x1 and x2) and a binary class (y).  Lines 11 and 12 divede the data set in training and testing set (75\% and 25\% respectively). Line 17 call the kdd.dist function which will generate a distance matrix among all the instances in the data set. Line 18 perform the classification calling the knn.predict function.  It takes the training and testing datasets, the distance matrix, the number of neighbors to be taken into account and the aggregation method to pick the class between them.  

Finally, line 22 calls the confusionMatrix function to retrieve the accuracy and other statistics from the model (figure \ref{fig:cm}). Lines 14 and 20 plot the initial instances in the training set and the result of the classification for the instances in the testing set.  Figures show the results respectively.

\begin{figure}
 \centering
 \inputminted[
  fontsize=\footnotesize,
  tabsize=2,
  breaklines,
  xleftmargin=15mm,
  frame=single,
  linenos
  ]{r}{example.R}
 \caption{A quick code example}\label{fig:code}
\end{figure}

<<example1, echo=FALSE, message=FALSE>>=
require(knnflex)
require(caret)

n <- 200
set.seed(123)
x1 <- c(rnorm(n/2,mean=2.5),rnorm(n/2,mean=7.5))
x2 <- c(rnorm(n/2,mean=7.5),rnorm(n/2,mean=2.5))
x  <- cbind(x1,x2)
y <- c(rep(1,n/2),rep(0,n/2))
train <- sample(1:n,n*0.75)
test <- (1:n)[-train]
kdist <- knn.dist(x)
preds <- knn.predict(train,test,y,kdist)
@

\begin{figure}
 \centering
<<example2, size='footnotesize'>>=
confusionMatrix(y[test],preds)
@
 \caption{Confusion matrix}\label{fig:cm}
\end{figure}

\begin{figure}
  \centering
  \includegraphics[width=0.6\textwidth]{ex1}
  \caption{Instances in training set.}\label{fig:train}
\end{figure}

\begin{figure}
  \centering
  \includegraphics[width=0.6\textwidth]{ex2}
  \caption{Results for instances in testing set.}\label{fig:test}
\end{figure}

\section{Error injector}
The code in figure \ref{fig:injector} takes the distance matrix generated in line 17 of figure \ref{fig:code} and introduces random errors.  A distance is changed according to a probability passed as second parameter. By default this value is set to 2\%.

\begin{figure}
 \centering
 \inputminted[
  fontsize=\footnotesize,
  tabsize=2,
  breaklines,
  xleftmargin=15mm,
  frame=single,
  linenos
  ]{r}{ErrorInjector.R}
 \caption{Code for error injection}\label{fig:injector}
\end{figure}

For example, given the small 5x5 distance matrix shown in figure \ref{fig:kdist}, it can be seen the effect of the injectError function.  It shows that in position (1,2) an error was injected.

\begin{figure}
 \centering
 \inputminted[
  fontsize=\footnotesize,
  tabsize=2,
  breaklines,
  xleftmargin=15mm,
  frame=single
  ]{r}{kdist.txt}
 \caption{Error injection example}\label{fig:kdist}
\end{figure}

\section{Simulations}
The code in figure \ref{fig:iris} is used to perform a simulation using the iris data set.  The original accuracy is stored in the line 13. Then, it runs 1000 iterations where errors are injected to the distance matrix and new predictions are performed.  The accuracies for the new experiments are stored in an array (line 22).  The last 5 lines display a summary of statistics for the run and plot the results (figures \ref{fig:output} and \ref{fig:sim}). From figure \ref{fig:output} we can see that mean of the accuracies during the run is the same that the original accuracy, the standard deviation of the run was just 0.002 and in 95\% of the cases kNN still gives the correct results.   

\begin{figure}
 \centering
 \inputminted[
  fontsize=\footnotesize,
  tabsize=2,
  breaklines,
  xleftmargin=15mm,
  frame=single,
  linenos
  ]{r}{simulation.R}
 \caption{Simulation in the iris data set}\label{fig:iris}
\end{figure}

\begin{figure}
 \centering
 \inputminted[
  fontsize=\footnotesize,
  tabsize=2,
  breaklines,
  xleftmargin=15mm,
  frame=single
  ]{r}{sim.txt}
 \caption{Error injection example}\label{fig:output}
\end{figure}

\begin{figure}
  \centering
  \includegraphics[width=\textwidth]{sim}
  \caption{Accuracies after error injection.  Red line shows the original accuracy.}\label{fig:sim}
\end{figure}


\end{document}