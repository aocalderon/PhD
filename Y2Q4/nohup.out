Running in 28 cores and 1024 partitions...
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
17/09/13 16:07:22 INFO SparkContext: Running Spark version 2.1.0
17/09/13 16:07:22 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/09/13 16:07:23 INFO SecurityManager: Changing view acls to: acald013
17/09/13 16:07:23 INFO SecurityManager: Changing modify acls to: acald013
17/09/13 16:07:23 INFO SecurityManager: Changing view acls groups to: 
17/09/13 16:07:23 INFO SecurityManager: Changing modify acls groups to: 
17/09/13 16:07:23 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(acald013); groups with view permissions: Set(); users  with modify permissions: Set(acald013); groups with modify permissions: Set()
17/09/13 16:07:23 INFO Utils: Successfully started service 'sparkDriver' on port 35205.
17/09/13 16:07:23 INFO SparkEnv: Registering MapOutputTracker
17/09/13 16:07:23 INFO SparkEnv: Registering BlockManagerMaster
17/09/13 16:07:23 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/09/13 16:07:23 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/09/13 16:07:23 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-e5607649-8fce-4c78-95cc-7ccb9038afa2
17/09/13 16:07:23 INFO MemoryStore: MemoryStore started with capacity 6.2 GB
17/09/13 16:07:23 INFO SparkEnv: Registering OutputCommitCoordinator
17/09/13 16:07:24 INFO Utils: Successfully started service 'SparkUI' on port 4040.
17/09/13 16:07:24 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://169.235.27.138:4040
17/09/13 16:07:24 INFO SparkContext: Added JAR file:/home/acald013/PhD/Y2Q4/PFlock/target/scala-2.11/pflock_2.11-1.0.jar at spark://169.235.27.138:35205/jars/pflock_2.11-1.0.jar with timestamp 1505344044176
17/09/13 16:07:24 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://169.235.27.138:7077...
17/09/13 16:07:24 INFO TransportClientFactory: Successfully created connection to /169.235.27.138:7077 after 46 ms (0 ms spent in bootstraps)
17/09/13 16:07:24 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20170913160724-0006
17/09/13 16:07:24 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20170913160724-0006/0 on worker-20170913113532-169.235.27.138-44944 (169.235.27.138:44944) with 7 cores
17/09/13 16:07:24 INFO StandaloneSchedulerBackend: Granted executor ID app-20170913160724-0006/0 on hostPort 169.235.27.138:44944 with 7 cores, 12.0 GB RAM
17/09/13 16:07:24 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20170913160724-0006/1 on worker-20170913113531-169.235.27.135-39694 (169.235.27.135:39694) with 7 cores
17/09/13 16:07:24 INFO StandaloneSchedulerBackend: Granted executor ID app-20170913160724-0006/1 on hostPort 169.235.27.135:39694 with 7 cores, 12.0 GB RAM
17/09/13 16:07:24 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20170913160724-0006/2 on worker-20170913113530-169.235.27.137-38262 (169.235.27.137:38262) with 7 cores
17/09/13 16:07:24 INFO StandaloneSchedulerBackend: Granted executor ID app-20170913160724-0006/2 on hostPort 169.235.27.137:38262 with 7 cores, 12.0 GB RAM
17/09/13 16:07:24 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45007.
17/09/13 16:07:24 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20170913160724-0006/3 on worker-20170913113534-169.235.27.134-34719 (169.235.27.134:34719) with 7 cores
17/09/13 16:07:24 INFO StandaloneSchedulerBackend: Granted executor ID app-20170913160724-0006/3 on hostPort 169.235.27.134:34719 with 7 cores, 12.0 GB RAM
17/09/13 16:07:24 INFO NettyBlockTransferService: Server created on 169.235.27.138:45007
17/09/13 16:07:24 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/09/13 16:07:24 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 169.235.27.138, 45007, None)
17/09/13 16:07:24 INFO BlockManagerMasterEndpoint: Registering block manager 169.235.27.138:45007 with 6.2 GB RAM, BlockManagerId(driver, 169.235.27.138, 45007, None)
17/09/13 16:07:24 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20170913160724-0006/0 is now RUNNING
17/09/13 16:07:24 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 169.235.27.138, 45007, None)
17/09/13 16:07:24 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20170913160724-0006/2 is now RUNNING
17/09/13 16:07:24 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 169.235.27.138, 45007, None)
17/09/13 16:07:24 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20170913160724-0006/3 is now RUNNING
17/09/13 16:07:24 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20170913160724-0006/1 is now RUNNING
17/09/13 16:07:25 INFO EventLoggingListener: Logging events to file:///home/acald013/Logs/app-20170913160724-0006
17/09/13 16:07:25 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
17/09/13 16:07:25 INFO SharedState: Warehouse path is 'file:/home/acald013/PhD/Y2Q4/spark-warehouse/'.
Running app-20170913160724-0006 on 28 cores and 1024 partitions...
       Tag    Epsilon    Dataset      TimeD      TimeM  TotalTime NCandidate   NMaximal      Cores Partitions       Timestamp
17/09/13 16:07:59 ERROR LiveListenerBus: Dropping SparkListenerEvent because no remaining room in event queue. This likely means one of the SparkListeners is too slow and cannot keep up with the rate at which tasks are being started by the scheduler.
    PFlock       10.0       160K     66.323      7.226     73.549     229234       7135         28       1024    16:08:40.212
    PFlock       20.0       160K     49.335      8.203     57.538     531344      41314         28       1024    16:09:40.613
    PFlock       30.0       160K     55.680     10.384     66.064     879724     118304         28       1024    16:10:50.879
    PFlock       40.0       160K     63.542     13.892     77.434    1281430     271297         28       1024    16:12:14.831
    PFlock       50.0       160K     76.235     16.643     92.878    1720770     502989         28       1024    16:13:59.164
    PFlock       60.0       160K     84.012     20.575    104.587    2200784     815071         28       1024    16:16:02.001
    PFlock       70.0       160K     98.143     25.926    124.069    2723892    1211964         28       1024    16:18:37.250
    PFlock       80.0       160K    108.237     27.776    136.013    3293358    1694406         28       1024    16:21:39.931
    PFlock       90.0       160K    120.134     33.642    153.776    3914498    2267421         28       1024    16:25:19.644
    PFlock      100.0       160K    128.726     37.950    166.676    4599964    2936755         28       1024    16:29:37.343
17/09/13 16:31:38 ERROR LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerBlockUpdated(BlockUpdatedInfo(BlockManagerId(driver, 169.235.27.138, 45007, None),broadcast_664_piece0,StorageLevel(1 replicas),0,0))
Done!!!
Running in 28 cores and 512 partitions...
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
17/09/13 16:31:43 INFO SparkContext: Running Spark version 2.1.0
17/09/13 16:31:44 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/09/13 16:31:44 INFO SecurityManager: Changing view acls to: acald013
17/09/13 16:31:44 INFO SecurityManager: Changing modify acls to: acald013
17/09/13 16:31:44 INFO SecurityManager: Changing view acls groups to: 
17/09/13 16:31:44 INFO SecurityManager: Changing modify acls groups to: 
17/09/13 16:31:44 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(acald013); groups with view permissions: Set(); users  with modify permissions: Set(acald013); groups with modify permissions: Set()
17/09/13 16:31:44 INFO Utils: Successfully started service 'sparkDriver' on port 34119.
17/09/13 16:31:44 INFO SparkEnv: Registering MapOutputTracker
17/09/13 16:31:44 INFO SparkEnv: Registering BlockManagerMaster
17/09/13 16:31:44 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/09/13 16:31:44 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/09/13 16:31:44 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-9d4c0fd4-6924-4cf0-b243-c746a98fd0c4
17/09/13 16:31:44 INFO MemoryStore: MemoryStore started with capacity 6.2 GB
17/09/13 16:31:44 INFO SparkEnv: Registering OutputCommitCoordinator
17/09/13 16:31:45 INFO Utils: Successfully started service 'SparkUI' on port 4040.
17/09/13 16:31:45 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://169.235.27.138:4040
17/09/13 16:31:45 INFO SparkContext: Added JAR file:/home/acald013/PhD/Y2Q4/PFlock/target/scala-2.11/pflock_2.11-1.0.jar at spark://169.235.27.138:34119/jars/pflock_2.11-1.0.jar with timestamp 1505345505473
17/09/13 16:31:45 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://169.235.27.138:7077...
17/09/13 16:31:45 INFO TransportClientFactory: Successfully created connection to /169.235.27.138:7077 after 46 ms (0 ms spent in bootstraps)
17/09/13 16:31:45 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20170913163145-0007
17/09/13 16:31:45 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20170913163145-0007/0 on worker-20170913113532-169.235.27.138-44944 (169.235.27.138:44944) with 7 cores
17/09/13 16:31:45 INFO StandaloneSchedulerBackend: Granted executor ID app-20170913163145-0007/0 on hostPort 169.235.27.138:44944 with 7 cores, 12.0 GB RAM
17/09/13 16:31:45 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20170913163145-0007/1 on worker-20170913113531-169.235.27.135-39694 (169.235.27.135:39694) with 7 cores
17/09/13 16:31:45 INFO StandaloneSchedulerBackend: Granted executor ID app-20170913163145-0007/1 on hostPort 169.235.27.135:39694 with 7 cores, 12.0 GB RAM
17/09/13 16:31:45 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20170913163145-0007/2 on worker-20170913113530-169.235.27.137-38262 (169.235.27.137:38262) with 7 cores
17/09/13 16:31:45 INFO StandaloneSchedulerBackend: Granted executor ID app-20170913163145-0007/2 on hostPort 169.235.27.137:38262 with 7 cores, 12.0 GB RAM
17/09/13 16:31:45 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20170913163145-0007/3 on worker-20170913113534-169.235.27.134-34719 (169.235.27.134:34719) with 7 cores
17/09/13 16:31:45 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42698.
17/09/13 16:31:45 INFO StandaloneSchedulerBackend: Granted executor ID app-20170913163145-0007/3 on hostPort 169.235.27.134:34719 with 7 cores, 12.0 GB RAM
17/09/13 16:31:45 INFO NettyBlockTransferService: Server created on 169.235.27.138:42698
17/09/13 16:31:45 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/09/13 16:31:45 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 169.235.27.138, 42698, None)
17/09/13 16:31:45 INFO BlockManagerMasterEndpoint: Registering block manager 169.235.27.138:42698 with 6.2 GB RAM, BlockManagerId(driver, 169.235.27.138, 42698, None)
17/09/13 16:31:45 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20170913163145-0007/1 is now RUNNING
17/09/13 16:31:45 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20170913163145-0007/0 is now RUNNING
17/09/13 16:31:45 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 169.235.27.138, 42698, None)
17/09/13 16:31:45 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20170913163145-0007/3 is now RUNNING
17/09/13 16:31:45 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20170913163145-0007/2 is now RUNNING
17/09/13 16:31:45 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 169.235.27.138, 42698, None)
17/09/13 16:31:46 INFO EventLoggingListener: Logging events to file:///home/acald013/Logs/app-20170913163145-0007
17/09/13 16:31:46 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
17/09/13 16:31:46 INFO SharedState: Warehouse path is 'file:/home/acald013/PhD/Y2Q4/spark-warehouse/'.
Running app-20170913163145-0007 on 28 cores and 512 partitions...
       Tag    Epsilon    Dataset      TimeD      TimeM  TotalTime NCandidate   NMaximal      Cores Partitions       Timestamp
    PFlock       10.0       160K     69.266      8.344     77.610     229234       7135         28        529    16:33:05.658
    PFlock       20.0       160K     46.107      8.979     55.086     531344      41314         28        529    16:34:03.247
    PFlock       30.0       160K     53.123     11.126     64.249     879724     118304         28        529    16:35:10.977
    PFlock       40.0       160K     61.083     14.491     75.574    1281430     271297         28        529    16:36:32.244
    PFlock       50.0       160K     75.161     18.340     93.501    1720770     502989         28        529    16:38:16.321
    PFlock       60.0       160K     84.752     20.911    105.663    2200784     815071         28        529    16:40:18.842
    PFlock       70.0       160K     96.489     25.904    122.393    2723892    1211964         28        529    16:42:47.936
    PFlock       80.0       160K    108.029     27.258    135.287    3293358    1694406         28        529    16:45:49.600
    PFlock       90.0       160K    113.139     39.853    152.992    3914498    2267421         28        529    16:49:27.580
    PFlock      100.0       160K    126.361     46.746    173.107    4599964    2936755         28        529    16:53:52.163
Done!!!
Running in 28 cores and 256 partitions...
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
17/09/13 16:56:00 INFO SparkContext: Running Spark version 2.1.0
17/09/13 16:56:00 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/09/13 16:56:00 INFO SecurityManager: Changing view acls to: acald013
17/09/13 16:56:00 INFO SecurityManager: Changing modify acls to: acald013
17/09/13 16:56:00 INFO SecurityManager: Changing view acls groups to: 
17/09/13 16:56:00 INFO SecurityManager: Changing modify acls groups to: 
17/09/13 16:56:00 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(acald013); groups with view permissions: Set(); users  with modify permissions: Set(acald013); groups with modify permissions: Set()
17/09/13 16:56:01 INFO Utils: Successfully started service 'sparkDriver' on port 42808.
17/09/13 16:56:01 INFO SparkEnv: Registering MapOutputTracker
17/09/13 16:56:01 INFO SparkEnv: Registering BlockManagerMaster
17/09/13 16:56:01 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/09/13 16:56:01 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/09/13 16:56:01 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-071dac13-b9c9-43c4-8a4c-e77d59cd94bd
17/09/13 16:56:01 INFO MemoryStore: MemoryStore started with capacity 6.2 GB
17/09/13 16:56:01 INFO SparkEnv: Registering OutputCommitCoordinator
17/09/13 16:56:02 INFO Utils: Successfully started service 'SparkUI' on port 4040.
17/09/13 16:56:02 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://169.235.27.138:4040
17/09/13 16:56:02 INFO SparkContext: Added JAR file:/home/acald013/PhD/Y2Q4/PFlock/target/scala-2.11/pflock_2.11-1.0.jar at spark://169.235.27.138:42808/jars/pflock_2.11-1.0.jar with timestamp 1505346962198
17/09/13 16:56:02 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://169.235.27.138:7077...
17/09/13 16:56:02 INFO TransportClientFactory: Successfully created connection to /169.235.27.138:7077 after 47 ms (0 ms spent in bootstraps)
17/09/13 16:56:02 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20170913165602-0008
17/09/13 16:56:02 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20170913165602-0008/0 on worker-20170913113532-169.235.27.138-44944 (169.235.27.138:44944) with 7 cores
17/09/13 16:56:02 INFO StandaloneSchedulerBackend: Granted executor ID app-20170913165602-0008/0 on hostPort 169.235.27.138:44944 with 7 cores, 12.0 GB RAM
17/09/13 16:56:02 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20170913165602-0008/1 on worker-20170913113531-169.235.27.135-39694 (169.235.27.135:39694) with 7 cores
17/09/13 16:56:02 INFO StandaloneSchedulerBackend: Granted executor ID app-20170913165602-0008/1 on hostPort 169.235.27.135:39694 with 7 cores, 12.0 GB RAM
17/09/13 16:56:02 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20170913165602-0008/2 on worker-20170913113530-169.235.27.137-38262 (169.235.27.137:38262) with 7 cores
17/09/13 16:56:02 INFO StandaloneSchedulerBackend: Granted executor ID app-20170913165602-0008/2 on hostPort 169.235.27.137:38262 with 7 cores, 12.0 GB RAM
17/09/13 16:56:02 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38950.
17/09/13 16:56:02 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20170913165602-0008/3 on worker-20170913113534-169.235.27.134-34719 (169.235.27.134:34719) with 7 cores
17/09/13 16:56:02 INFO StandaloneSchedulerBackend: Granted executor ID app-20170913165602-0008/3 on hostPort 169.235.27.134:34719 with 7 cores, 12.0 GB RAM
17/09/13 16:56:02 INFO NettyBlockTransferService: Server created on 169.235.27.138:38950
17/09/13 16:56:02 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/09/13 16:56:02 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 169.235.27.138, 38950, None)
17/09/13 16:56:02 INFO BlockManagerMasterEndpoint: Registering block manager 169.235.27.138:38950 with 6.2 GB RAM, BlockManagerId(driver, 169.235.27.138, 38950, None)
17/09/13 16:56:02 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20170913165602-0008/1 is now RUNNING
17/09/13 16:56:02 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20170913165602-0008/0 is now RUNNING
17/09/13 16:56:02 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20170913165602-0008/2 is now RUNNING
17/09/13 16:56:02 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 169.235.27.138, 38950, None)
17/09/13 16:56:02 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 169.235.27.138, 38950, None)
17/09/13 16:56:02 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20170913165602-0008/3 is now RUNNING
17/09/13 16:56:03 INFO EventLoggingListener: Logging events to file:///home/acald013/Logs/app-20170913165602-0008
17/09/13 16:56:03 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
17/09/13 16:56:03 INFO SharedState: Warehouse path is 'file:/home/acald013/PhD/Y2Q4/spark-warehouse/'.
Running app-20170913165602-0008 on 28 cores and 256 partitions...
       Tag    Epsilon    Dataset      TimeD      TimeM  TotalTime NCandidate   NMaximal      Cores Partitions       Timestamp
    PFlock       10.0       160K     52.020      7.470     59.490     229234       7135         28        256    16:57:04.121
    PFlock       20.0       160K     44.822      9.652     54.474     531344      41314         28        256    16:58:00.705
    PFlock       30.0       160K     46.284     10.232     56.516     879724     118304         28        256    16:59:00.349
    PFlock       40.0       160K     52.659     12.717     65.376    1281430     271297         28        256    17:00:10.738
    PFlock       50.0       160K     70.644     19.725     90.369    1720770     502989         28        256    17:01:50.465
    PFlock       60.0       160K     67.569     22.911     90.480    2200784     815071         28        256    17:03:37.359
    PFlock       70.0       160K     80.324     26.287    106.611    2723892    1211964         28        256    17:05:51.297
    PFlock       80.0       160K     88.676     32.719    121.395    3293358    1694406         28        256    17:08:40.381
    PFlock       90.0       160K     98.910     30.639    129.549    3914498    2267421         28        256    17:11:55.667
    PFlock      100.0       160K    115.817     36.352    152.169    4599964    2936755         28        256    17:15:58.155
Done!!!
