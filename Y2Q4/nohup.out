Running in 18 cores and 2500 partitions...
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
17/09/12 16:37:03 INFO SparkContext: Running Spark version 2.1.0
17/09/12 16:37:03 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/09/12 16:37:03 INFO SecurityManager: Changing view acls to: acald013
17/09/12 16:37:03 INFO SecurityManager: Changing modify acls to: acald013
17/09/12 16:37:03 INFO SecurityManager: Changing view acls groups to: 
17/09/12 16:37:03 INFO SecurityManager: Changing modify acls groups to: 
17/09/12 16:37:03 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(acald013); groups with view permissions: Set(); users  with modify permissions: Set(acald013); groups with modify permissions: Set()
17/09/12 16:37:03 INFO Utils: Successfully started service 'sparkDriver' on port 37607.
17/09/12 16:37:03 INFO SparkEnv: Registering MapOutputTracker
17/09/12 16:37:03 INFO SparkEnv: Registering BlockManagerMaster
17/09/12 16:37:03 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/09/12 16:37:03 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/09/12 16:37:03 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-88edd2ea-e95d-4735-b671-59b2a36eba35
17/09/12 16:37:03 INFO MemoryStore: MemoryStore started with capacity 6.2 GB
17/09/12 16:37:03 INFO SparkEnv: Registering OutputCommitCoordinator
17/09/12 16:37:03 INFO Utils: Successfully started service 'SparkUI' on port 4040.
17/09/12 16:37:03 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://169.235.27.134:4040
17/09/12 16:37:04 INFO SparkContext: Added JAR file:/home/acald013/PhD/Y2Q4/PFlock/target/scala-2.11/pflock_2.11-1.0.jar at spark://169.235.27.134:37607/jars/pflock_2.11-1.0.jar with timestamp 1505259424001
17/09/12 16:37:04 INFO SparkContext: Added file file:/home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/conf/metrics.properties at spark://169.235.27.134:37607/files/metrics.properties with timestamp 1505259424141
17/09/12 16:37:04 INFO Utils: Copying /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/conf/metrics.properties to /tmp/spark-24293795-f333-44b1-87e9-68cac72e9834/userFiles-48fc5c8e-41d2-474b-8a13-6102240d8a78/metrics.properties
17/09/12 16:37:04 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://169.235.27.134:7077...
17/09/12 16:37:04 INFO TransportClientFactory: Successfully created connection to /169.235.27.134:7077 after 27 ms (0 ms spent in bootstraps)
17/09/12 16:37:04 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20170912163704-0000
17/09/12 16:37:04 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39509.
17/09/12 16:37:04 INFO NettyBlockTransferService: Server created on 169.235.27.134:39509
17/09/12 16:37:04 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/09/12 16:37:04 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 169.235.27.134, 39509, None)
17/09/12 16:37:04 INFO BlockManagerMasterEndpoint: Registering block manager 169.235.27.134:39509 with 6.2 GB RAM, BlockManagerId(driver, 169.235.27.134, 39509, None)
17/09/12 16:37:04 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 169.235.27.134, 39509, None)
17/09/12 16:37:04 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 169.235.27.134, 39509, None)
17/09/12 16:37:04 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20170912163704-0000/0 on worker-20170912163633-169.235.27.135-37998 (169.235.27.135:37998) with 6 cores
17/09/12 16:37:04 INFO StandaloneSchedulerBackend: Granted executor ID app-20170912163704-0000/0 on hostPort 169.235.27.135:37998 with 6 cores, 12.0 GB RAM
17/09/12 16:37:04 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20170912163704-0000/1 on worker-20170912163632-169.235.27.137-34076 (169.235.27.137:34076) with 6 cores
17/09/12 16:37:04 INFO StandaloneSchedulerBackend: Granted executor ID app-20170912163704-0000/1 on hostPort 169.235.27.137:34076 with 6 cores, 12.0 GB RAM
17/09/12 16:37:04 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20170912163704-0000/2 on worker-20170912163632-169.235.27.134-38244 (169.235.27.134:38244) with 6 cores
17/09/12 16:37:04 INFO StandaloneSchedulerBackend: Granted executor ID app-20170912163704-0000/2 on hostPort 169.235.27.134:38244 with 6 cores, 12.0 GB RAM
17/09/12 16:37:04 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20170912163704-0000/0 is now RUNNING
17/09/12 16:37:04 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20170912163704-0000/2 is now RUNNING
17/09/12 16:37:04 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20170912163704-0000/1 is now RUNNING
17/09/12 16:37:04 INFO EventLoggingListener: Logging events to file:///home/acald013/Spark/Logs/app-20170912163704-0000
17/09/12 16:37:04 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
17/09/12 16:37:04 INFO SharedState: Warehouse path is 'file:/home/acald013/PhD/Y2Q4/spark-warehouse/'.
Running app-20170912163704-0000 on 18 cores and 2500 partitions...
       Tag    Epsilon    Dataset      TimeD      TimeM  TotalTime NCandidate   NMaximal      Cores Partitions       Timestamp
17/09/12 16:37:25 ERROR LiveListenerBus: Dropping SparkListenerEvent because no remaining room in event queue. This likely means one of the SparkListeners is too slow and cannot keep up with the rate at which tasks are being started by the scheduler.
Exception in thread "main" org.apache.spark.SparkException: Job 33 cancelled 
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435)
	at org.apache.spark.scheduler.DAGScheduler.handleJobCancellation(DAGScheduler.scala:1375)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1622)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1605)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1594)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:628)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1918)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1931)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1944)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1958)
	at org.apache.spark.rdd.RDD.count(RDD.scala:1157)
	at PFlock$$anonfun$main$1$$anonfun$apply$mcVI$sp$1.apply$mcVD$sp(PFlock.scala:117)
	at PFlock$$anonfun$main$1$$anonfun$apply$mcVI$sp$1.apply(PFlock.scala:57)
	at PFlock$$anonfun$main$1$$anonfun$apply$mcVI$sp$1.apply(PFlock.scala:57)
	at scala.collection.immutable.NumericRange.foreach(NumericRange.scala:73)
	at PFlock$$anonfun$main$1.apply$mcVI$sp(PFlock.scala:57)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at PFlock$.main(PFlock.scala:56)
	at PFlock.main(PFlock.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:738)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:187)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:212)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:126)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
Done!!!
Running in 18 cores and 2250 partitions...
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
17/09/12 16:51:33 INFO SparkContext: Running Spark version 2.1.0
17/09/12 16:51:33 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/09/12 16:51:33 INFO SecurityManager: Changing view acls to: acald013
17/09/12 16:51:33 INFO SecurityManager: Changing modify acls to: acald013
17/09/12 16:51:33 INFO SecurityManager: Changing view acls groups to: 
17/09/12 16:51:33 INFO SecurityManager: Changing modify acls groups to: 
17/09/12 16:51:33 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(acald013); groups with view permissions: Set(); users  with modify permissions: Set(acald013); groups with modify permissions: Set()
17/09/12 16:51:34 INFO Utils: Successfully started service 'sparkDriver' on port 42458.
17/09/12 16:51:34 INFO SparkEnv: Registering MapOutputTracker
17/09/12 16:51:34 INFO SparkEnv: Registering BlockManagerMaster
17/09/12 16:51:34 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/09/12 16:51:34 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/09/12 16:51:34 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-ededc812-a54b-4504-94b6-5880ff7b4497
17/09/12 16:51:34 INFO MemoryStore: MemoryStore started with capacity 6.2 GB
17/09/12 16:51:34 INFO SparkEnv: Registering OutputCommitCoordinator
17/09/12 16:51:34 INFO Utils: Successfully started service 'SparkUI' on port 4040.
17/09/12 16:51:34 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://169.235.27.134:4040
17/09/12 16:51:34 INFO SparkContext: Added JAR file:/home/acald013/PhD/Y2Q4/PFlock/target/scala-2.11/pflock_2.11-1.0.jar at spark://169.235.27.134:42458/jars/pflock_2.11-1.0.jar with timestamp 1505260294454
17/09/12 16:51:34 INFO SparkContext: Added file file:/home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/conf/metrics.properties at spark://169.235.27.134:42458/files/metrics.properties with timestamp 1505260294600
17/09/12 16:51:34 INFO Utils: Copying /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/conf/metrics.properties to /tmp/spark-6a2e5e57-1a22-43a1-9c17-6918d4234972/userFiles-ac4428dc-4957-48af-952d-853902f8e38e/metrics.properties
17/09/12 16:51:34 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://169.235.27.134:7077...
17/09/12 16:51:34 INFO TransportClientFactory: Successfully created connection to /169.235.27.134:7077 after 27 ms (0 ms spent in bootstraps)
17/09/12 16:51:34 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20170912165134-0001
17/09/12 16:51:34 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20170912165134-0001/0 on worker-20170912163633-169.235.27.135-37998 (169.235.27.135:37998) with 6 cores
17/09/12 16:51:34 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46070.
17/09/12 16:51:34 INFO StandaloneSchedulerBackend: Granted executor ID app-20170912165134-0001/0 on hostPort 169.235.27.135:37998 with 6 cores, 12.0 GB RAM
17/09/12 16:51:34 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20170912165134-0001/1 on worker-20170912163632-169.235.27.137-34076 (169.235.27.137:34076) with 6 cores
17/09/12 16:51:34 INFO StandaloneSchedulerBackend: Granted executor ID app-20170912165134-0001/1 on hostPort 169.235.27.137:34076 with 6 cores, 12.0 GB RAM
17/09/12 16:51:34 INFO NettyBlockTransferService: Server created on 169.235.27.134:46070
17/09/12 16:51:34 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/09/12 16:51:34 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20170912165134-0001/2 on worker-20170912163632-169.235.27.134-38244 (169.235.27.134:38244) with 6 cores
17/09/12 16:51:34 INFO StandaloneSchedulerBackend: Granted executor ID app-20170912165134-0001/2 on hostPort 169.235.27.134:38244 with 6 cores, 12.0 GB RAM
17/09/12 16:51:34 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 169.235.27.134, 46070, None)
17/09/12 16:51:34 INFO BlockManagerMasterEndpoint: Registering block manager 169.235.27.134:46070 with 6.2 GB RAM, BlockManagerId(driver, 169.235.27.134, 46070, None)
17/09/12 16:51:34 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 169.235.27.134, 46070, None)
17/09/12 16:51:34 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 169.235.27.134, 46070, None)
17/09/12 16:51:34 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20170912165134-0001/0 is now RUNNING
17/09/12 16:51:34 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20170912165134-0001/1 is now RUNNING
17/09/12 16:51:34 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20170912165134-0001/2 is now RUNNING
17/09/12 16:51:35 INFO EventLoggingListener: Logging events to file:///home/acald013/Spark/Logs/app-20170912165134-0001
17/09/12 16:51:35 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
17/09/12 16:51:35 INFO SharedState: Warehouse path is 'file:/home/acald013/PhD/Y2Q4/spark-warehouse/'.
Running app-20170912165134-0001 on 18 cores and 2250 partitions...
       Tag    Epsilon    Dataset      TimeD      TimeM  TotalTime NCandidate   NMaximal      Cores Partitions       Timestamp
17/09/12 16:51:55 ERROR LiveListenerBus: Dropping SparkListenerEvent because no remaining room in event queue. This likely means one of the SparkListeners is too slow and cannot keep up with the rate at which tasks are being started by the scheduler.
Exception in thread "main" org.apache.spark.SparkException: Job 33 cancelled 
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435)
	at org.apache.spark.scheduler.DAGScheduler.handleJobCancellation(DAGScheduler.scala:1375)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1622)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1605)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1594)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:628)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1918)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1931)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1944)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1958)
	at org.apache.spark.rdd.RDD.count(RDD.scala:1157)
	at PFlock$$anonfun$main$1$$anonfun$apply$mcVI$sp$1.apply$mcVD$sp(PFlock.scala:117)
	at PFlock$$anonfun$main$1$$anonfun$apply$mcVI$sp$1.apply(PFlock.scala:57)
	at PFlock$$anonfun$main$1$$anonfun$apply$mcVI$sp$1.apply(PFlock.scala:57)
	at scala.collection.immutable.NumericRange.foreach(NumericRange.scala:73)
	at PFlock$$anonfun$main$1.apply$mcVI$sp(PFlock.scala:57)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at PFlock$.main(PFlock.scala:56)
	at PFlock.main(PFlock.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:738)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:187)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:212)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:126)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
Done!!!
Running in 18 cores and 2000 partitions...
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
17/09/12 16:58:47 INFO SparkContext: Running Spark version 2.1.0
17/09/12 16:58:47 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/09/12 16:58:47 INFO SecurityManager: Changing view acls to: acald013
17/09/12 16:58:47 INFO SecurityManager: Changing modify acls to: acald013
17/09/12 16:58:47 INFO SecurityManager: Changing view acls groups to: 
17/09/12 16:58:47 INFO SecurityManager: Changing modify acls groups to: 
17/09/12 16:58:47 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(acald013); groups with view permissions: Set(); users  with modify permissions: Set(acald013); groups with modify permissions: Set()
17/09/12 16:58:47 INFO Utils: Successfully started service 'sparkDriver' on port 38504.
17/09/12 16:58:47 INFO SparkEnv: Registering MapOutputTracker
17/09/12 16:58:47 INFO SparkEnv: Registering BlockManagerMaster
17/09/12 16:58:47 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/09/12 16:58:47 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/09/12 16:58:47 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-f53ce64f-4754-484b-a8cc-f5a0599e4a3a
17/09/12 16:58:47 INFO MemoryStore: MemoryStore started with capacity 6.2 GB
17/09/12 16:58:47 INFO SparkEnv: Registering OutputCommitCoordinator
17/09/12 16:58:47 INFO Utils: Successfully started service 'SparkUI' on port 4040.
17/09/12 16:58:47 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://169.235.27.134:4040
17/09/12 16:58:47 INFO SparkContext: Added JAR file:/home/acald013/PhD/Y2Q4/PFlock/target/scala-2.11/pflock_2.11-1.0.jar at spark://169.235.27.134:38504/jars/pflock_2.11-1.0.jar with timestamp 1505260727929
17/09/12 16:58:48 INFO SparkContext: Added file file:/home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/conf/metrics.properties at spark://169.235.27.134:38504/files/metrics.properties with timestamp 1505260728083
17/09/12 16:58:48 INFO Utils: Copying /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/conf/metrics.properties to /tmp/spark-d345f926-e70e-4b3e-b59a-180b4de5c931/userFiles-01955bf1-336c-4b42-a45a-38fc2e9d606a/metrics.properties
17/09/12 16:58:48 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://169.235.27.134:7077...
17/09/12 16:58:48 INFO TransportClientFactory: Successfully created connection to /169.235.27.134:7077 after 18 ms (0 ms spent in bootstraps)
17/09/12 16:58:48 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20170912165848-0002
17/09/12 16:58:48 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20170912165848-0002/0 on worker-20170912163633-169.235.27.135-37998 (169.235.27.135:37998) with 6 cores
17/09/12 16:58:48 INFO StandaloneSchedulerBackend: Granted executor ID app-20170912165848-0002/0 on hostPort 169.235.27.135:37998 with 6 cores, 12.0 GB RAM
17/09/12 16:58:48 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20170912165848-0002/1 on worker-20170912163632-169.235.27.137-34076 (169.235.27.137:34076) with 6 cores
17/09/12 16:58:48 INFO StandaloneSchedulerBackend: Granted executor ID app-20170912165848-0002/1 on hostPort 169.235.27.137:34076 with 6 cores, 12.0 GB RAM
17/09/12 16:58:48 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35270.
17/09/12 16:58:48 INFO NettyBlockTransferService: Server created on 169.235.27.134:35270
17/09/12 16:58:48 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/09/12 16:58:48 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20170912165848-0002/2 on worker-20170912163632-169.235.27.134-38244 (169.235.27.134:38244) with 6 cores
17/09/12 16:58:48 INFO StandaloneSchedulerBackend: Granted executor ID app-20170912165848-0002/2 on hostPort 169.235.27.134:38244 with 6 cores, 12.0 GB RAM
17/09/12 16:58:48 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 169.235.27.134, 35270, None)
17/09/12 16:58:48 INFO BlockManagerMasterEndpoint: Registering block manager 169.235.27.134:35270 with 6.2 GB RAM, BlockManagerId(driver, 169.235.27.134, 35270, None)
17/09/12 16:58:48 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 169.235.27.134, 35270, None)
17/09/12 16:58:48 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 169.235.27.134, 35270, None)
17/09/12 16:58:48 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20170912165848-0002/0 is now RUNNING
17/09/12 16:58:48 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20170912165848-0002/2 is now RUNNING
17/09/12 16:58:48 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20170912165848-0002/1 is now RUNNING
17/09/12 16:58:48 INFO EventLoggingListener: Logging events to file:///home/acald013/Spark/Logs/app-20170912165848-0002
17/09/12 16:58:48 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
17/09/12 16:58:48 INFO SharedState: Warehouse path is 'file:/home/acald013/PhD/Y2Q4/spark-warehouse/'.
Running app-20170912165848-0002 on 18 cores and 2000 partitions...
       Tag    Epsilon    Dataset      TimeD      TimeM  TotalTime NCandidate   NMaximal      Cores Partitions       Timestamp
17/09/12 16:59:17 ERROR LiveListenerBus: Dropping SparkListenerEvent because no remaining room in event queue. This likely means one of the SparkListeners is too slow and cannot keep up with the rate at which tasks are being started by the scheduler.
Exception in thread "main" org.apache.spark.SparkException: Job 33 cancelled because Stage 142 was cancelled
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435)
	at org.apache.spark.scheduler.DAGScheduler.handleJobCancellation(DAGScheduler.scala:1375)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleStageCancellation$1.apply$mcVI$sp(DAGScheduler.scala:1364)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleStageCancellation$1.apply(DAGScheduler.scala:1363)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleStageCancellation$1.apply(DAGScheduler.scala:1363)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofInt.foreach(ArrayOps.scala:234)
	at org.apache.spark.scheduler.DAGScheduler.handleStageCancellation(DAGScheduler.scala:1363)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1619)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1605)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1594)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:628)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1918)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1931)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1944)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1958)
	at org.apache.spark.rdd.RDD.count(RDD.scala:1157)
	at PFlock$$anonfun$main$1$$anonfun$apply$mcVI$sp$1.apply$mcVD$sp(PFlock.scala:117)
	at PFlock$$anonfun$main$1$$anonfun$apply$mcVI$sp$1.apply(PFlock.scala:57)
	at PFlock$$anonfun$main$1$$anonfun$apply$mcVI$sp$1.apply(PFlock.scala:57)
	at scala.collection.immutable.NumericRange.foreach(NumericRange.scala:73)
	at PFlock$$anonfun$main$1.apply$mcVI$sp(PFlock.scala:57)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at PFlock$.main(PFlock.scala:56)
	at PFlock.main(PFlock.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:738)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:187)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:212)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:126)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
Done!!!
Running in 18 cores and 1750 partitions...
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
17/09/12 17:05:34 INFO SparkContext: Running Spark version 2.1.0
17/09/12 17:05:35 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/09/12 17:05:35 INFO SecurityManager: Changing view acls to: acald013
17/09/12 17:05:35 INFO SecurityManager: Changing modify acls to: acald013
17/09/12 17:05:35 INFO SecurityManager: Changing view acls groups to: 
17/09/12 17:05:35 INFO SecurityManager: Changing modify acls groups to: 
17/09/12 17:05:35 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(acald013); groups with view permissions: Set(); users  with modify permissions: Set(acald013); groups with modify permissions: Set()
17/09/12 17:05:35 INFO Utils: Successfully started service 'sparkDriver' on port 36492.
17/09/12 17:05:35 INFO SparkEnv: Registering MapOutputTracker
17/09/12 17:05:35 INFO SparkEnv: Registering BlockManagerMaster
17/09/12 17:05:35 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/09/12 17:05:35 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/09/12 17:05:35 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-6b2ffd5c-317f-478b-aaab-a8f33be5a20a
17/09/12 17:05:35 INFO MemoryStore: MemoryStore started with capacity 6.2 GB
17/09/12 17:05:35 INFO SparkEnv: Registering OutputCommitCoordinator
17/09/12 17:05:35 INFO Utils: Successfully started service 'SparkUI' on port 4040.
17/09/12 17:05:35 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://169.235.27.134:4040
17/09/12 17:05:35 INFO SparkContext: Added JAR file:/home/acald013/PhD/Y2Q4/PFlock/target/scala-2.11/pflock_2.11-1.0.jar at spark://169.235.27.134:36492/jars/pflock_2.11-1.0.jar with timestamp 1505261135933
17/09/12 17:05:36 INFO SparkContext: Added file file:/home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/conf/metrics.properties at spark://169.235.27.134:36492/files/metrics.properties with timestamp 1505261136097
17/09/12 17:05:36 INFO Utils: Copying /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/conf/metrics.properties to /tmp/spark-0f6055ef-5572-4052-9fb6-c18632349b5d/userFiles-2bb137ef-9e46-44f7-bbfb-5e0cee0fc378/metrics.properties
17/09/12 17:05:36 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://169.235.27.134:7077...
17/09/12 17:05:36 INFO TransportClientFactory: Successfully created connection to /169.235.27.134:7077 after 29 ms (0 ms spent in bootstraps)
17/09/12 17:05:36 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20170912170536-0003
17/09/12 17:05:36 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20170912170536-0003/0 on worker-20170912163633-169.235.27.135-37998 (169.235.27.135:37998) with 6 cores
17/09/12 17:05:36 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39369.
17/09/12 17:05:36 INFO StandaloneSchedulerBackend: Granted executor ID app-20170912170536-0003/0 on hostPort 169.235.27.135:37998 with 6 cores, 12.0 GB RAM
17/09/12 17:05:36 INFO NettyBlockTransferService: Server created on 169.235.27.134:39369
17/09/12 17:05:36 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20170912170536-0003/1 on worker-20170912163632-169.235.27.137-34076 (169.235.27.137:34076) with 6 cores
17/09/12 17:05:36 INFO StandaloneSchedulerBackend: Granted executor ID app-20170912170536-0003/1 on hostPort 169.235.27.137:34076 with 6 cores, 12.0 GB RAM
17/09/12 17:05:36 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/09/12 17:05:36 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20170912170536-0003/2 on worker-20170912163632-169.235.27.134-38244 (169.235.27.134:38244) with 6 cores
17/09/12 17:05:36 INFO StandaloneSchedulerBackend: Granted executor ID app-20170912170536-0003/2 on hostPort 169.235.27.134:38244 with 6 cores, 12.0 GB RAM
17/09/12 17:05:36 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 169.235.27.134, 39369, None)
17/09/12 17:05:36 INFO BlockManagerMasterEndpoint: Registering block manager 169.235.27.134:39369 with 6.2 GB RAM, BlockManagerId(driver, 169.235.27.134, 39369, None)
17/09/12 17:05:36 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 169.235.27.134, 39369, None)
17/09/12 17:05:36 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 169.235.27.134, 39369, None)
17/09/12 17:05:36 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20170912170536-0003/2 is now RUNNING
17/09/12 17:05:36 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20170912170536-0003/0 is now RUNNING
17/09/12 17:05:36 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20170912170536-0003/1 is now RUNNING
17/09/12 17:05:36 INFO EventLoggingListener: Logging events to file:///home/acald013/Spark/Logs/app-20170912170536-0003
17/09/12 17:05:36 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
17/09/12 17:05:36 INFO SharedState: Warehouse path is 'file:/home/acald013/PhD/Y2Q4/spark-warehouse/'.
Running app-20170912170536-0003 on 18 cores and 1750 partitions...
       Tag    Epsilon    Dataset      TimeD      TimeM  TotalTime NCandidate   NMaximal      Cores Partitions       Timestamp
17/09/12 17:06:02 ERROR LiveListenerBus: Dropping SparkListenerEvent because no remaining room in event queue. This likely means one of the SparkListeners is too slow and cannot keep up with the rate at which tasks are being started by the scheduler.
Exception in thread "main" org.apache.spark.SparkException: Job 33 cancelled because Stage 142 was cancelled
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435)
	at org.apache.spark.scheduler.DAGScheduler.handleJobCancellation(DAGScheduler.scala:1375)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleStageCancellation$1.apply$mcVI$sp(DAGScheduler.scala:1364)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleStageCancellation$1.apply(DAGScheduler.scala:1363)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleStageCancellation$1.apply(DAGScheduler.scala:1363)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofInt.foreach(ArrayOps.scala:234)
	at org.apache.spark.scheduler.DAGScheduler.handleStageCancellation(DAGScheduler.scala:1363)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1619)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1605)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1594)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:628)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1918)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1931)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1944)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1958)
	at org.apache.spark.rdd.RDD.count(RDD.scala:1157)
	at PFlock$$anonfun$main$1$$anonfun$apply$mcVI$sp$1.apply$mcVD$sp(PFlock.scala:117)
	at PFlock$$anonfun$main$1$$anonfun$apply$mcVI$sp$1.apply(PFlock.scala:57)
	at PFlock$$anonfun$main$1$$anonfun$apply$mcVI$sp$1.apply(PFlock.scala:57)
	at scala.collection.immutable.NumericRange.foreach(NumericRange.scala:73)
	at PFlock$$anonfun$main$1.apply$mcVI$sp(PFlock.scala:57)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at PFlock$.main(PFlock.scala:56)
	at PFlock.main(PFlock.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:738)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:187)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:212)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:126)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
Done!!!
Running in 18 cores and 1500 partitions...
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
17/09/12 17:11:09 INFO SparkContext: Running Spark version 2.1.0
17/09/12 17:11:09 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/09/12 17:11:09 INFO SecurityManager: Changing view acls to: acald013
17/09/12 17:11:09 INFO SecurityManager: Changing modify acls to: acald013
17/09/12 17:11:09 INFO SecurityManager: Changing view acls groups to: 
17/09/12 17:11:09 INFO SecurityManager: Changing modify acls groups to: 
17/09/12 17:11:09 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(acald013); groups with view permissions: Set(); users  with modify permissions: Set(acald013); groups with modify permissions: Set()
17/09/12 17:11:09 INFO Utils: Successfully started service 'sparkDriver' on port 34050.
17/09/12 17:11:09 INFO SparkEnv: Registering MapOutputTracker
17/09/12 17:11:09 INFO SparkEnv: Registering BlockManagerMaster
17/09/12 17:11:09 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/09/12 17:11:09 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/09/12 17:11:09 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-b6807421-0677-441f-939e-968e657ff48b
17/09/12 17:11:09 INFO MemoryStore: MemoryStore started with capacity 6.2 GB
17/09/12 17:11:09 INFO SparkEnv: Registering OutputCommitCoordinator
17/09/12 17:11:10 INFO Utils: Successfully started service 'SparkUI' on port 4040.
17/09/12 17:11:10 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://169.235.27.134:4040
17/09/12 17:11:10 INFO SparkContext: Added JAR file:/home/acald013/PhD/Y2Q4/PFlock/target/scala-2.11/pflock_2.11-1.0.jar at spark://169.235.27.134:34050/jars/pflock_2.11-1.0.jar with timestamp 1505261470104
17/09/12 17:11:10 INFO SparkContext: Added file file:/home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/conf/metrics.properties at spark://169.235.27.134:34050/files/metrics.properties with timestamp 1505261470250
17/09/12 17:11:10 INFO Utils: Copying /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/conf/metrics.properties to /tmp/spark-2456f56e-9d71-4931-8e6a-55f76de57d9f/userFiles-5b5d8916-2028-486b-9220-0e89cdf2affa/metrics.properties
17/09/12 17:11:10 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://169.235.27.134:7077...
17/09/12 17:11:10 INFO TransportClientFactory: Successfully created connection to /169.235.27.134:7077 after 26 ms (0 ms spent in bootstraps)
17/09/12 17:11:10 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20170912171110-0004
17/09/12 17:11:10 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20170912171110-0004/0 on worker-20170912163633-169.235.27.135-37998 (169.235.27.135:37998) with 6 cores
17/09/12 17:11:10 INFO StandaloneSchedulerBackend: Granted executor ID app-20170912171110-0004/0 on hostPort 169.235.27.135:37998 with 6 cores, 12.0 GB RAM
17/09/12 17:11:10 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20170912171110-0004/1 on worker-20170912163632-169.235.27.137-34076 (169.235.27.137:34076) with 6 cores
17/09/12 17:11:10 INFO StandaloneSchedulerBackend: Granted executor ID app-20170912171110-0004/1 on hostPort 169.235.27.137:34076 with 6 cores, 12.0 GB RAM
17/09/12 17:11:10 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39579.
17/09/12 17:11:10 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20170912171110-0004/2 on worker-20170912163632-169.235.27.134-38244 (169.235.27.134:38244) with 6 cores
17/09/12 17:11:10 INFO StandaloneSchedulerBackend: Granted executor ID app-20170912171110-0004/2 on hostPort 169.235.27.134:38244 with 6 cores, 12.0 GB RAM
17/09/12 17:11:10 INFO NettyBlockTransferService: Server created on 169.235.27.134:39579
17/09/12 17:11:10 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/09/12 17:11:10 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 169.235.27.134, 39579, None)
17/09/12 17:11:10 INFO BlockManagerMasterEndpoint: Registering block manager 169.235.27.134:39579 with 6.2 GB RAM, BlockManagerId(driver, 169.235.27.134, 39579, None)
17/09/12 17:11:10 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20170912171110-0004/0 is now RUNNING
17/09/12 17:11:10 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 169.235.27.134, 39579, None)
17/09/12 17:11:10 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 169.235.27.134, 39579, None)
17/09/12 17:11:10 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20170912171110-0004/2 is now RUNNING
17/09/12 17:11:10 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20170912171110-0004/1 is now RUNNING
17/09/12 17:11:10 INFO EventLoggingListener: Logging events to file:///home/acald013/Spark/Logs/app-20170912171110-0004
17/09/12 17:11:10 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
17/09/12 17:11:10 INFO SharedState: Warehouse path is 'file:/home/acald013/PhD/Y2Q4/spark-warehouse/'.
Running app-20170912171110-0004 on 18 cores and 1500 partitions...
       Tag    Epsilon    Dataset      TimeD      TimeM  TotalTime NCandidate   NMaximal      Cores Partitions       Timestamp
17/09/12 17:11:39 ERROR LiveListenerBus: Dropping SparkListenerEvent because no remaining room in event queue. This likely means one of the SparkListeners is too slow and cannot keep up with the rate at which tasks are being started by the scheduler.
Exception in thread "main" org.apache.spark.SparkException: Job 33 cancelled 
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435)
	at org.apache.spark.scheduler.DAGScheduler.handleJobCancellation(DAGScheduler.scala:1375)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1622)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1605)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1594)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:628)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1918)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1931)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1944)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1958)
	at org.apache.spark.rdd.RDD.count(RDD.scala:1157)
	at PFlock$$anonfun$main$1$$anonfun$apply$mcVI$sp$1.apply$mcVD$sp(PFlock.scala:117)
	at PFlock$$anonfun$main$1$$anonfun$apply$mcVI$sp$1.apply(PFlock.scala:57)
	at PFlock$$anonfun$main$1$$anonfun$apply$mcVI$sp$1.apply(PFlock.scala:57)
	at scala.collection.immutable.NumericRange.foreach(NumericRange.scala:73)
	at PFlock$$anonfun$main$1.apply$mcVI$sp(PFlock.scala:57)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at PFlock$.main(PFlock.scala:56)
	at PFlock.main(PFlock.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:738)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:187)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:212)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:126)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
Done!!!
Running in 18 cores and 1250 partitions...
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
17/09/12 17:16:59 INFO SparkContext: Running Spark version 2.1.0
17/09/12 17:16:59 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/09/12 17:16:59 INFO SecurityManager: Changing view acls to: acald013
17/09/12 17:16:59 INFO SecurityManager: Changing modify acls to: acald013
17/09/12 17:16:59 INFO SecurityManager: Changing view acls groups to: 
17/09/12 17:16:59 INFO SecurityManager: Changing modify acls groups to: 
17/09/12 17:16:59 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(acald013); groups with view permissions: Set(); users  with modify permissions: Set(acald013); groups with modify permissions: Set()
17/09/12 17:16:59 INFO Utils: Successfully started service 'sparkDriver' on port 43831.
17/09/12 17:16:59 INFO SparkEnv: Registering MapOutputTracker
17/09/12 17:16:59 INFO SparkEnv: Registering BlockManagerMaster
17/09/12 17:16:59 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/09/12 17:16:59 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/09/12 17:16:59 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-d385f016-2bd1-4f26-beac-ff0ff283f596
17/09/12 17:16:59 INFO MemoryStore: MemoryStore started with capacity 6.2 GB
17/09/12 17:16:59 INFO SparkEnv: Registering OutputCommitCoordinator
17/09/12 17:16:59 INFO Utils: Successfully started service 'SparkUI' on port 4040.
17/09/12 17:16:59 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://169.235.27.134:4040
17/09/12 17:16:59 INFO SparkContext: Added JAR file:/home/acald013/PhD/Y2Q4/PFlock/target/scala-2.11/pflock_2.11-1.0.jar at spark://169.235.27.134:43831/jars/pflock_2.11-1.0.jar with timestamp 1505261819887
17/09/12 17:17:00 INFO SparkContext: Added file file:/home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/conf/metrics.properties at spark://169.235.27.134:43831/files/metrics.properties with timestamp 1505261820027
17/09/12 17:17:00 INFO Utils: Copying /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/conf/metrics.properties to /tmp/spark-9dfb5970-8a37-46e6-9d72-34394a283cce/userFiles-34c5f365-8f69-451d-a0c3-c04ad4931124/metrics.properties
17/09/12 17:17:00 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://169.235.27.134:7077...
17/09/12 17:17:00 INFO TransportClientFactory: Successfully created connection to /169.235.27.134:7077 after 29 ms (0 ms spent in bootstraps)
17/09/12 17:17:00 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20170912171700-0005
17/09/12 17:17:00 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20170912171700-0005/0 on worker-20170912163633-169.235.27.135-37998 (169.235.27.135:37998) with 6 cores
17/09/12 17:17:00 INFO StandaloneSchedulerBackend: Granted executor ID app-20170912171700-0005/0 on hostPort 169.235.27.135:37998 with 6 cores, 12.0 GB RAM
17/09/12 17:17:00 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20170912171700-0005/1 on worker-20170912163632-169.235.27.137-34076 (169.235.27.137:34076) with 6 cores
17/09/12 17:17:00 INFO StandaloneSchedulerBackend: Granted executor ID app-20170912171700-0005/1 on hostPort 169.235.27.137:34076 with 6 cores, 12.0 GB RAM
17/09/12 17:17:00 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20170912171700-0005/2 on worker-20170912163632-169.235.27.134-38244 (169.235.27.134:38244) with 6 cores
17/09/12 17:17:00 INFO StandaloneSchedulerBackend: Granted executor ID app-20170912171700-0005/2 on hostPort 169.235.27.134:38244 with 6 cores, 12.0 GB RAM
17/09/12 17:17:00 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43579.
17/09/12 17:17:00 INFO NettyBlockTransferService: Server created on 169.235.27.134:43579
17/09/12 17:17:00 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/09/12 17:17:00 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 169.235.27.134, 43579, None)
17/09/12 17:17:00 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20170912171700-0005/2 is now RUNNING
17/09/12 17:17:00 INFO BlockManagerMasterEndpoint: Registering block manager 169.235.27.134:43579 with 6.2 GB RAM, BlockManagerId(driver, 169.235.27.134, 43579, None)
17/09/12 17:17:00 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20170912171700-0005/1 is now RUNNING
17/09/12 17:17:00 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 169.235.27.134, 43579, None)
17/09/12 17:17:00 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 169.235.27.134, 43579, None)
17/09/12 17:17:00 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20170912171700-0005/0 is now RUNNING
17/09/12 17:17:00 INFO EventLoggingListener: Logging events to file:///home/acald013/Spark/Logs/app-20170912171700-0005
17/09/12 17:17:00 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
17/09/12 17:17:00 INFO SharedState: Warehouse path is 'file:/home/acald013/PhD/Y2Q4/spark-warehouse/'.
Running app-20170912171700-0005 on 18 cores and 1250 partitions...
       Tag    Epsilon    Dataset      TimeD      TimeM  TotalTime NCandidate   NMaximal      Cores Partitions       Timestamp
Exception in thread "main" org.apache.spark.SparkException: Job 33 cancelled 
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435)
	at org.apache.spark.scheduler.DAGScheduler.handleJobCancellation(DAGScheduler.scala:1375)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1622)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1605)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1594)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:628)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1918)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1931)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1944)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1958)
	at org.apache.spark.rdd.RDD.count(RDD.scala:1157)
	at PFlock$$anonfun$main$1$$anonfun$apply$mcVI$sp$1.apply$mcVD$sp(PFlock.scala:117)
	at PFlock$$anonfun$main$1$$anonfun$apply$mcVI$sp$1.apply(PFlock.scala:57)
	at PFlock$$anonfun$main$1$$anonfun$apply$mcVI$sp$1.apply(PFlock.scala:57)
	at scala.collection.immutable.NumericRange.foreach(NumericRange.scala:73)
	at PFlock$$anonfun$main$1.apply$mcVI$sp(PFlock.scala:57)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at PFlock$.main(PFlock.scala:56)
	at PFlock.main(PFlock.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:738)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:187)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:212)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:126)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
Done!!!
Running in 18 cores and 1000 partitions...
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
17/09/12 17:25:31 INFO SparkContext: Running Spark version 2.1.0
17/09/12 17:25:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/09/12 17:25:31 INFO SecurityManager: Changing view acls to: acald013
17/09/12 17:25:31 INFO SecurityManager: Changing modify acls to: acald013
17/09/12 17:25:31 INFO SecurityManager: Changing view acls groups to: 
17/09/12 17:25:31 INFO SecurityManager: Changing modify acls groups to: 
17/09/12 17:25:31 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(acald013); groups with view permissions: Set(); users  with modify permissions: Set(acald013); groups with modify permissions: Set()
17/09/12 17:25:31 INFO Utils: Successfully started service 'sparkDriver' on port 37021.
17/09/12 17:25:31 INFO SparkEnv: Registering MapOutputTracker
17/09/12 17:25:31 INFO SparkEnv: Registering BlockManagerMaster
17/09/12 17:25:31 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/09/12 17:25:31 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/09/12 17:25:31 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-0eed3dae-c52c-4a73-8a89-4c0edfb431a3
17/09/12 17:25:31 INFO MemoryStore: MemoryStore started with capacity 6.2 GB
17/09/12 17:25:31 INFO SparkEnv: Registering OutputCommitCoordinator
17/09/12 17:25:32 INFO Utils: Successfully started service 'SparkUI' on port 4040.
17/09/12 17:25:32 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://169.235.27.134:4040
17/09/12 17:25:32 INFO SparkContext: Added JAR file:/home/acald013/PhD/Y2Q4/PFlock/target/scala-2.11/pflock_2.11-1.0.jar at spark://169.235.27.134:37021/jars/pflock_2.11-1.0.jar with timestamp 1505262332061
17/09/12 17:25:32 INFO SparkContext: Added file file:/home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/conf/metrics.properties at spark://169.235.27.134:37021/files/metrics.properties with timestamp 1505262332211
17/09/12 17:25:32 INFO Utils: Copying /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/conf/metrics.properties to /tmp/spark-18a2a25b-5cab-4dc6-983d-a6c8f807d92a/userFiles-d86be099-7e4b-4bd8-86f2-106d9ec0f756/metrics.properties
17/09/12 17:25:32 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://169.235.27.134:7077...
17/09/12 17:25:32 INFO TransportClientFactory: Successfully created connection to /169.235.27.134:7077 after 21 ms (0 ms spent in bootstraps)
17/09/12 17:25:32 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20170912172532-0006
17/09/12 17:25:32 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20170912172532-0006/0 on worker-20170912163633-169.235.27.135-37998 (169.235.27.135:37998) with 6 cores
17/09/12 17:25:32 INFO StandaloneSchedulerBackend: Granted executor ID app-20170912172532-0006/0 on hostPort 169.235.27.135:37998 with 6 cores, 12.0 GB RAM
17/09/12 17:25:32 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20170912172532-0006/1 on worker-20170912163632-169.235.27.137-34076 (169.235.27.137:34076) with 6 cores
17/09/12 17:25:32 INFO StandaloneSchedulerBackend: Granted executor ID app-20170912172532-0006/1 on hostPort 169.235.27.137:34076 with 6 cores, 12.0 GB RAM
17/09/12 17:25:32 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20170912172532-0006/2 on worker-20170912163632-169.235.27.134-38244 (169.235.27.134:38244) with 6 cores
17/09/12 17:25:32 INFO StandaloneSchedulerBackend: Granted executor ID app-20170912172532-0006/2 on hostPort 169.235.27.134:38244 with 6 cores, 12.0 GB RAM
17/09/12 17:25:32 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39011.
17/09/12 17:25:32 INFO NettyBlockTransferService: Server created on 169.235.27.134:39011
17/09/12 17:25:32 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/09/12 17:25:32 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 169.235.27.134, 39011, None)
17/09/12 17:25:32 INFO BlockManagerMasterEndpoint: Registering block manager 169.235.27.134:39011 with 6.2 GB RAM, BlockManagerId(driver, 169.235.27.134, 39011, None)
17/09/12 17:25:32 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 169.235.27.134, 39011, None)
17/09/12 17:25:32 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 169.235.27.134, 39011, None)
17/09/12 17:25:32 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20170912172532-0006/2 is now RUNNING
17/09/12 17:25:32 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20170912172532-0006/1 is now RUNNING
17/09/12 17:25:32 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20170912172532-0006/0 is now RUNNING
17/09/12 17:25:32 INFO EventLoggingListener: Logging events to file:///home/acald013/Spark/Logs/app-20170912172532-0006
17/09/12 17:25:32 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
17/09/12 17:25:32 INFO SharedState: Warehouse path is 'file:/home/acald013/PhD/Y2Q4/spark-warehouse/'.
Running app-20170912172532-0006 on 18 cores and 1000 partitions...
       Tag    Epsilon    Dataset      TimeD      TimeM  TotalTime NCandidate   NMaximal      Cores Partitions       Timestamp
Exception in thread "main" org.apache.spark.SparkException: Job 33 cancelled because Stage 142 was cancelled
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435)
	at org.apache.spark.scheduler.DAGScheduler.handleJobCancellation(DAGScheduler.scala:1375)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleStageCancellation$1.apply$mcVI$sp(DAGScheduler.scala:1364)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleStageCancellation$1.apply(DAGScheduler.scala:1363)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleStageCancellation$1.apply(DAGScheduler.scala:1363)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofInt.foreach(ArrayOps.scala:234)
	at org.apache.spark.scheduler.DAGScheduler.handleStageCancellation(DAGScheduler.scala:1363)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1619)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1605)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1594)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:628)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1918)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1931)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1944)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1958)
	at org.apache.spark.rdd.RDD.count(RDD.scala:1157)
	at PFlock$$anonfun$main$1$$anonfun$apply$mcVI$sp$1.apply$mcVD$sp(PFlock.scala:117)
	at PFlock$$anonfun$main$1$$anonfun$apply$mcVI$sp$1.apply(PFlock.scala:57)
	at PFlock$$anonfun$main$1$$anonfun$apply$mcVI$sp$1.apply(PFlock.scala:57)
	at scala.collection.immutable.NumericRange.foreach(NumericRange.scala:73)
	at PFlock$$anonfun$main$1.apply$mcVI$sp(PFlock.scala:57)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at PFlock$.main(PFlock.scala:56)
	at PFlock.main(PFlock.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:738)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:187)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:212)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:126)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
Done!!!
Running in 18 cores and 750 partitions...
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
17/09/12 17:30:44 INFO SparkContext: Running Spark version 2.1.0
17/09/12 17:30:44 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/09/12 17:30:44 INFO SecurityManager: Changing view acls to: acald013
17/09/12 17:30:44 INFO SecurityManager: Changing modify acls to: acald013
17/09/12 17:30:44 INFO SecurityManager: Changing view acls groups to: 
17/09/12 17:30:44 INFO SecurityManager: Changing modify acls groups to: 
17/09/12 17:30:44 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(acald013); groups with view permissions: Set(); users  with modify permissions: Set(acald013); groups with modify permissions: Set()
17/09/12 17:30:44 INFO Utils: Successfully started service 'sparkDriver' on port 37778.
17/09/12 17:30:44 INFO SparkEnv: Registering MapOutputTracker
17/09/12 17:30:44 INFO SparkEnv: Registering BlockManagerMaster
17/09/12 17:30:44 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/09/12 17:30:44 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/09/12 17:30:44 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-315feefa-2ee4-4443-a9dd-6ffc669f622f
17/09/12 17:30:44 INFO MemoryStore: MemoryStore started with capacity 6.2 GB
17/09/12 17:30:44 INFO SparkEnv: Registering OutputCommitCoordinator
17/09/12 17:30:45 INFO Utils: Successfully started service 'SparkUI' on port 4040.
17/09/12 17:30:45 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://169.235.27.134:4040
17/09/12 17:30:45 INFO SparkContext: Added JAR file:/home/acald013/PhD/Y2Q4/PFlock/target/scala-2.11/pflock_2.11-1.0.jar at spark://169.235.27.134:37778/jars/pflock_2.11-1.0.jar with timestamp 1505262645152
17/09/12 17:30:45 INFO SparkContext: Added file file:/home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/conf/metrics.properties at spark://169.235.27.134:37778/files/metrics.properties with timestamp 1505262645308
17/09/12 17:30:45 INFO Utils: Copying /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/conf/metrics.properties to /tmp/spark-d17632c3-cd3b-4332-af16-1490a4c29fa8/userFiles-797d4d3f-7f40-4cca-966b-acf540bd0e2a/metrics.properties
17/09/12 17:30:45 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://169.235.27.134:7077...
17/09/12 17:30:45 INFO TransportClientFactory: Successfully created connection to /169.235.27.134:7077 after 26 ms (0 ms spent in bootstraps)
17/09/12 17:30:45 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20170912173045-0007
17/09/12 17:30:45 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20170912173045-0007/0 on worker-20170912163633-169.235.27.135-37998 (169.235.27.135:37998) with 6 cores
17/09/12 17:30:45 INFO StandaloneSchedulerBackend: Granted executor ID app-20170912173045-0007/0 on hostPort 169.235.27.135:37998 with 6 cores, 12.0 GB RAM
17/09/12 17:30:45 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20170912173045-0007/1 on worker-20170912163632-169.235.27.137-34076 (169.235.27.137:34076) with 6 cores
17/09/12 17:30:45 INFO StandaloneSchedulerBackend: Granted executor ID app-20170912173045-0007/1 on hostPort 169.235.27.137:34076 with 6 cores, 12.0 GB RAM
17/09/12 17:30:45 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33078.
17/09/12 17:30:45 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20170912173045-0007/2 on worker-20170912163632-169.235.27.134-38244 (169.235.27.134:38244) with 6 cores
17/09/12 17:30:45 INFO NettyBlockTransferService: Server created on 169.235.27.134:33078
17/09/12 17:30:45 INFO StandaloneSchedulerBackend: Granted executor ID app-20170912173045-0007/2 on hostPort 169.235.27.134:38244 with 6 cores, 12.0 GB RAM
17/09/12 17:30:45 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/09/12 17:30:45 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 169.235.27.134, 33078, None)
17/09/12 17:30:45 INFO BlockManagerMasterEndpoint: Registering block manager 169.235.27.134:33078 with 6.2 GB RAM, BlockManagerId(driver, 169.235.27.134, 33078, None)
17/09/12 17:30:45 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 169.235.27.134, 33078, None)
17/09/12 17:30:45 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 169.235.27.134, 33078, None)
17/09/12 17:30:45 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20170912173045-0007/2 is now RUNNING
17/09/12 17:30:45 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20170912173045-0007/0 is now RUNNING
17/09/12 17:30:45 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20170912173045-0007/1 is now RUNNING
17/09/12 17:30:45 INFO EventLoggingListener: Logging events to file:///home/acald013/Spark/Logs/app-20170912173045-0007
17/09/12 17:30:45 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
17/09/12 17:30:45 INFO SharedState: Warehouse path is 'file:/home/acald013/PhD/Y2Q4/spark-warehouse/'.
Running app-20170912173045-0007 on 18 cores and 750 partitions...
       Tag    Epsilon    Dataset      TimeD      TimeM  TotalTime NCandidate   NMaximal      Cores Partitions       Timestamp
Exception in thread "main" org.apache.spark.SparkException: Job 33 cancelled because Stage 142 was cancelled
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435)
	at org.apache.spark.scheduler.DAGScheduler.handleJobCancellation(DAGScheduler.scala:1375)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleStageCancellation$1.apply$mcVI$sp(DAGScheduler.scala:1364)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleStageCancellation$1.apply(DAGScheduler.scala:1363)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleStageCancellation$1.apply(DAGScheduler.scala:1363)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofInt.foreach(ArrayOps.scala:234)
	at org.apache.spark.scheduler.DAGScheduler.handleStageCancellation(DAGScheduler.scala:1363)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1619)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1605)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1594)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:628)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1918)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1931)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1944)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1958)
	at org.apache.spark.rdd.RDD.count(RDD.scala:1157)
	at PFlock$$anonfun$main$1$$anonfun$apply$mcVI$sp$1.apply$mcVD$sp(PFlock.scala:117)
	at PFlock$$anonfun$main$1$$anonfun$apply$mcVI$sp$1.apply(PFlock.scala:57)
	at PFlock$$anonfun$main$1$$anonfun$apply$mcVI$sp$1.apply(PFlock.scala:57)
	at scala.collection.immutable.NumericRange.foreach(NumericRange.scala:73)
	at PFlock$$anonfun$main$1.apply$mcVI$sp(PFlock.scala:57)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at PFlock$.main(PFlock.scala:56)
	at PFlock.main(PFlock.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:738)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:187)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:212)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:126)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
Done!!!
Running in 18 cores and 500 partitions...
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
17/09/12 17:35:41 INFO SparkContext: Running Spark version 2.1.0
17/09/12 17:35:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/09/12 17:35:41 INFO SecurityManager: Changing view acls to: acald013
17/09/12 17:35:41 INFO SecurityManager: Changing modify acls to: acald013
17/09/12 17:35:41 INFO SecurityManager: Changing view acls groups to: 
17/09/12 17:35:41 INFO SecurityManager: Changing modify acls groups to: 
17/09/12 17:35:41 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(acald013); groups with view permissions: Set(); users  with modify permissions: Set(acald013); groups with modify permissions: Set()
17/09/12 17:35:41 INFO Utils: Successfully started service 'sparkDriver' on port 37279.
17/09/12 17:35:42 INFO SparkEnv: Registering MapOutputTracker
17/09/12 17:35:42 INFO SparkEnv: Registering BlockManagerMaster
17/09/12 17:35:42 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/09/12 17:35:42 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/09/12 17:35:42 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-3eadab60-eecc-49aa-bcd7-8d220f82c08a
17/09/12 17:35:42 INFO MemoryStore: MemoryStore started with capacity 6.2 GB
17/09/12 17:35:42 INFO SparkEnv: Registering OutputCommitCoordinator
17/09/12 17:35:42 INFO Utils: Successfully started service 'SparkUI' on port 4040.
17/09/12 17:35:42 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://169.235.27.134:4040
17/09/12 17:35:42 INFO SparkContext: Added JAR file:/home/acald013/PhD/Y2Q4/PFlock/target/scala-2.11/pflock_2.11-1.0.jar at spark://169.235.27.134:37279/jars/pflock_2.11-1.0.jar with timestamp 1505262942290
17/09/12 17:35:42 INFO SparkContext: Added file file:/home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/conf/metrics.properties at spark://169.235.27.134:37279/files/metrics.properties with timestamp 1505262942440
17/09/12 17:35:42 INFO Utils: Copying /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/conf/metrics.properties to /tmp/spark-90c5a5b1-c3e7-4c1c-a666-c3d2f8703d74/userFiles-6563b865-5f26-4084-820c-74c034593e50/metrics.properties
17/09/12 17:35:42 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://169.235.27.134:7077...
17/09/12 17:35:42 INFO TransportClientFactory: Successfully created connection to /169.235.27.134:7077 after 26 ms (0 ms spent in bootstraps)
17/09/12 17:35:42 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20170912173542-0008
17/09/12 17:35:42 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20170912173542-0008/0 on worker-20170912163633-169.235.27.135-37998 (169.235.27.135:37998) with 6 cores
17/09/12 17:35:42 INFO StandaloneSchedulerBackend: Granted executor ID app-20170912173542-0008/0 on hostPort 169.235.27.135:37998 with 6 cores, 12.0 GB RAM
17/09/12 17:35:42 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38198.
17/09/12 17:35:42 INFO NettyBlockTransferService: Server created on 169.235.27.134:38198
17/09/12 17:35:42 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20170912173542-0008/1 on worker-20170912163632-169.235.27.137-34076 (169.235.27.137:34076) with 6 cores
17/09/12 17:35:42 INFO StandaloneSchedulerBackend: Granted executor ID app-20170912173542-0008/1 on hostPort 169.235.27.137:34076 with 6 cores, 12.0 GB RAM
17/09/12 17:35:42 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/09/12 17:35:42 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20170912173542-0008/2 on worker-20170912163632-169.235.27.134-38244 (169.235.27.134:38244) with 6 cores
17/09/12 17:35:42 INFO StandaloneSchedulerBackend: Granted executor ID app-20170912173542-0008/2 on hostPort 169.235.27.134:38244 with 6 cores, 12.0 GB RAM
17/09/12 17:35:42 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 169.235.27.134, 38198, None)
17/09/12 17:35:42 INFO BlockManagerMasterEndpoint: Registering block manager 169.235.27.134:38198 with 6.2 GB RAM, BlockManagerId(driver, 169.235.27.134, 38198, None)
17/09/12 17:35:42 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 169.235.27.134, 38198, None)
17/09/12 17:35:42 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 169.235.27.134, 38198, None)
17/09/12 17:35:42 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20170912173542-0008/0 is now RUNNING
17/09/12 17:35:42 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20170912173542-0008/2 is now RUNNING
17/09/12 17:35:42 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20170912173542-0008/1 is now RUNNING
17/09/12 17:35:42 INFO EventLoggingListener: Logging events to file:///home/acald013/Spark/Logs/app-20170912173542-0008
17/09/12 17:35:42 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
17/09/12 17:35:42 INFO SharedState: Warehouse path is 'file:/home/acald013/PhD/Y2Q4/spark-warehouse/'.
Running app-20170912173542-0008 on 18 cores and 500 partitions...
       Tag    Epsilon    Dataset      TimeD      TimeM  TotalTime NCandidate   NMaximal      Cores Partitions       Timestamp
17/09/12 17:36:53 ERROR TaskSchedulerImpl: Lost executor 2 on 169.235.27.134: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/09/12 17:36:54 ERROR TaskSchedulerImpl: Lost executor 1 on 169.235.27.137: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/09/12 17:37:03 ERROR TaskSchedulerImpl: Lost executor 0 on 169.235.27.135: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/09/12 17:37:03 ERROR TransportRequestHandler: Error sending result RpcResponse{requestId=5657401774758103124, body=NioManagedBuffer{buf=java.nio.HeapByteBuffer[pos=0 lim=81 cap=156]}} to /169.235.27.135:55156; closing connection
java.nio.channels.ClosedChannelException
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source)
