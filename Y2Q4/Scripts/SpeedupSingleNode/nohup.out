acald013@dblab-rack11: stopping org.apache.spark.deploy.worker.Worker
no org.apache.spark.deploy.master.Master to stop
starting org.apache.spark.deploy.master.Master, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.master.Master-1-dblab-rack15.out
acald013@dblab-rack15: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack15.out
Running in 7 cores and 1024 partitions.  Setting mu = 50 ...
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
17/09/19 15:41:24 INFO SparkContext: Running Spark version 2.1.0
17/09/19 15:41:24 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/09/19 15:41:25 INFO SecurityManager: Changing view acls to: acald013
17/09/19 15:41:25 INFO SecurityManager: Changing modify acls to: acald013
17/09/19 15:41:25 INFO SecurityManager: Changing view acls groups to: 
17/09/19 15:41:25 INFO SecurityManager: Changing modify acls groups to: 
17/09/19 15:41:25 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(acald013); groups with view permissions: Set(); users  with modify permissions: Set(acald013); groups with modify permissions: Set()
17/09/19 15:41:25 INFO Utils: Successfully started service 'sparkDriver' on port 35591.
17/09/19 15:41:25 INFO SparkEnv: Registering MapOutputTracker
17/09/19 15:41:25 INFO SparkEnv: Registering BlockManagerMaster
17/09/19 15:41:25 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/09/19 15:41:25 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/09/19 15:41:25 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-9cedb4f9-1143-4920-b65d-52b432ba80af
17/09/19 15:41:25 INFO MemoryStore: MemoryStore started with capacity 6.2 GB
17/09/19 15:41:25 INFO SparkEnv: Registering OutputCommitCoordinator
17/09/19 15:41:26 INFO Utils: Successfully started service 'SparkUI' on port 4040.
17/09/19 15:41:26 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://169.235.27.138:4040
17/09/19 15:41:26 INFO SparkContext: Added JAR file:/home/acald013/PhD/Y2Q4/PFlock/target/scala-2.11/pflock_2.11-1.0.jar at spark://169.235.27.138:35591/jars/pflock_2.11-1.0.jar with timestamp 1505860886362
17/09/19 15:41:26 INFO Executor: Starting executor ID driver on host localhost
17/09/19 15:41:26 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40590.
17/09/19 15:41:26 INFO NettyBlockTransferService: Server created on 169.235.27.138:40590
17/09/19 15:41:26 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/09/19 15:41:26 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 169.235.27.138, 40590, None)
17/09/19 15:41:26 INFO BlockManagerMasterEndpoint: Registering block manager 169.235.27.138:40590 with 6.2 GB RAM, BlockManagerId(driver, 169.235.27.138, 40590, None)
17/09/19 15:41:26 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 169.235.27.138, 40590, None)
17/09/19 15:41:26 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 169.235.27.138, 40590, None)
17/09/19 15:41:27 INFO EventLoggingListener: Logging events to file:///home/acald013/Logs/local-1505860886418
17/09/19 15:41:27 INFO SharedState: Warehouse path is 'file:/home/acald013/PhD/Y2Q4/Scripts/SpeedupSingleNode/spark-warehouse/'.
Running local-1505860886418 on 7 cores and 1024 partitions...
       Tag    Epsilon    Dataset      TimeD      TimeM  TotalTime NCandidate   NMaximal      Cores Partitions       Timestamp
    PFlock       50.0        80K    134.210     83.602    217.812     575930        482          7       1024    15:45:06.337
    PFlock       60.0        80K    129.221     93.022    222.243     700950        751          7       1024    15:48:48.744
    PFlock       70.0        80K    138.320    102.212    240.532     833016        904          7       1024    15:52:49.368
    PFlock       80.0        80K    147.507    114.739    262.246     974432       1065          7       1024    15:57:11.701
    PFlock       90.0        80K    154.814    125.529    280.343    1130136       1287          7       1024    16:01:52.136
    PFlock      100.0        80K    164.366    139.859    304.225    1302882       1563          7       1024    16:06:56.451
Done!!!
Running in 7 cores and 1024 partitions.  Setting mu = 50 ...
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
17/09/19 16:07:08 INFO SparkContext: Running Spark version 2.1.0
17/09/19 16:07:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/09/19 16:07:09 INFO SecurityManager: Changing view acls to: acald013
17/09/19 16:07:09 INFO SecurityManager: Changing modify acls to: acald013
17/09/19 16:07:09 INFO SecurityManager: Changing view acls groups to: 
17/09/19 16:07:09 INFO SecurityManager: Changing modify acls groups to: 
17/09/19 16:07:09 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(acald013); groups with view permissions: Set(); users  with modify permissions: Set(acald013); groups with modify permissions: Set()
17/09/19 16:07:09 INFO Utils: Successfully started service 'sparkDriver' on port 39123.
17/09/19 16:07:09 INFO SparkEnv: Registering MapOutputTracker
17/09/19 16:07:09 INFO SparkEnv: Registering BlockManagerMaster
17/09/19 16:07:09 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/09/19 16:07:09 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/09/19 16:07:09 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-d827a741-8a07-48d8-8c3b-dcb206a26909
17/09/19 16:07:09 INFO MemoryStore: MemoryStore started with capacity 6.2 GB
17/09/19 16:07:09 INFO SparkEnv: Registering OutputCommitCoordinator
17/09/19 16:07:10 INFO Utils: Successfully started service 'SparkUI' on port 4040.
17/09/19 16:07:10 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://169.235.27.138:4040
17/09/19 16:07:10 INFO SparkContext: Added JAR file:/home/acald013/PhD/Y2Q4/PFlock/target/scala-2.11/pflock_2.11-1.0.jar at spark://169.235.27.138:39123/jars/pflock_2.11-1.0.jar with timestamp 1505862430200
17/09/19 16:07:10 INFO Executor: Starting executor ID driver on host localhost
17/09/19 16:07:10 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38113.
17/09/19 16:07:10 INFO NettyBlockTransferService: Server created on 169.235.27.138:38113
17/09/19 16:07:10 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/09/19 16:07:10 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 169.235.27.138, 38113, None)
17/09/19 16:07:10 INFO BlockManagerMasterEndpoint: Registering block manager 169.235.27.138:38113 with 6.2 GB RAM, BlockManagerId(driver, 169.235.27.138, 38113, None)
17/09/19 16:07:10 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 169.235.27.138, 38113, None)
17/09/19 16:07:10 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 169.235.27.138, 38113, None)
17/09/19 16:07:11 INFO EventLoggingListener: Logging events to file:///home/acald013/Logs/local-1505862430255
17/09/19 16:07:11 INFO SharedState: Warehouse path is 'file:/home/acald013/PhD/Y2Q4/Scripts/SpeedupSingleNode/spark-warehouse/'.
Running local-1505862430255 on 7 cores and 1024 partitions...
       Tag    Epsilon    Dataset      TimeD      TimeM  TotalTime NCandidate   NMaximal      Cores Partitions       Timestamp
    PFlock       50.0        80K    132.502     81.876    214.378     575930        482          7       1024    16:10:46.828
    PFlock       60.0        80K    127.339     92.366    219.705     700950        751          7       1024    16:14:26.696
    PFlock       70.0        80K    139.876    101.524    241.400     833016        904          7       1024    16:18:28.188
    PFlock       80.0        80K    144.901    112.714    257.615     974432       1065          7       1024    16:22:45.893
    PFlock       90.0        80K    156.666    124.968    281.634    1130136       1287          7       1024    16:27:27.610
    PFlock      100.0        80K    165.339    137.947    303.286    1302882       1563          7       1024    16:32:30.982
Done!!!
Running in 7 cores and 1024 partitions.  Setting mu = 50 ...
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
17/09/19 16:32:42 INFO SparkContext: Running Spark version 2.1.0
17/09/19 16:32:43 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/09/19 16:32:43 INFO SecurityManager: Changing view acls to: acald013
17/09/19 16:32:43 INFO SecurityManager: Changing modify acls to: acald013
17/09/19 16:32:43 INFO SecurityManager: Changing view acls groups to: 
17/09/19 16:32:43 INFO SecurityManager: Changing modify acls groups to: 
17/09/19 16:32:43 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(acald013); groups with view permissions: Set(); users  with modify permissions: Set(acald013); groups with modify permissions: Set()
17/09/19 16:32:43 INFO Utils: Successfully started service 'sparkDriver' on port 44476.
17/09/19 16:32:44 INFO SparkEnv: Registering MapOutputTracker
17/09/19 16:32:44 INFO SparkEnv: Registering BlockManagerMaster
17/09/19 16:32:44 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/09/19 16:32:44 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/09/19 16:32:44 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-469588d4-90f8-40e1-9dc5-19dac6d291b5
17/09/19 16:32:44 INFO MemoryStore: MemoryStore started with capacity 6.2 GB
17/09/19 16:32:44 INFO SparkEnv: Registering OutputCommitCoordinator
17/09/19 16:32:44 INFO Utils: Successfully started service 'SparkUI' on port 4040.
17/09/19 16:32:44 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://169.235.27.138:4040
17/09/19 16:32:44 INFO SparkContext: Added JAR file:/home/acald013/PhD/Y2Q4/PFlock/target/scala-2.11/pflock_2.11-1.0.jar at spark://169.235.27.138:44476/jars/pflock_2.11-1.0.jar with timestamp 1505863964672
17/09/19 16:32:44 INFO Executor: Starting executor ID driver on host localhost
17/09/19 16:32:44 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35775.
17/09/19 16:32:44 INFO NettyBlockTransferService: Server created on 169.235.27.138:35775
17/09/19 16:32:44 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/09/19 16:32:44 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 169.235.27.138, 35775, None)
17/09/19 16:32:44 INFO BlockManagerMasterEndpoint: Registering block manager 169.235.27.138:35775 with 6.2 GB RAM, BlockManagerId(driver, 169.235.27.138, 35775, None)
17/09/19 16:32:44 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 169.235.27.138, 35775, None)
17/09/19 16:32:44 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 169.235.27.138, 35775, None)
17/09/19 16:32:45 INFO EventLoggingListener: Logging events to file:///home/acald013/Logs/local-1505863964727
17/09/19 16:32:45 INFO SharedState: Warehouse path is 'file:/home/acald013/PhD/Y2Q4/Scripts/SpeedupSingleNode/spark-warehouse/'.
Running local-1505863964727 on 7 cores and 1024 partitions...
       Tag    Epsilon    Dataset      TimeD      TimeM  TotalTime NCandidate   NMaximal      Cores Partitions       Timestamp
    PFlock       50.0        80K    130.107     82.361    212.468     575930        482          7       1024    16:36:19.381
    PFlock       60.0        80K    127.579     93.126    220.705     700950        751          7       1024    16:40:00.246
    PFlock       70.0        80K    137.689    102.722    240.411     833016        904          7       1024    16:44:00.750
    PFlock       80.0        80K    145.363    113.168    258.531     974432       1065          7       1024    16:48:19.371
    PFlock       90.0        80K    156.418    124.365    280.783    1130136       1287          7       1024    16:53:00.239
    PFlock      100.0        80K    166.085    138.031    304.116    1302882       1563          7       1024    16:58:04.442
Done!!!
Running in 6 cores and 1024 partitions.  Setting mu = 50 ...
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
17/09/19 16:58:18 INFO SparkContext: Running Spark version 2.1.0
17/09/19 16:58:18 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/09/19 16:58:18 INFO SecurityManager: Changing view acls to: acald013
17/09/19 16:58:18 INFO SecurityManager: Changing modify acls to: acald013
17/09/19 16:58:18 INFO SecurityManager: Changing view acls groups to: 
17/09/19 16:58:18 INFO SecurityManager: Changing modify acls groups to: 
17/09/19 16:58:18 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(acald013); groups with view permissions: Set(); users  with modify permissions: Set(acald013); groups with modify permissions: Set()
17/09/19 16:58:19 INFO Utils: Successfully started service 'sparkDriver' on port 39645.
17/09/19 16:58:19 INFO SparkEnv: Registering MapOutputTracker
17/09/19 16:58:19 INFO SparkEnv: Registering BlockManagerMaster
17/09/19 16:58:19 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/09/19 16:58:19 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/09/19 16:58:19 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-a428beb2-cd94-40d2-8b3e-0a610e488d89
17/09/19 16:58:19 INFO MemoryStore: MemoryStore started with capacity 6.2 GB
17/09/19 16:58:19 INFO SparkEnv: Registering OutputCommitCoordinator
17/09/19 16:58:19 INFO Utils: Successfully started service 'SparkUI' on port 4040.
17/09/19 16:58:19 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://169.235.27.138:4040
17/09/19 16:58:20 INFO SparkContext: Added JAR file:/home/acald013/PhD/Y2Q4/PFlock/target/scala-2.11/pflock_2.11-1.0.jar at spark://169.235.27.138:39645/jars/pflock_2.11-1.0.jar with timestamp 1505865500003
17/09/19 16:58:20 INFO Executor: Starting executor ID driver on host localhost
17/09/19 16:58:20 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37199.
17/09/19 16:58:20 INFO NettyBlockTransferService: Server created on 169.235.27.138:37199
17/09/19 16:58:20 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/09/19 16:58:20 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 169.235.27.138, 37199, None)
17/09/19 16:58:20 INFO BlockManagerMasterEndpoint: Registering block manager 169.235.27.138:37199 with 6.2 GB RAM, BlockManagerId(driver, 169.235.27.138, 37199, None)
17/09/19 16:58:20 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 169.235.27.138, 37199, None)
17/09/19 16:58:20 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 169.235.27.138, 37199, None)
17/09/19 16:58:20 INFO EventLoggingListener: Logging events to file:///home/acald013/Logs/local-1505865500059
17/09/19 16:58:21 INFO SharedState: Warehouse path is 'file:/home/acald013/PhD/Y2Q4/Scripts/SpeedupSingleNode/spark-warehouse/'.
Running local-1505865500059 on 6 cores and 1024 partitions...
       Tag    Epsilon    Dataset      TimeD      TimeM  TotalTime NCandidate   NMaximal      Cores Partitions       Timestamp
    PFlock       50.0        80K    146.538    106.686    253.224     575930        482          6       1024    17:02:35.434
    PFlock       60.0        80K    146.965    122.050    269.015     700950        751          6       1024    17:07:04.610
    PFlock       70.0        80K    155.938    135.863    291.801     833016        904          6       1024    17:11:56.504
    PFlock       80.0        80K    165.071    152.515    317.586     974432       1065          6       1024    17:17:14.180
    PFlock       90.0        80K    177.015    168.799    345.814    1130136       1287          6       1024    17:23:00.082
    PFlock      100.0        80K    188.467    188.745    377.212    1302882       1563          6       1024    17:29:17.377
Done!!!
Running in 6 cores and 1024 partitions.  Setting mu = 50 ...
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
17/09/19 17:29:29 INFO SparkContext: Running Spark version 2.1.0
17/09/19 17:29:30 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/09/19 17:29:30 INFO SecurityManager: Changing view acls to: acald013
17/09/19 17:29:30 INFO SecurityManager: Changing modify acls to: acald013
17/09/19 17:29:30 INFO SecurityManager: Changing view acls groups to: 
17/09/19 17:29:30 INFO SecurityManager: Changing modify acls groups to: 
17/09/19 17:29:30 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(acald013); groups with view permissions: Set(); users  with modify permissions: Set(acald013); groups with modify permissions: Set()
17/09/19 17:29:31 INFO Utils: Successfully started service 'sparkDriver' on port 45405.
17/09/19 17:29:31 INFO SparkEnv: Registering MapOutputTracker
17/09/19 17:29:31 INFO SparkEnv: Registering BlockManagerMaster
17/09/19 17:29:31 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/09/19 17:29:31 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/09/19 17:29:31 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-5b4bd09c-4171-44de-9887-e9b21e5c0f2e
17/09/19 17:29:31 INFO MemoryStore: MemoryStore started with capacity 6.2 GB
17/09/19 17:29:31 INFO SparkEnv: Registering OutputCommitCoordinator
17/09/19 17:29:31 INFO Utils: Successfully started service 'SparkUI' on port 4040.
17/09/19 17:29:31 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://169.235.27.138:4040
17/09/19 17:29:31 INFO SparkContext: Added JAR file:/home/acald013/PhD/Y2Q4/PFlock/target/scala-2.11/pflock_2.11-1.0.jar at spark://169.235.27.138:45405/jars/pflock_2.11-1.0.jar with timestamp 1505867371899
17/09/19 17:29:32 INFO Executor: Starting executor ID driver on host localhost
17/09/19 17:29:32 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36988.
17/09/19 17:29:32 INFO NettyBlockTransferService: Server created on 169.235.27.138:36988
17/09/19 17:29:32 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/09/19 17:29:32 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 169.235.27.138, 36988, None)
17/09/19 17:29:32 INFO BlockManagerMasterEndpoint: Registering block manager 169.235.27.138:36988 with 6.2 GB RAM, BlockManagerId(driver, 169.235.27.138, 36988, None)
17/09/19 17:29:32 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 169.235.27.138, 36988, None)
17/09/19 17:29:32 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 169.235.27.138, 36988, None)
17/09/19 17:29:32 INFO EventLoggingListener: Logging events to file:///home/acald013/Logs/local-1505867371956
17/09/19 17:29:32 INFO SharedState: Warehouse path is 'file:/home/acald013/PhD/Y2Q4/Scripts/SpeedupSingleNode/spark-warehouse/'.
Running local-1505867371956 on 6 cores and 1024 partitions...
       Tag    Epsilon    Dataset      TimeD      TimeM  TotalTime NCandidate   NMaximal      Cores Partitions       Timestamp
    PFlock       50.0        80K    147.596     93.718    241.314     575930        482          6       1024    17:33:35.378
    PFlock       60.0        80K    143.712    106.724    250.436     700950        751          6       1024    17:37:45.976
    PFlock       70.0        80K    154.336    115.198    269.534     833016        904          6       1024    17:42:15.602
    PFlock       80.0        80K    163.019    130.759    293.778     974432       1065          6       1024    17:47:09.472
    PFlock       90.0        80K    177.335    142.006    319.341    1130136       1287          6       1024    17:52:28.898
    PFlock      100.0        80K    186.918    158.448    345.366    1302882       1563          6       1024    17:58:14.352
Done!!!
Running in 6 cores and 1024 partitions.  Setting mu = 50 ...
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
17/09/19 17:58:26 INFO SparkContext: Running Spark version 2.1.0
17/09/19 17:58:26 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/09/19 17:58:26 INFO SecurityManager: Changing view acls to: acald013
17/09/19 17:58:26 INFO SecurityManager: Changing modify acls to: acald013
17/09/19 17:58:26 INFO SecurityManager: Changing view acls groups to: 
17/09/19 17:58:26 INFO SecurityManager: Changing modify acls groups to: 
17/09/19 17:58:26 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(acald013); groups with view permissions: Set(); users  with modify permissions: Set(acald013); groups with modify permissions: Set()
17/09/19 17:58:27 INFO Utils: Successfully started service 'sparkDriver' on port 45862.
17/09/19 17:58:27 INFO SparkEnv: Registering MapOutputTracker
17/09/19 17:58:27 INFO SparkEnv: Registering BlockManagerMaster
17/09/19 17:58:27 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/09/19 17:58:27 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/09/19 17:58:27 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-422c5f44-cc8b-4e63-bfdd-326859723ae3
17/09/19 17:58:27 INFO MemoryStore: MemoryStore started with capacity 6.2 GB
17/09/19 17:58:27 INFO SparkEnv: Registering OutputCommitCoordinator
17/09/19 17:58:28 INFO Utils: Successfully started service 'SparkUI' on port 4040.
17/09/19 17:58:28 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://169.235.27.138:4040
17/09/19 17:58:28 INFO SparkContext: Added JAR file:/home/acald013/PhD/Y2Q4/PFlock/target/scala-2.11/pflock_2.11-1.0.jar at spark://169.235.27.138:45862/jars/pflock_2.11-1.0.jar with timestamp 1505869108075
17/09/19 17:58:28 INFO Executor: Starting executor ID driver on host localhost
17/09/19 17:58:28 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33119.
17/09/19 17:58:28 INFO NettyBlockTransferService: Server created on 169.235.27.138:33119
17/09/19 17:58:28 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/09/19 17:58:28 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 169.235.27.138, 33119, None)
17/09/19 17:58:28 INFO BlockManagerMasterEndpoint: Registering block manager 169.235.27.138:33119 with 6.2 GB RAM, BlockManagerId(driver, 169.235.27.138, 33119, None)
17/09/19 17:58:28 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 169.235.27.138, 33119, None)
17/09/19 17:58:28 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 169.235.27.138, 33119, None)
17/09/19 17:58:29 INFO EventLoggingListener: Logging events to file:///home/acald013/Logs/local-1505869108131
17/09/19 17:58:29 INFO SharedState: Warehouse path is 'file:/home/acald013/PhD/Y2Q4/Scripts/SpeedupSingleNode/spark-warehouse/'.
Running local-1505869108131 on 6 cores and 1024 partitions...
       Tag    Epsilon    Dataset      TimeD      TimeM  TotalTime NCandidate   NMaximal      Cores Partitions       Timestamp
    PFlock       50.0        80K    145.510     94.615    240.125     575930        482          6       1024    18:02:30.402
    PFlock       60.0        80K    146.382    106.793    253.175     700950        751          6       1024    18:06:43.735
    PFlock       70.0        80K    155.288    117.373    272.661     833016        904          6       1024    18:11:16.489
    PFlock       80.0        80K    169.546    129.783    299.329     974432       1065          6       1024    18:16:15.904
    PFlock       90.0        80K    178.897    143.556    322.453    1130136       1287          6       1024    18:21:38.442
    PFlock      100.0        80K    187.602    159.019    346.621    1302882       1563          6       1024    18:27:25.149
Done!!!
Running in 5 cores and 1024 partitions.  Setting mu = 50 ...
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
17/09/19 18:27:37 INFO SparkContext: Running Spark version 2.1.0
17/09/19 18:27:38 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/09/19 18:27:38 INFO SecurityManager: Changing view acls to: acald013
17/09/19 18:27:38 INFO SecurityManager: Changing modify acls to: acald013
17/09/19 18:27:38 INFO SecurityManager: Changing view acls groups to: 
17/09/19 18:27:38 INFO SecurityManager: Changing modify acls groups to: 
17/09/19 18:27:38 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(acald013); groups with view permissions: Set(); users  with modify permissions: Set(acald013); groups with modify permissions: Set()
17/09/19 18:27:39 INFO Utils: Successfully started service 'sparkDriver' on port 33273.
17/09/19 18:27:39 INFO SparkEnv: Registering MapOutputTracker
17/09/19 18:27:39 INFO SparkEnv: Registering BlockManagerMaster
17/09/19 18:27:39 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/09/19 18:27:39 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/09/19 18:27:39 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-9db8c8a2-f4ca-414b-8f83-4ab469dadcad
17/09/19 18:27:39 INFO MemoryStore: MemoryStore started with capacity 6.2 GB
17/09/19 18:27:39 INFO SparkEnv: Registering OutputCommitCoordinator
17/09/19 18:27:39 INFO Utils: Successfully started service 'SparkUI' on port 4040.
17/09/19 18:27:39 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://169.235.27.138:4040
17/09/19 18:27:39 INFO SparkContext: Added JAR file:/home/acald013/PhD/Y2Q4/PFlock/target/scala-2.11/pflock_2.11-1.0.jar at spark://169.235.27.138:33273/jars/pflock_2.11-1.0.jar with timestamp 1505870859817
17/09/19 18:27:39 INFO Executor: Starting executor ID driver on host localhost
17/09/19 18:27:39 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46458.
17/09/19 18:27:39 INFO NettyBlockTransferService: Server created on 169.235.27.138:46458
17/09/19 18:27:39 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/09/19 18:27:39 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 169.235.27.138, 46458, None)
17/09/19 18:27:39 INFO BlockManagerMasterEndpoint: Registering block manager 169.235.27.138:46458 with 6.2 GB RAM, BlockManagerId(driver, 169.235.27.138, 46458, None)
17/09/19 18:27:39 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 169.235.27.138, 46458, None)
17/09/19 18:27:39 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 169.235.27.138, 46458, None)
17/09/19 18:27:40 INFO EventLoggingListener: Logging events to file:///home/acald013/Logs/local-1505870859871
17/09/19 18:27:40 INFO SharedState: Warehouse path is 'file:/home/acald013/PhD/Y2Q4/Scripts/SpeedupSingleNode/spark-warehouse/'.
Running local-1505870859871 on 5 cores and 1024 partitions...
       Tag    Epsilon    Dataset      TimeD      TimeM  TotalTime NCandidate   NMaximal      Cores Partitions       Timestamp
    PFlock       50.0        80K    169.278    107.539    276.817     575930        482          5       1024    18:32:18.836
    PFlock       60.0        80K    166.831    121.249    288.080     700950        751          5       1024    18:37:07.079
    PFlock       70.0        80K    176.713    133.035    309.748     833016        904          5       1024    18:42:16.925
    PFlock       80.0        80K    191.346    148.127    339.473     974432       1065          5       1024    18:47:56.484
    PFlock       90.0        80K    199.303    164.821    364.124    1130136       1287          5       1024    18:54:00.691
    PFlock      100.0        80K    213.929    182.915    396.844    1302882       1563          5       1024    19:00:37.618
Done!!!
Running in 5 cores and 1024 partitions.  Setting mu = 50 ...
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
17/09/19 19:00:49 INFO SparkContext: Running Spark version 2.1.0
17/09/19 19:00:49 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/09/19 19:00:49 INFO SecurityManager: Changing view acls to: acald013
17/09/19 19:00:49 INFO SecurityManager: Changing modify acls to: acald013
17/09/19 19:00:49 INFO SecurityManager: Changing view acls groups to: 
17/09/19 19:00:49 INFO SecurityManager: Changing modify acls groups to: 
17/09/19 19:00:49 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(acald013); groups with view permissions: Set(); users  with modify permissions: Set(acald013); groups with modify permissions: Set()
17/09/19 19:00:50 INFO Utils: Successfully started service 'sparkDriver' on port 41434.
17/09/19 19:00:50 INFO SparkEnv: Registering MapOutputTracker
17/09/19 19:00:50 INFO SparkEnv: Registering BlockManagerMaster
17/09/19 19:00:50 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/09/19 19:00:50 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/09/19 19:00:50 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-cde4bf98-5373-42a1-bd38-9411864d59a4
17/09/19 19:00:50 INFO MemoryStore: MemoryStore started with capacity 6.2 GB
17/09/19 19:00:50 INFO SparkEnv: Registering OutputCommitCoordinator
17/09/19 19:00:50 INFO Utils: Successfully started service 'SparkUI' on port 4040.
17/09/19 19:00:50 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://169.235.27.138:4040
17/09/19 19:00:50 INFO SparkContext: Added JAR file:/home/acald013/PhD/Y2Q4/PFlock/target/scala-2.11/pflock_2.11-1.0.jar at spark://169.235.27.138:41434/jars/pflock_2.11-1.0.jar with timestamp 1505872850954
17/09/19 19:00:51 INFO Executor: Starting executor ID driver on host localhost
17/09/19 19:00:51 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37476.
17/09/19 19:00:51 INFO NettyBlockTransferService: Server created on 169.235.27.138:37476
17/09/19 19:00:51 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/09/19 19:00:51 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 169.235.27.138, 37476, None)
17/09/19 19:00:51 INFO BlockManagerMasterEndpoint: Registering block manager 169.235.27.138:37476 with 6.2 GB RAM, BlockManagerId(driver, 169.235.27.138, 37476, None)
17/09/19 19:00:51 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 169.235.27.138, 37476, None)
17/09/19 19:00:51 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 169.235.27.138, 37476, None)
17/09/19 19:00:51 INFO EventLoggingListener: Logging events to file:///home/acald013/Logs/local-1505872851008
17/09/19 19:00:51 INFO SharedState: Warehouse path is 'file:/home/acald013/PhD/Y2Q4/Scripts/SpeedupSingleNode/spark-warehouse/'.
Running local-1505872851008 on 5 cores and 1024 partitions...
       Tag    Epsilon    Dataset      TimeD      TimeM  TotalTime NCandidate   NMaximal      Cores Partitions       Timestamp
    PFlock       50.0        80K    163.329    107.674    271.003     575930        482          5       1024    19:05:24.111
