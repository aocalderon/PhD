acald013@dblab-rack11: stopping org.apache.spark.deploy.worker.Worker
stopping org.apache.spark.deploy.master.Master
starting org.apache.spark.deploy.master.Master, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.master.Master-1-dblab-rack15.out
acald013@dblab-rack11: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack11.cs.ucr.edu.out
Running in 7 cores and 1024 partitions.  Setting mu = 40 ...
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
17/09/20 20:05:27 INFO SparkContext: Running Spark version 2.1.0
17/09/20 20:05:28 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/09/20 20:05:28 INFO SecurityManager: Changing view acls to: acald013
17/09/20 20:05:28 INFO SecurityManager: Changing modify acls to: acald013
17/09/20 20:05:28 INFO SecurityManager: Changing view acls groups to: 
17/09/20 20:05:28 INFO SecurityManager: Changing modify acls groups to: 
17/09/20 20:05:28 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(acald013); groups with view permissions: Set(); users  with modify permissions: Set(acald013); groups with modify permissions: Set()
17/09/20 20:05:28 INFO Utils: Successfully started service 'sparkDriver' on port 35570.
17/09/20 20:05:28 INFO SparkEnv: Registering MapOutputTracker
17/09/20 20:05:28 INFO SparkEnv: Registering BlockManagerMaster
17/09/20 20:05:28 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/09/20 20:05:28 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/09/20 20:05:28 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-c1f9d986-94a1-426b-8806-0c2b7700f072
17/09/20 20:05:28 INFO MemoryStore: MemoryStore started with capacity 6.2 GB
17/09/20 20:05:28 INFO SparkEnv: Registering OutputCommitCoordinator
17/09/20 20:05:29 INFO Utils: Successfully started service 'SparkUI' on port 4040.
17/09/20 20:05:29 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://169.235.27.138:4040
17/09/20 20:05:29 INFO SparkContext: Added JAR file:/home/acald013/PhD/Y2Q4/PFlock/target/scala-2.11/pflock_2.11-1.0.jar at spark://169.235.27.138:35570/jars/pflock_2.11-1.0.jar with timestamp 1505963129438
17/09/20 20:05:29 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://169.235.27.138:7077...
17/09/20 20:05:29 INFO TransportClientFactory: Successfully created connection to /169.235.27.138:7077 after 48 ms (0 ms spent in bootstraps)
17/09/20 20:05:29 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20170920200529-0000
17/09/20 20:05:29 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39075.
17/09/20 20:05:29 INFO NettyBlockTransferService: Server created on 169.235.27.138:39075
17/09/20 20:05:29 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/09/20 20:05:29 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 169.235.27.138, 39075, None)
17/09/20 20:05:29 INFO BlockManagerMasterEndpoint: Registering block manager 169.235.27.138:39075 with 6.2 GB RAM, BlockManagerId(driver, 169.235.27.138, 39075, None)
17/09/20 20:05:29 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 169.235.27.138, 39075, None)
17/09/20 20:05:29 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 169.235.27.138, 39075, None)
17/09/20 20:05:29 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20170920200529-0000/0 on worker-20170920200522-169.235.27.134-44025 (169.235.27.134:44025) with 7 cores
17/09/20 20:05:29 INFO StandaloneSchedulerBackend: Granted executor ID app-20170920200529-0000/0 on hostPort 169.235.27.134:44025 with 7 cores, 12.0 GB RAM
17/09/20 20:05:29 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20170920200529-0000/0 is now RUNNING
17/09/20 20:05:30 INFO EventLoggingListener: Logging events to file:///home/acald013/Logs/app-20170920200529-0000
17/09/20 20:05:30 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
17/09/20 20:05:30 INFO SharedState: Warehouse path is 'file:/home/acald013/PhD/Y2Q4/Scripts/Scaleup/spark-warehouse/'.
Running app-20170920200529-0000 on 7 cores and 1024 partitions...
       Tag    Epsilon    Dataset      TimeD      TimeM  TotalTime NCandidate   NMaximal      Cores Partitions       Timestamp
17/09/20 20:05:42 ERROR TaskSchedulerImpl: Lost executor 0 on 169.235.27.134: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
./runDataset.sh: line 29: 22531 Killed                  spark-submit ~/PhD/Y2Q4/PFlock/target/scala-2.11/pflock_2.11-1.0.jar --prefix /home/acald013/Datasets/Berlin/EPSG3068/B --suffix $SUFFIX --master spark://169.235.27.138:7077 --mu $MU --cores $CORES --partitions $PARTITIONS --tag $TS --estart $ESTART --eend $EEND --estep 10 --dstart $DSTART --dend $DEND --dstep 20 --dirlogs ~/Spark/Logs --output $OUTPUT
Done!!!
acald013@dblab-rack11: no org.apache.spark.deploy.worker.Worker to stop
no org.apache.spark.deploy.master.Master to stop
starting org.apache.spark.deploy.master.Master, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.master.Master-1-dblab-rack15.out
acald013@dblab-rack11: starting org.apache.spark.deploy.worker.Worker, logging to /home/acald013/Spark/spark-2.1.0-bin-hadoop2.7/logs/spark-acald013-org.apache.spark.deploy.worker.Worker-1-dblab-rack11.cs.ucr.edu.out
Running in 7 cores and 1024 partitions.  Setting mu = 20 ...
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
17/09/20 20:10:24 INFO SparkContext: Running Spark version 2.1.0
17/09/20 20:10:24 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/09/20 20:10:24 INFO SecurityManager: Changing view acls to: acald013
17/09/20 20:10:24 INFO SecurityManager: Changing modify acls to: acald013
17/09/20 20:10:24 INFO SecurityManager: Changing view acls groups to: 
17/09/20 20:10:24 INFO SecurityManager: Changing modify acls groups to: 
17/09/20 20:10:24 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(acald013); groups with view permissions: Set(); users  with modify permissions: Set(acald013); groups with modify permissions: Set()
17/09/20 20:10:25 INFO Utils: Successfully started service 'sparkDriver' on port 44744.
17/09/20 20:10:25 INFO SparkEnv: Registering MapOutputTracker
17/09/20 20:10:25 INFO SparkEnv: Registering BlockManagerMaster
17/09/20 20:10:25 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/09/20 20:10:25 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/09/20 20:10:25 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-0a463ff4-3045-44bc-a9f7-ea58b6798873
17/09/20 20:10:25 INFO MemoryStore: MemoryStore started with capacity 6.2 GB
17/09/20 20:10:25 INFO SparkEnv: Registering OutputCommitCoordinator
17/09/20 20:10:26 INFO Utils: Successfully started service 'SparkUI' on port 4040.
17/09/20 20:10:26 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://169.235.27.138:4040
17/09/20 20:10:26 INFO SparkContext: Added JAR file:/home/acald013/PhD/Y2Q4/PFlock/target/scala-2.11/pflock_2.11-1.0.jar at spark://169.235.27.138:44744/jars/pflock_2.11-1.0.jar with timestamp 1505963426125
17/09/20 20:10:26 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://169.235.27.138:7077...
17/09/20 20:10:26 INFO TransportClientFactory: Successfully created connection to /169.235.27.138:7077 after 47 ms (0 ms spent in bootstraps)
17/09/20 20:10:26 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20170920201026-0000
17/09/20 20:10:26 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44680.
17/09/20 20:10:26 INFO NettyBlockTransferService: Server created on 169.235.27.138:44680
17/09/20 20:10:26 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/09/20 20:10:26 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 169.235.27.138, 44680, None)
17/09/20 20:10:26 INFO BlockManagerMasterEndpoint: Registering block manager 169.235.27.138:44680 with 6.2 GB RAM, BlockManagerId(driver, 169.235.27.138, 44680, None)
17/09/20 20:10:26 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 169.235.27.138, 44680, None)
17/09/20 20:10:26 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 169.235.27.138, 44680, None)
17/09/20 20:10:26 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20170920201026-0000/0 on worker-20170920201018-169.235.27.134-35615 (169.235.27.134:35615) with 7 cores
17/09/20 20:10:26 INFO StandaloneSchedulerBackend: Granted executor ID app-20170920201026-0000/0 on hostPort 169.235.27.134:35615 with 7 cores, 12.0 GB RAM
17/09/20 20:10:26 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20170920201026-0000/0 is now RUNNING
17/09/20 20:10:26 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
17/09/20 20:10:26 INFO SharedState: Warehouse path is 'file:/home/acald013/PhD/Y2Q4/Scripts/Scaleup/spark-warehouse/'.
Running app-20170920201026-0000 on 7 cores and 1024 partitions...
       Tag    Epsilon    Dataset      TimeD      TimeM  TotalTime NCandidate   NMaximal      Cores Partitions       Timestamp
    PFlock       50.0        20K     56.651     23.027     79.678      36144         11          7       1024    20:11:48.081
    PFlock       60.0        20K     43.881     22.629     66.510      44016         18          7       1024    20:12:54.738
    PFlock       70.0        20K     44.217     22.748     66.965      52488         18          7       1024    20:14:01.792
    PFlock       80.0        20K     45.000     24.429     69.429      61482         20          7       1024    20:15:11.303
