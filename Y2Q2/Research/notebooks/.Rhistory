install.packages("optparse")
q()
opt$lat = 39.976057
opt = {}
opt$lat = 39.976057
opt
library(SparkR)
library(leaflet)
library(sp)
options(digits=15)
source("input.R")
the_lat = opt$lat
the_lng = opt$lng
the_zoom = opt$zoom
epsilon = opt$epsilon
mu = opt$mu
source("pbfe.R")
output = paste0(opt$out, "_E",  epsilon, "_M", mu)
data = read.csv(opt$input)
names(data) = c("ID","lat","lng")
sc <- sparkR.init("local[*]", "SparkR")
sqlContext <- sparkRSQL.init(sc)
dataRDD = SparkR:::textFile(sc,opt$input)
dataRDD = SparkR:::map(dataRDD, transformCoords)
head(dataRDD)
print("Transforming coordinates...")
schema <- structType(structField("id", "double"), structField("lng", "double"), structField("lat", "double"))
points <- createDataFrame(sqlContext, dataRDD, schema = schema)
head(points)
registerTempTable(points, "p1")
registerTempTable(points, "p2")
print("Running distance join...")
sql = paste0("SELECT * FROM p1 DISTANCE JOIN p2 ON POINT(p2.lng, p2.lat) IN CIRCLERANGE(POINT(p1.lng, p1.lat), ",epsilon,") WHERE p2.id < p1.id")
pairs = sql(sqlContext,sql)
head(pairs)
head(points)
epsilon
library(SparkR)
library(leaflet)
library(sp)
options(digits=15)
source("input.R")
the_lat = opt$lat
the_lng = opt$lng
the_zoom = opt$zoom
epsilon = opt$epsilon
mu = opt$mu
source("pbfe.R")
output = paste0(opt$out, "_E",  epsilon, "_M", mu)
data = read.csv(opt$input)
names(data) = c("ID","lat","lng")
sc <- sparkR.init("local[*]", "SparkR")
sqlContext <- sparkRSQL.init(sc)
dataRDD = SparkR:::textFile(sc,opt$input)
dataRDD = SparkR:::map(dataRDD, transformCoords)
print("Transforming coordinates...")
schema <- structType(structField("id", "double"), structField("lng", "double"), structField("lat", "double"))
points <- createDataFrame(sqlContext, dataRDD, schema = schema)
registerTempTable(points, "p1")
registerTempTable(points, "p2")
print("Running distance join...")
sql = paste0("SELECT * FROM p1 DISTANCE JOIN p2 ON POINT(p2.lng, p2.lat) IN CIRCLERANGE(POINT(p1.lng, p1.lat), ",epsilon,") WHERE p2.id < p1.id")
pairs = sql(sqlContext,sql)
head(pairs)
source("input.R")
the_lat = opt$lat
the_lng = opt$lng
the_zoom = opt$zoom
epsilon = opt$epsilon
mu = opt$mu
source("pbfe.R")
output = paste0(opt$out, "_E",  epsilon, "_M", mu)
data = read.csv(opt$input)
names(data) = c("ID","lat","lng")
# head(data)
# map = leaflet() %>%
#	addTiles() %>%
#	addCircleMarkers(lng=data$lng, lat=data$lat,weight=2,fillOpacity=1,color="blue",radius=2)
# file = 'map.html'
# htmlwidgets::saveWidget(map, file = file, selfcontained = F)
# IRdisplay::display_html(paste("<iframe width=100% height=400 src=' ", file, " ' ","/>"))
sc <- sparkR.init("local[*]", "SparkR")
sqlContext <- sparkRSQL.init(sc)
dataRDD = SparkR:::textFile(sc,opt$input)
dataRDD = SparkR:::map(dataRDD, transformCoords)
print("Transforming coordinates...")
schema <- structType(structField("id", "double"), structField("lng", "double"), structField("lat", "double"))
points <- createDataFrame(sqlContext, dataRDD, schema = schema)
# cache(points)
# head(points)
# count(points)
registerTempTable(points, "p1")
registerTempTable(points, "p2")
print("Running distance join...")
sql = paste0("SELECT * FROM p1 DISTANCE JOIN p2 ON POINT(p2.lng, p2.lat) IN CIRCLERANGE(POINT(p1.lng, p1.lat), ",epsilon,") WHERE p2.id < p1.id")
pairs = sql(sqlContext,sql)
head(pairs)
# nrow(pairs)
centers <- SparkR:::map(pairs, calculateDisk)
schema <- structType(structField("id1", "double"), structField("id2", "double"), structField("lng1", "double"), structField("lat1", "double"), structField("lng2", "double"), structField("lat2", "double"))
d <- createDataFrame(sqlContext, centers, schema = schema)
source('~/Documents/PhD/Code/Y2Q2/Research/notebooks/Beijing_Finding_Disks1.R')
source('~/Documents/PhD/Code/Y2Q2/Research/notebooks/Beijing_Finding_Disks1.R')
sparkR.stop()
source('~/Documents/PhD/Code/Y2Q2/Research/notebooks/Beijing_Finding_Disks1.R')
