\documentclass[a4paper,10pt]{scrartcl}
\usepackage[hmargin=2.5cm,vmargin=3cm]{geometry}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{hyperref}
\hypersetup{
colorlinks=false,
hidelinks
}
\usepackage{minted}
\usepackage{xcolor}
\usepackage{amsmath}

%opening
\title{Report Lab 3}
\author{Andres Calderon - SID:861243796}

\begin{document}

\maketitle
\section{Code}
The following code was used to complete the report:

\subsection{Reduction}

\subsubsection{kernel.cu}

\inputminted[
fontsize=\footnotesize,
tabsize=2,
breaklines,
linenos
]{c}{3.1-reduction/kernel.cu}

There are not significant changes in the other files.

\subsection{Prefix-scan}

\subsubsection{kernel.cu}

\inputminted[
fontsize=\footnotesize,
tabsize=2,
breaklines,
linenos
]{c}{3.2-prefix-scan/kernel.cu}

\subsubsection{main.cu}

\inputminted[
fontsize=\footnotesize,
tabsize=2,
breaklines,
linenos
]{c}{3.2-prefix-scan/main.cu}

Full code and other materials are available at \cite{github}.

\section{Answers to Questions}
\begin{enumerate}
 \item Use visual profiler to report relevant statistics about the execution of your kernels.  Did you find any surprising results?
 
 Figure \ref{fig:NVVP_Reduction} shows the summary of the profile analysis over the \texttt{reduction} kernel.  One important metric that should be noted is the high performance for \textit{Global Load and Global Store Efficiency} (highlighted by 1 in the figures).  Those values are significantly larger in comparison with the \texttt{prefix-scan} kernel (figure \ref{fig:NVVP_Prefix-scan}).  The strategy for avoiding uncoalesced memory access implemented in the \texttt{reduction} kernel proves to be more efficient.  
 
 Another important metric is the \textit{Low Compute / Memcpy Efficiency} in both kernels (pointed by 2 in both figures).  As it can be seen, the time spent to copy data between the host and the device is considerably larger that the time spent in computation. The NVVP Help proposes asynchronous and overlapping transfers using \texttt{cudaMemcpyAsync()} function as a possible alternative to address the problem \cite{overlap} \cite{fortran}.
 
 \begin{figure}
  \centering
  \includegraphics[width=\textwidth]{./NVVP_Reduction.png}
  \caption{NVVP performance analysis for \textit{reduction}.}\label{fig:NVVP_Reduction}
 \end{figure}

 \begin{figure}
  \centering
  \includegraphics[width=\textwidth]{./NVVP_Prefix-scan.png}
  \caption{NVVP performance analysis for \textit{prefix-scan}.}\label{fig:NVVP_Prefix-scan}
 \end{figure}

 \item For each of reduction and prefix scan, suggest one approach to speed up your implementation.
 
 For reduction, it is possible to chunk input data to perform more \textbf{\texttt{memcpy}} operations and take advantage of the time of each of them to perform computation using streams. So, when the program is copying some data, it already can compute some of them asynchronously \cite{overlap} \cite{fortran}.  In this way, it is possible to overlap the copy and compute stages.
 
 For prefix-scan, \cite{harris2007} explore an alternative in order to avoid share memory bank conflicts. The main idea is to avoid most of the bank conflicts by adding a variable amount of padding to each shared memory array index they compute. Specifically, the value of the index divided by the number of shared memory banks is added to each index. A gentle explanation of the algorithm is available in \cite{udacity}.  However, as \cite{hwu2015} argues, this approach (although offers an increase in time response) could be more computationally expensive.
\end{enumerate}

\begin{thebibliography}{9}
\bibitem{github} 
Andres Calderon.
\textit{GitHub Personal Repository}, 2015. 
\url{https://github.com/aocalderon/PhD/tree/master/Y1Q1/GPU/lab3}.
 
\bibitem{hwu2015} 
Wen-Mei Hwu.
\textit{Parallel Computation Patterns, More on Parallel Scan - Heterogeneous Parallel Programming}. 
Coursera Course, 2015. \url{https://www.dropbox.com/s/ad1ifkeoucwargz/4%20-%207%20-%204.7-%20Parallel%20Computation%20Patterns%20-%20More%20on%20Parallel%20Scan.mp4?dl=0}.

\bibitem{udacity} 
David Luebke, John Owens, Mike Roberts and Cheng-Han Lee.
\textit{Blelloch Scan - Intro to Parallel Programming}. 
Udacity Course, 2015. \url{https://www.youtube.com/watch?v=hyKA5fb5ZJI}.

\bibitem{harris2007}
Mark Harris, Shubhabrata Sengupta and John D. Owens.
\textit{Parallel Prefix Sum (Scan) with CUDA} in \textit{GPU Gems 3} edited by Hubert Nguyen. 
Addison-Wesley, 2007.
\url{http://http.developer.nvidia.com/GPUGems3/gpugems3_ch39.html}.

\bibitem{overlap}
Mark Harris.
\textit{How to Overlap Data Transfers in CUDA C/C++} in \textit{Parallel Forall} Website. Nvidia, 2012.
\url{http://devblogs.nvidia.com/parallelforall/how-overlap-data-transfers-cuda-cc/}.

\bibitem{fortran}
Gregory Ruetsch and Massimiliano Fatica.
\textit{CUDA Fortran for Scientists and Engineers: Best Practices for Efficient CUDA Fortran Programming}. pag 52-60.
Morgan Kaufmann. 2013.

\end{thebibliography}

\end{document}
